{
    "title": "House Prices - Advanced Regression Techniques",
    "overview": "Overview\nDescription\nStart here if...\nYou have some experience with R or Python and machine learning basics. This is a perfect competition for data science students who have completed an online course in machine learning and are looking to expand their skill set before trying a featured competition. \n\nðŸ’¡Getting Started Notebook\nTo get started quickly, feel free to take advantage of this starter notebook.\n\nCompetition Description\n\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\nPractice Skills\nCreative feature engineering \nAdvanced regression techniques like random forest and gradient boosting\n\nEvaluation\nGoal\nIt is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. \n\nMetric\nSubmissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)",
    "type": "Regression",
    "model": [
        "Lightgbm",
        "XGBoost"
    ],
    "code": "1-house-prices-solution-top-1.ipynb",
    "url": "https://www.kaggle.com/code/jesucristo/1-house-prices-solution-top-1",
    "score": 0.10649,
    "evaluation": "Regression Error(MAE,R^2,RMSE,RMSLE)",
    "max score": 0.0,
    "min score": 0.11989,
    "relative score": 0.11176912169488694,
    "medal": "Silver"
}