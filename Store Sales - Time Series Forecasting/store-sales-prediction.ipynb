{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6b3605",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-15T15:20:41.613337Z",
     "iopub.status.busy": "2023-10-15T15:20:41.612491Z",
     "iopub.status.idle": "2023-10-15T15:20:41.992133Z",
     "shell.execute_reply": "2023-10-15T15:20:41.991023Z"
    },
    "papermill": {
     "duration": 0.392763,
     "end_time": "2023-10-15T15:20:41.994674",
     "exception": false,
     "start_time": "2023-10-15T15:20:41.601911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/store-sales-time-series-forecasting/oil.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/stores.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/train.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/test.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4faa36e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:20:42.024936Z",
     "iopub.status.busy": "2023-10-15T15:20:42.024467Z",
     "iopub.status.idle": "2023-10-15T15:21:03.678584Z",
     "shell.execute_reply": "2023-10-15T15:21:03.677030Z"
    },
    "papermill": {
     "duration": 21.671888,
     "end_time": "2023-10-15T15:21:03.681744",
     "exception": false,
     "start_time": "2023-10-15T15:20:42.009856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/store-sales-time-series-forecasting/oil.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/stores.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/train.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/test.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "!pip install darts --quiet\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce53ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:03.702014Z",
     "iopub.status.busy": "2023-10-15T15:21:03.701607Z",
     "iopub.status.idle": "2023-10-15T15:21:07.135632Z",
     "shell.execute_reply": "2023-10-15T15:21:07.134400Z"
    },
    "papermill": {
     "duration": 3.446933,
     "end_time": "2023-10-15T15:21:07.137937",
     "exception": false,
     "start_time": "2023-10-15T15:21:03.691004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06f4ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:07.157662Z",
     "iopub.status.busy": "2023-10-15T15:21:07.157330Z",
     "iopub.status.idle": "2023-10-15T15:21:07.167741Z",
     "shell.execute_reply": "2023-10-15T15:21:07.166617Z"
    },
    "papermill": {
     "duration": 0.023516,
     "end_time": "2023-10-15T15:21:07.170624",
     "exception": false,
     "start_time": "2023-10-15T15:21:07.147108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_holidays_events = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2489dfb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:07.190498Z",
     "iopub.status.busy": "2023-10-15T15:21:07.190148Z",
     "iopub.status.idle": "2023-10-15T15:21:07.201245Z",
     "shell.execute_reply": "2023-10-15T15:21:07.200368Z"
    },
    "papermill": {
     "duration": 0.023794,
     "end_time": "2023-10-15T15:21:07.203700",
     "exception": false,
     "start_time": "2023-10-15T15:21:07.179906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_oil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d8225b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:07.224820Z",
     "iopub.status.busy": "2023-10-15T15:21:07.224134Z",
     "iopub.status.idle": "2023-10-15T15:21:07.236103Z",
     "shell.execute_reply": "2023-10-15T15:21:07.235170Z"
    },
    "papermill": {
     "duration": 0.025466,
     "end_time": "2023-10-15T15:21:07.238577",
     "exception": false,
     "start_time": "2023-10-15T15:21:07.213111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc720cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:07.266660Z",
     "iopub.status.busy": "2023-10-15T15:21:07.266257Z",
     "iopub.status.idle": "2023-10-15T15:21:07.324297Z",
     "shell.execute_reply": "2023-10-15T15:21:07.322656Z"
    },
    "papermill": {
     "duration": 0.079014,
     "end_time": "2023-10-15T15:21:07.328233",
     "exception": false,
     "start_time": "2023-10-15T15:21:07.249219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_transactions = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec07d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:07.354671Z",
     "iopub.status.busy": "2023-10-15T15:21:07.354220Z",
     "iopub.status.idle": "2023-10-15T15:21:07.388391Z",
     "shell.execute_reply": "2023-10-15T15:21:07.387357Z"
    },
    "papermill": {
     "duration": 0.053053,
     "end_time": "2023-10-15T15:21:07.391035",
     "exception": false,
     "start_time": "2023-10-15T15:21:07.337982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a585ddfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:07.412389Z",
     "iopub.status.busy": "2023-10-15T15:21:07.412041Z",
     "iopub.status.idle": "2023-10-15T15:21:07.571890Z",
     "shell.execute_reply": "2023-10-15T15:21:07.570553Z"
    },
    "papermill": {
     "duration": 0.173878,
     "end_time": "2023-10-15T15:21:07.574796",
     "exception": false,
     "start_time": "2023-10-15T15:21:07.400918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "family_list = df_train['family'].unique()\n",
    "store_list = df_stores['store_nbr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b735a6d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:07.595096Z",
     "iopub.status.busy": "2023-10-15T15:21:07.594688Z",
     "iopub.status.idle": "2023-10-15T15:21:12.945302Z",
     "shell.execute_reply": "2023-10-15T15:21:12.944443Z"
    },
    "papermill": {
     "duration": 5.363705,
     "end_time": "2023-10-15T15:21:12.947704",
     "exception": false,
     "start_time": "2023-10-15T15:21:07.583999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_merged = pd.merge(df_train, df_stores, on ='store_nbr')\n",
    "train_merged = train_merged.sort_values([\"store_nbr\",\"family\",\"date\"])\n",
    "train_merged = train_merged.astype({\"store_nbr\":'str', \"family\":'str', \"city\":'str',\n",
    "                          \"state\":'str', \"type\":'str', \"cluster\":'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c774921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:12.967372Z",
     "iopub.status.busy": "2023-10-15T15:21:12.966920Z",
     "iopub.status.idle": "2023-10-15T15:21:16.045779Z",
     "shell.execute_reply": "2023-10-15T15:21:16.044644Z"
    },
    "papermill": {
     "duration": 3.091784,
     "end_time": "2023-10-15T15:21:16.048491",
     "exception": false,
     "start_time": "2023-10-15T15:21:12.956707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"installl\" - maybe you meant \"install\"\r\n"
     ]
    }
   ],
   "source": [
    "!pip installl darts\n",
    "from darts import TimeSeries\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7049b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:16.068006Z",
     "iopub.status.busy": "2023-10-15T15:21:16.067432Z",
     "iopub.status.idle": "2023-10-15T15:21:42.894646Z",
     "shell.execute_reply": "2023-10-15T15:21:42.893186Z"
    },
    "papermill": {
     "duration": 26.84002,
     "end_time": "2023-10-15T15:21:42.897416",
     "exception": false,
     "start_time": "2023-10-15T15:21:16.057396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:26<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "family_TS_dict = {}\n",
    "\n",
    "for family in tqdm(family_list):\n",
    "    df_family = train_merged.loc[train_merged['family'] == family]\n",
    "\n",
    "    list_of_TS_family = TimeSeries.from_group_dataframe(\n",
    "                                df_family,\n",
    "                                time_col=\"date\",\n",
    "                                group_cols=[\"store_nbr\",\"family\"], # columns for grouping time series\n",
    "                                static_cols=[\"city\",\"state\",\"type\",\"cluster\"], # static covariates\n",
    "                                value_cols=\"sales\", # target\n",
    "                                fill_missing_dates=True, # filling missing dates, remember Dec 25th\n",
    "                                freq='D' # days\n",
    "                                )\n",
    "    for ts in list_of_TS_family:\n",
    "            ts = ts.astype(np.float32)\n",
    "    list_of_TS_family = sorted(list_of_TS_family, key=lambda ts: int(ts.static_covariates_values()[0,0]))\n",
    "    \n",
    "    family_TS_dict[family] = list_of_TS_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "149fbe94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:42.922270Z",
     "iopub.status.busy": "2023-10-15T15:21:42.921904Z",
     "iopub.status.idle": "2023-10-15T15:21:43.367349Z",
     "shell.execute_reply": "2023-10-15T15:21:43.365965Z"
    },
    "papermill": {
     "duration": 0.461285,
     "end_time": "2023-10-15T15:21:43.370178",
     "exception": false,
     "start_time": "2023-10-15T15:21:42.908893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from darts.dataprocessing import Pipeline\n",
    "from darts.dataprocessing.transformers import Scaler, StaticCovariatesTransformer, MissingValuesFiller, InvertibleMapper\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5c35efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:21:43.395174Z",
     "iopub.status.busy": "2023-10-15T15:21:43.393808Z",
     "iopub.status.idle": "2023-10-15T15:22:26.734435Z",
     "shell.execute_reply": "2023-10-15T15:22:26.733538Z"
    },
    "papermill": {
     "duration": 43.355464,
     "end_time": "2023-10-15T15:22:26.736810",
     "exception": false,
     "start_time": "2023-10-15T15:21:43.381346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:43<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "family_pipeline_dict = {}\n",
    "family_TS_transformed_dict = {}\n",
    "\n",
    "for key in tqdm(family_TS_dict):\n",
    "    train_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Fill NAs\")\n",
    "    static_cov_transformer = StaticCovariatesTransformer(verbose=False, transformer_cat = OrdinalEncoder(), name=\"Encoder\")\n",
    "    log_transformer = InvertibleMapper(np.log1p, np.expm1, verbose=False, n_jobs=-1, name=\"Log-Transform\")   \n",
    "    train_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaling\")\n",
    "\n",
    "    train_pipeline = Pipeline([train_filler,\n",
    "                             static_cov_transformer,\n",
    "                             log_transformer,\n",
    "                             train_scaler])\n",
    "\n",
    "    training_transformed = train_pipeline.fit_transform(family_TS_dict[key])\n",
    "    family_pipeline_dict[key] = train_pipeline\n",
    "    family_TS_transformed_dict[key] = training_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01422e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:26.825947Z",
     "iopub.status.busy": "2023-10-15T15:22:26.825498Z",
     "iopub.status.idle": "2023-10-15T15:22:26.830712Z",
     "shell.execute_reply": "2023-10-15T15:22:26.829718Z"
    },
    "papermill": {
     "duration": 0.083482,
     "end_time": "2023-10-15T15:22:26.832643",
     "exception": false,
     "start_time": "2023-10-15T15:22:26.749161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2b1564e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:26.860352Z",
     "iopub.status.busy": "2023-10-15T15:22:26.859938Z",
     "iopub.status.idle": "2023-10-15T15:22:26.913487Z",
     "shell.execute_reply": "2023-10-15T15:22:26.912046Z"
    },
    "papermill": {
     "duration": 0.070419,
     "end_time": "2023-10-15T15:22:26.916145",
     "exception": false,
     "start_time": "2023-10-15T15:22:26.845726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_time_period = pd.date_range(start='2013-01-01', end='2017-08-31', freq='D')\n",
    "\n",
    "year = datetime_attribute_timeseries(time_index = full_time_period, attribute='year')\n",
    "month = datetime_attribute_timeseries(time_index= full_time_period, attribute='month')\n",
    "day = datetime_attribute_timeseries(time_index = full_time_period, attribute='day')\n",
    "dayofyear = datetime_attribute_timeseries(time_index = full_time_period, attribute = 'dayofyear')\n",
    "weekday = datetime_attribute_timeseries(time_index = full_time_period , attribute='dayofweek')\n",
    "weekofyear = datetime_attribute_timeseries(time_index = full_time_period, attribute='weekofyear')\n",
    "timesteps = TimeSeries.from_times_and_values(times = full_time_period,\n",
    "                                            values = np.arange(len(full_time_period)),\n",
    "                                            columns= ['linear_increase'])\n",
    "\n",
    "time_cov = year.stack(month).stack(day).stack(dayofyear).stack(weekday).stack(weekofyear).stack(timesteps)\n",
    "time_cov = time_cov.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d8d1963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:26.943163Z",
     "iopub.status.busy": "2023-10-15T15:22:26.942832Z",
     "iopub.status.idle": "2023-10-15T15:22:26.984518Z",
     "shell.execute_reply": "2023-10-15T15:22:26.983383Z"
    },
    "papermill": {
     "duration": 0.058008,
     "end_time": "2023-10-15T15:22:26.986751",
     "exception": false,
     "start_time": "2023-10-15T15:22:26.928743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_cov_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaler\")\n",
    "time_cov_train, time_cov_val = time_cov.split_before(pd.Timestamp('20170816'))\n",
    "time_cov_scaler.fit(time_cov_train)\n",
    "time_cov_transformed = time_cov_scaler.transform(time_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb39e4d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:27.023802Z",
     "iopub.status.busy": "2023-10-15T15:22:27.022494Z",
     "iopub.status.idle": "2023-10-15T15:22:50.029994Z",
     "shell.execute_reply": "2023-10-15T15:22:50.028780Z"
    },
    "papermill": {
     "duration": 23.033816,
     "end_time": "2023-10-15T15:22:50.032992",
     "exception": false,
     "start_time": "2023-10-15T15:22:26.999176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from darts.models.filtering.moving_average_filter import MovingAverageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "929f8968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:50.061137Z",
     "iopub.status.busy": "2023-10-15T15:22:50.060361Z",
     "iopub.status.idle": "2023-10-15T15:22:50.144422Z",
     "shell.execute_reply": "2023-10-15T15:22:50.143306Z"
    },
    "papermill": {
     "duration": 0.101047,
     "end_time": "2023-10-15T15:22:50.147062",
     "exception": false,
     "start_time": "2023-10-15T15:22:50.046015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oil = TimeSeries.from_dataframe(df_oil, \n",
    "                                time_col = 'date', \n",
    "                                value_cols = ['dcoilwtico'],\n",
    "                                freq = 'D')\n",
    "\n",
    "oil = oil.astype(np.float32)\n",
    "\n",
    "# Transform\n",
    "oil_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Filler\")\n",
    "oil_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaler\")\n",
    "oil_pipeline = Pipeline([oil_filler, oil_scaler])\n",
    "oil_transformed = oil_pipeline.fit_transform(oil)\n",
    "\n",
    "# Moving Averages for Oil Price\n",
    "oil_moving_average_7 = MovingAverageFilter(window=7)\n",
    "oil_moving_average_28 = MovingAverageFilter(window=28)\n",
    "\n",
    "oil_moving_averages = []\n",
    "ma_7 = oil_moving_average_7.filter(oil_transformed).astype(np.float32)\n",
    "ma_7 = ma_7.with_columns_renamed(col_names=ma_7.components, col_names_new='oil_ma_7')\n",
    "ma_28 = oil_moving_average_28.filter(oil_transformed).astype(np.float32)\n",
    "ma_28 = ma_28.with_columns_renamed(col_names=ma_28.components, col_names_new='oil_ma_28')\n",
    "oil_moving_averages = ma_7.stack(ma_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91210157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:50.174890Z",
     "iopub.status.busy": "2023-10-15T15:22:50.174496Z",
     "iopub.status.idle": "2023-10-15T15:22:50.183282Z",
     "shell.execute_reply": "2023-10-15T15:22:50.182579Z"
    },
    "papermill": {
     "duration": 0.025053,
     "end_time": "2023-10-15T15:22:50.185094",
     "exception": false,
     "start_time": "2023-10-15T15:22:50.160041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def holiday_list(df_stores):\n",
    "\n",
    "    listofseries = []\n",
    "    \n",
    "    for i in range(0,len(df_stores)):        \n",
    "            df_holiday_dummies = pd.DataFrame(columns=['date'])\n",
    "            df_holiday_dummies[\"date\"] = df_holidays_events[\"date\"]\n",
    "    \n",
    "            df_holiday_dummies[\"national_holiday\"] = np.where(((df_holidays_events[\"type\"] == \"Holiday\") & (df_holidays_events[\"locale\"] == \"National\")), 1, 0)\n",
    "\n",
    "            df_holiday_dummies[\"earthquake_relief\"] = np.where(df_holidays_events['description'].str.contains('Terremoto Manabi'), 1, 0)\n",
    "\n",
    "            df_holiday_dummies[\"christmas\"] = np.where(df_holidays_events['description'].str.contains('Navidad'), 1, 0)\n",
    "\n",
    "            df_holiday_dummies[\"football_event\"] = np.where(df_holidays_events['description'].str.contains('futbol'), 1, 0)\n",
    "\n",
    "            df_holiday_dummies[\"national_event\"] = np.where(((df_holidays_events[\"type\"] == \"Event\") & (df_holidays_events[\"locale\"] == \"National\") & (~df_holidays_events['description'].str.contains('Terremoto Manabi')) & (~df_holidays_events['description'].str.contains('futbol'))), 1, 0)\n",
    "\n",
    "            df_holiday_dummies[\"work_day\"] = np.where((df_holidays_events[\"type\"] == \"Work Day\"), 1, 0)\n",
    "\n",
    "            df_holiday_dummies[\"local_holiday\"] = np.where(((df_holidays_events[\"type\"] == \"Holiday\") & ((df_holidays_events[\"locale_name\"] == df_stores['state'][i]) | (df_holidays_events[\"locale_name\"] == df_stores['city'][i]))), 1, 0)\n",
    "                     \n",
    "            listofseries.append(df_holiday_dummies)\n",
    "\n",
    "    return listofseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f691b3b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:50.212832Z",
     "iopub.status.busy": "2023-10-15T15:22:50.212455Z",
     "iopub.status.idle": "2023-10-15T15:22:50.219244Z",
     "shell.execute_reply": "2023-10-15T15:22:50.218196Z"
    },
    "papermill": {
     "duration": 0.023106,
     "end_time": "2023-10-15T15:22:50.221587",
     "exception": false,
     "start_time": "2023-10-15T15:22:50.198481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_0_and_duplicates(holiday_list):\n",
    "\n",
    "    listofseries = []\n",
    "    \n",
    "    for i in range(0,len(holiday_list)):         \n",
    "            df_holiday_per_store = list_of_holidays_per_store[i].set_index('date')\n",
    "\n",
    "            df_holiday_per_store = df_holiday_per_store.loc[~(df_holiday_per_store==0).all(axis=1)]\n",
    "            \n",
    "            df_holiday_per_store = df_holiday_per_store.groupby('date').agg({'national_holiday':'max', 'earthquake_relief':'max', \n",
    "                                   'christmas':'max', 'football_event':'max', \n",
    "                                   'national_event':'max', 'work_day':'max', \n",
    "                                   'local_holiday':'max'}).reset_index()\n",
    "\n",
    "            listofseries.append(df_holiday_per_store)\n",
    "\n",
    "    return listofseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5117f374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:50.248402Z",
     "iopub.status.busy": "2023-10-15T15:22:50.247976Z",
     "iopub.status.idle": "2023-10-15T15:22:50.254272Z",
     "shell.execute_reply": "2023-10-15T15:22:50.253149Z"
    },
    "papermill": {
     "duration": 0.022472,
     "end_time": "2023-10-15T15:22:50.256614",
     "exception": false,
     "start_time": "2023-10-15T15:22:50.234142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def holiday_TS_list_54(holiday_list):\n",
    "    listofseries = []\n",
    "    \n",
    "    for i in range(0,54):\n",
    "            holidays_TS = TimeSeries.from_dataframe(list_of_holidays_per_store[i], \n",
    "                                        time_col = 'date',\n",
    "                                        fill_missing_dates=True,\n",
    "                                        fillna_value=0,\n",
    "                                        freq='D')\n",
    "            \n",
    "            holidays_TS = holidays_TS.slice(pd.Timestamp('20130101'),pd.Timestamp('20170831'))\n",
    "            holidays_TS = holidays_TS.astype(np.float32)\n",
    "            listofseries.append(holidays_TS)\n",
    "\n",
    "    return listofseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c363bf8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:50.284781Z",
     "iopub.status.busy": "2023-10-15T15:22:50.283694Z",
     "iopub.status.idle": "2023-10-15T15:22:52.034941Z",
     "shell.execute_reply": "2023-10-15T15:22:52.034030Z"
    },
    "papermill": {
     "duration": 1.767747,
     "end_time": "2023-10-15T15:22:52.037403",
     "exception": false,
     "start_time": "2023-10-15T15:22:50.269656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_of_holidays_per_store = holiday_list(df_stores)\n",
    "list_of_holidays_per_store = remove_0_and_duplicates(list_of_holidays_per_store)\n",
    "list_of_holidays_store = holiday_TS_list_54(list_of_holidays_per_store)\n",
    "\n",
    "holidays_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Filler\")\n",
    "holidays_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaler\")\n",
    "\n",
    "holidays_pipeline = Pipeline([holidays_filler, holidays_scaler])\n",
    "holidays_transformed = holidays_pipeline.fit_transform(list_of_holidays_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c939011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:22:52.064852Z",
     "iopub.status.busy": "2023-10-15T15:22:52.064491Z",
     "iopub.status.idle": "2023-10-15T15:23:22.479354Z",
     "shell.execute_reply": "2023-10-15T15:23:22.478339Z"
    },
    "papermill": {
     "duration": 30.446582,
     "end_time": "2023-10-15T15:23:22.497114",
     "exception": false,
     "start_time": "2023-10-15T15:22:52.050532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21251</th>\n",
       "      <td>3022139</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23033</th>\n",
       "      <td>3023921</td>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24815</th>\n",
       "      <td>3025703</td>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26597</th>\n",
       "      <td>3027485</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28379</th>\n",
       "      <td>3029267</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        date  store_nbr   family  sales  onpromotion\n",
       "21251  3022139  2017-08-27         54  SEAFOOD    NaN            0\n",
       "23033  3023921  2017-08-28         54  SEAFOOD    NaN            0\n",
       "24815  3025703  2017-08-29         54  SEAFOOD    NaN            0\n",
       "26597  3027485  2017-08-30         54  SEAFOOD    NaN            0\n",
       "28379  3029267  2017-08-31         54  SEAFOOD    NaN            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:27<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "df_promotion = pd.concat([df_train, df_test], axis=0)\n",
    "df_promotion = df_promotion.sort_values([\"store_nbr\",\"family\",\"date\"])\n",
    "display(df_promotion.tail())\n",
    "\n",
    "family_promotion_dict = {}\n",
    "\n",
    "for family in tqdm(family_list):\n",
    "    df_family = df_promotion.loc[df_promotion['family'] == family]\n",
    "\n",
    "    list_of_TS_promo = TimeSeries.from_group_dataframe(\n",
    "                                df_family,\n",
    "                                time_col=\"date\",\n",
    "                                group_cols=[\"store_nbr\",\"family\"],\n",
    "                                value_cols=\"onpromotion\",\n",
    "                                fill_missing_dates=True,\n",
    "                                freq='D')\n",
    "\n",
    "    for ts in list_of_TS_promo:\n",
    "        ts = ts.astype(np.float32)\n",
    "\n",
    "    family_promotion_dict[family] = list_of_TS_promo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "390ab652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:23:22.527540Z",
     "iopub.status.busy": "2023-10-15T15:23:22.526981Z",
     "iopub.status.idle": "2023-10-15T15:24:34.189944Z",
     "shell.execute_reply": "2023-10-15T15:24:34.188641Z"
    },
    "papermill": {
     "duration": 71.680326,
     "end_time": "2023-10-15T15:24:34.191983",
     "exception": false,
     "start_time": "2023-10-15T15:23:22.511657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:11<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "promotion_transformed_dict = {}\n",
    "\n",
    "for key in tqdm(family_promotion_dict):\n",
    "    promo_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Fill NAs\")\n",
    "    promo_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaling\")\n",
    "\n",
    "    promo_pipeline = Pipeline([promo_filler,\n",
    "                             promo_scaler])\n",
    "\n",
    "    promotion_transformed = promo_pipeline.fit_transform(family_promotion_dict[key])\n",
    "\n",
    "    # Moving Averages for Promotion Family Dictionaries\n",
    "    promo_moving_average_7 = MovingAverageFilter(window=7)\n",
    "    promo_moving_average_28 = MovingAverageFilter(window=28)\n",
    "\n",
    "    promotion_covs = []\n",
    "\n",
    "    for ts in promotion_transformed:\n",
    "        ma_7 = promo_moving_average_7.filter(ts)\n",
    "        ma_7 = TimeSeries.from_series(ma_7.pd_series())  \n",
    "        ma_7 = ma_7.astype(np.float32)\n",
    "        ma_7 = ma_7.with_columns_renamed(col_names=ma_7.components, col_names_new=\"promotion_ma_7\")\n",
    "        ma_28 = promo_moving_average_28.filter(ts)\n",
    "        ma_28 = TimeSeries.from_series(ma_28.pd_series())  \n",
    "        ma_28 = ma_28.astype(np.float32)\n",
    "        ma_28 = ma_28.with_columns_renamed(col_names=ma_28.components, col_names_new=\"promotion_ma_28\")\n",
    "        promo_and_mas = ts.stack(ma_7).stack(ma_28)\n",
    "        promotion_covs.append(promo_and_mas)\n",
    "\n",
    "    promotion_transformed_dict[key] = promotion_covs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "525d8602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:24:34.226412Z",
     "iopub.status.busy": "2023-10-15T15:24:34.225961Z",
     "iopub.status.idle": "2023-10-15T15:24:34.238539Z",
     "shell.execute_reply": "2023-10-15T15:24:34.237350Z"
    },
    "papermill": {
     "duration": 0.032708,
     "end_time": "2023-10-15T15:24:34.241161",
     "exception": false,
     "start_time": "2023-10-15T15:24:34.208453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "general_covariates = time_cov_transformed.stack(oil_transformed).stack(oil_moving_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9dd1a9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:24:34.275363Z",
     "iopub.status.busy": "2023-10-15T15:24:34.274961Z",
     "iopub.status.idle": "2023-10-15T15:24:34.401105Z",
     "shell.execute_reply": "2023-10-15T15:24:34.400031Z"
    },
    "papermill": {
     "duration": 0.146417,
     "end_time": "2023-10-15T15:24:34.403721",
     "exception": false,
     "start_time": "2023-10-15T15:24:34.257304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "store_covariates_future = []\n",
    "\n",
    "for store in range(0,len(store_list)):\n",
    "    stacked_covariates = holidays_transformed[store].stack(general_covariates)  \n",
    "    store_covariates_future.append(stacked_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c88fd51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:24:34.437589Z",
     "iopub.status.busy": "2023-10-15T15:24:34.437159Z",
     "iopub.status.idle": "2023-10-15T15:24:39.781973Z",
     "shell.execute_reply": "2023-10-15T15:24:39.780462Z"
    },
    "papermill": {
     "duration": 5.36459,
     "end_time": "2023-10-15T15:24:39.784349",
     "exception": false,
     "start_time": "2023-10-15T15:24:34.419759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:05<00:00,  6.18it/s]\n"
     ]
    }
   ],
   "source": [
    "future_covariates_dict = {}\n",
    "\n",
    "for key in tqdm(promotion_transformed_dict):\n",
    "    promotion_family = promotion_transformed_dict[key]\n",
    "    covariates_future = [promotion_family[i].stack(store_covariates_future[i]) for i in range(0,len(promotion_family))]\n",
    "    future_covariates_dict[key] = covariates_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4db71876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:24:39.823741Z",
     "iopub.status.busy": "2023-10-15T15:24:39.823295Z",
     "iopub.status.idle": "2023-10-15T15:24:41.644505Z",
     "shell.execute_reply": "2023-10-15T15:24:41.643375Z"
    },
    "papermill": {
     "duration": 1.844468,
     "end_time": "2023-10-15T15:24:41.647019",
     "exception": false,
     "start_time": "2023-10-15T15:24:39.802551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_transactions.sort_values(['store_nbr','date'], inplace= True)\n",
    "\n",
    "TS_transactions_list = TimeSeries.from_group_dataframe(\n",
    "                                df_transactions,\n",
    "                                time_col=\"date\",\n",
    "                                group_cols=[\"store_nbr\"],\n",
    "                                value_cols=\"transactions\",\n",
    "                                fill_missing_dates=True,\n",
    "                                freq='D')\n",
    "\n",
    "transactions_list = []\n",
    "\n",
    "for ts in TS_transactions_list:\n",
    "            series = TimeSeries.from_series(ts.pd_series())\n",
    "            series = series.astype(np.float32)\n",
    "            transactions_list.append(series)\n",
    "            \n",
    "# as the transactions dataframe have for store_nbr 24 transactions from 01-01-2013 but every store_nbr have data from 02-01-2013\n",
    "transactions_list[24] = transactions_list[24].slice(start_ts=pd.Timestamp('20130102'), end_ts=pd.Timestamp('20170815'))\n",
    "\n",
    "transactions_list_full = []\n",
    "for ts in transactions_list:\n",
    "    if ts.start_time() > pd.Timestamp('20130101'):\n",
    "        end_time = (ts.start_time() - timedelta(days=1))\n",
    "        delta = end_time - pd.Timestamp('20130101')\n",
    "        zero_series = TimeSeries.from_times_and_values(\n",
    "                                  times=pd.date_range(start=pd.Timestamp('20130101'), \n",
    "                                  end=end_time, freq=\"D\"),\n",
    "                                  values=np.zeros(delta.days+1))\n",
    "        ts = zero_series.append(ts)\n",
    "        ts = ts.with_columns_renamed(col_names=ts.components, col_names_new=\"transactions\")\n",
    "        transactions_list_full.append(ts)\n",
    "\n",
    "transactions_filler = MissingValuesFiller(verbose=False, n_jobs=-1, name=\"Filler\")\n",
    "transactions_scaler = Scaler(verbose=False, n_jobs=-1, name=\"Scaler\")\n",
    "\n",
    "transactions_pipeline = Pipeline([transactions_filler, transactions_scaler])\n",
    "transactions_transformed = transactions_pipeline.fit_transform(transactions_list_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95bbb714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:24:41.685341Z",
     "iopub.status.busy": "2023-10-15T15:24:41.684997Z",
     "iopub.status.idle": "2023-10-15T15:24:43.429474Z",
     "shell.execute_reply": "2023-10-15T15:24:43.428419Z"
    },
    "papermill": {
     "duration": 1.766431,
     "end_time": "2023-10-15T15:24:43.431782",
     "exception": false,
     "start_time": "2023-10-15T15:24:41.665351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_indexes = pd.concat([df_train, df_test])\n",
    "df_indexes = df_indexes.drop(['onpromotion'], axis=1)\n",
    "df_indexes = df_indexes.sort_values(by=['store_nbr', 'family'])\n",
    "df_indexes.date = pd.to_datetime(df_indexes.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df1f49db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:24:43.468306Z",
     "iopub.status.busy": "2023-10-15T15:24:43.467976Z",
     "iopub.status.idle": "2023-10-15T15:24:43.546774Z",
     "shell.execute_reply": "2023-10-15T15:24:43.545734Z"
    },
    "papermill": {
     "duration": 0.099701,
     "end_time": "2023-10-15T15:24:43.549135",
     "exception": false,
     "start_time": "2023-10-15T15:24:43.449434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_indexes = df_indexes.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09fcf62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:24:43.586267Z",
     "iopub.status.busy": "2023-10-15T15:24:43.585846Z",
     "iopub.status.idle": "2023-10-15T15:33:27.201901Z",
     "shell.execute_reply": "2023-10-15T15:33:27.200753Z"
    },
    "papermill": {
     "duration": 523.637339,
     "end_time": "2023-10-15T15:33:27.204262",
     "exception": false,
     "start_time": "2023-10-15T15:24:43.566923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [08:43<00:00, 15.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>1782.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>3564.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>5346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>7128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>3022139.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>3023921.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>3025703.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>3027485.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>3029267.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3031104 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  store_nbr      family  sales\n",
       "2013-01-01        0.0        1.0  AUTOMOTIVE    0.0\n",
       "2013-01-02     1782.0        1.0  AUTOMOTIVE    2.0\n",
       "2013-01-03     3564.0        1.0  AUTOMOTIVE    3.0\n",
       "2013-01-04     5346.0        1.0  AUTOMOTIVE    3.0\n",
       "2013-01-05     7128.0        1.0  AUTOMOTIVE    5.0\n",
       "...               ...        ...         ...    ...\n",
       "2017-08-27  3022139.0       54.0     SEAFOOD    NaN\n",
       "2017-08-28  3023921.0       54.0     SEAFOOD    NaN\n",
       "2017-08-29  3025703.0       54.0     SEAFOOD    NaN\n",
       "2017-08-30  3027485.0       54.0     SEAFOOD    NaN\n",
       "2017-08-31  3029267.0       54.0     SEAFOOD    NaN\n",
       "\n",
       "[3031104 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range = pd.date_range(start=df_indexes.index.min(), end=df_indexes.index.max(), freq='D')\n",
    "df_indexes_filled = pd.DataFrame(columns=df_indexes.columns)\n",
    "\n",
    "for family in tqdm(family_list):\n",
    "    for store in store_list:\n",
    "        temp_df = df_indexes.iloc[np.where((df_indexes.family == family) & (df_indexes.store_nbr == store))]\n",
    "        temp_df = temp_df.reindex(date_range).fillna({'id': np.nan, 'store_nbr': store, 'family': family, 'sales': np.nan})\n",
    "        df_indexes_filled = pd.concat([df_indexes, temp_df])\n",
    "        \n",
    "df_indexes_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb362093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:33:27.249086Z",
     "iopub.status.busy": "2023-10-15T15:33:27.247551Z",
     "iopub.status.idle": "2023-10-15T15:33:29.120824Z",
     "shell.execute_reply": "2023-10-15T15:33:29.119777Z"
    },
    "papermill": {
     "duration": 1.896842,
     "end_time": "2023-10-15T15:33:29.122864",
     "exception": false,
     "start_time": "2023-10-15T15:33:27.226022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1782.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>3564.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>5346.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>7128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029399</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>3029267.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3029758</th>\n",
       "      <td>2013-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030123</th>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030488</th>\n",
       "      <td>2015-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030854</th>\n",
       "      <td>2016-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3029404 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date         id  store_nbr      family  sales\n",
       "0       2013-01-01        0.0        1.0  AUTOMOTIVE    0.0\n",
       "1       2013-01-02     1782.0        1.0  AUTOMOTIVE    2.0\n",
       "2       2013-01-03     3564.0        1.0  AUTOMOTIVE    3.0\n",
       "3       2013-01-04     5346.0        1.0  AUTOMOTIVE    3.0\n",
       "4       2013-01-05     7128.0        1.0  AUTOMOTIVE    5.0\n",
       "...            ...        ...        ...         ...    ...\n",
       "3029399 2017-08-31  3029267.0       54.0     SEAFOOD    NaN\n",
       "3029758 2013-12-25        NaN       54.0     SEAFOOD    NaN\n",
       "3030123 2014-12-25        NaN       54.0     SEAFOOD    NaN\n",
       "3030488 2015-12-25        NaN       54.0     SEAFOOD    NaN\n",
       "3030854 2016-12-25        NaN       54.0     SEAFOOD    NaN\n",
       "\n",
       "[3029404 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indexes_filled.index.name = 'date'\n",
    "df_indexes_filled = df_indexes_filled.reset_index()\n",
    "df_indexes_filled = df_indexes_filled.sort_values(['store_nbr','family'])\n",
    "df_indexes_filled = df_indexes_filled.drop_duplicates()\n",
    "df_indexes_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9370292e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:33:29.164105Z",
     "iopub.status.busy": "2023-10-15T15:33:29.163771Z",
     "iopub.status.idle": "2023-10-15T15:33:29.356760Z",
     "shell.execute_reply": "2023-10-15T15:33:29.355647Z"
    },
    "papermill": {
     "duration": 0.216402,
     "end_time": "2023-10-15T15:33:29.359158",
     "exception": false,
     "start_time": "2023-10-15T15:33:29.142756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_train_date = pd.to_datetime(df_train.date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05e953ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:33:29.401598Z",
     "iopub.status.busy": "2023-10-15T15:33:29.401231Z",
     "iopub.status.idle": "2023-10-15T15:33:29.406324Z",
     "shell.execute_reply": "2023-10-15T15:33:29.404934Z"
    },
    "papermill": {
     "duration": 0.028559,
     "end_time": "2023-10-15T15:33:29.408252",
     "exception": false,
     "start_time": "2023-10-15T15:33:29.379693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36b9859f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:33:29.451128Z",
     "iopub.status.busy": "2023-10-15T15:33:29.450233Z",
     "iopub.status.idle": "2023-10-15T15:33:30.855731Z",
     "shell.execute_reply": "2023-10-15T15:33:30.854490Z"
    },
    "papermill": {
     "duration": 1.42984,
     "end_time": "2023-10-15T15:33:30.858300",
     "exception": false,
     "start_time": "2023-10-15T15:33:29.428460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(df_train)\n",
    "del(df_test)\n",
    "del(df_stores)\n",
    "del(df_holidays_events)\n",
    "del(df_oil)\n",
    "del(df_transactions)\n",
    "del(df_indexes)\n",
    "del(train_merged)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "087c897f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:33:30.902336Z",
     "iopub.status.busy": "2023-10-15T15:33:30.901730Z",
     "iopub.status.idle": "2023-10-15T15:33:30.906194Z",
     "shell.execute_reply": "2023-10-15T15:33:30.905519Z"
    },
    "papermill": {
     "duration": 0.028167,
     "end_time": "2023-10-15T15:33:30.908015",
     "exception": false,
     "start_time": "2023-10-15T15:33:30.879848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from darts.models import LightGBMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbeb69b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:33:30.950638Z",
     "iopub.status.busy": "2023-10-15T15:33:30.950244Z",
     "iopub.status.idle": "2023-10-15T15:33:30.967114Z",
     "shell.execute_reply": "2023-10-15T15:33:30.965988Z"
    },
    "papermill": {
     "duration": 0.041668,
     "end_time": "2023-10-15T15:33:30.969732",
     "exception": false,
     "start_time": "2023-10-15T15:33:30.928064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lgbm_predictions(model_params, val_df_size = 0):\n",
    "    l_train_date = last_train_date - np.timedelta64(val_df_size, 'D')\n",
    "    local_df_indexes = df_indexes_filled.iloc[np.where(df_indexes_filled.date > l_train_date)]\n",
    "    \n",
    "    submission_kaggle_list = []    \n",
    "    cnt = 1\n",
    "    \n",
    "    for params in model_params:\n",
    "        LGBM_Models_Submission = {}\n",
    "        display(\"Training...\")\n",
    "            \n",
    "        # Fit Model\n",
    "        print(f'Start fit model {cnt}')\n",
    "        for family in tqdm(family_list):    \n",
    "            sales_family = family_TS_transformed_dict[family]\n",
    "            # training_data: represents the number of sales in the training sample minus the sales for the val\n",
    "            training_data = [ts[:1688-val_df_size] for ts in sales_family]\n",
    "            # TCN_covariates: represents the future covariates associated with the target product family\n",
    "            TCN_covariates = future_covariates_dict[family]\n",
    "            # train_sliced: represents the number of sales associated with the target product family.\n",
    "            # slice_intersect: function that you can see used simply ensures that the components span the same time interval. \n",
    "            # In the case of different time intervals an error message will appear if we try to combine them.\n",
    "            train_sliced = [training_data[i].slice_intersect(TCN_covariates[i]) for i in range(0,len(training_data))]\n",
    "            \n",
    "\n",
    "            LGBM_Model_Submission = LightGBMModel(lags = params[\"lags\"],\n",
    "                                                  lags_future_covariates = params[\"lags_future_covariates\"],\n",
    "                                                  lags_past_covariates = params[\"lags_past_covariates\"],\n",
    "                                                  output_chunk_length=1,\n",
    "                                                  random_state=2022,\n",
    "                                                  gpu_use_dp= \"false\")\n",
    "\n",
    "\n",
    "            LGBM_Model_Submission.fit(series=train_sliced, \n",
    "                                  future_covariates=TCN_covariates,\n",
    "                                  # transactions_transformed: the past covariates do not need to be indexed on the target \n",
    "                                  # family because there is only one global `TimeSeries` per store.\n",
    "                                  past_covariates=transactions_transformed)\n",
    "\n",
    "            LGBM_Models_Submission[family] = LGBM_Model_Submission\n",
    "\n",
    "        display(\"Predictions...\")\n",
    "        LGBM_Forecasts_Families_Submission = {}\n",
    "\n",
    "        # Predict\n",
    "        print(f'Start predict model {cnt}')\n",
    "        for family in tqdm(family_list):\n",
    "            sales_family = family_TS_transformed_dict[family]\n",
    "            training_data = [ts[:1688-val_df_size] for ts in sales_family]\n",
    "            LGBM_covariates = future_covariates_dict[family]\n",
    "            train_sliced = [training_data[i].slice_intersect(TCN_covariates[i]) for i in range(0,len(training_data))]\n",
    "\n",
    "            forecast_LGBM = LGBM_Models_Submission[family].predict(\n",
    "                                                  n = 16 + val_df_size,\n",
    "                                                  series=train_sliced,\n",
    "                                                  future_covariates=LGBM_covariates,\n",
    "                                                  past_covariates=transactions_transformed\n",
    "                                                 )\n",
    "\n",
    "            LGBM_Forecasts_Families_Submission[family] = forecast_LGBM\n",
    "\n",
    "        # Transform Back\n",
    "        print(f'Start transform Back {cnt}')\n",
    "        LGBM_Forecasts_Families_back_Submission = {}\n",
    "\n",
    "        for family in tqdm(family_list):\n",
    "            LGBM_Forecasts_Families_back_Submission[family] = family_pipeline_dict[family].inverse_transform(LGBM_Forecasts_Families_Submission[family], partial=True)\n",
    "        print(f'Start Prepare Submission {cnt}')\n",
    "        for family in tqdm(LGBM_Forecasts_Families_back_Submission):\n",
    "            for n in range(0,len(LGBM_Forecasts_Families_back_Submission[family])):\n",
    "                if (family_TS_dict[family][n].univariate_values()[-21:] == 0).all():\n",
    "                    LGBM_Forecasts_Families_back_Submission[family][n] = LGBM_Forecasts_Families_back_Submission[family][n].map(lambda x: x * 0)\n",
    "\n",
    "        listofseries = []\n",
    "\n",
    "        for store in tqdm(range(0,54)):\n",
    "            for family in family_list:\n",
    "                oneforecast = LGBM_Forecasts_Families_back_Submission[family][store].pd_dataframe()\n",
    "                oneforecast.columns = ['y_pred']\n",
    "                listofseries.append(oneforecast)\n",
    "\n",
    "        df_forecasts = pd.concat(listofseries) \n",
    "        df_forecasts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # No Negative Forecasts\n",
    "        print(f'Start No Negative Forecasts {cnt}')\n",
    "        df_forecasts[df_forecasts < 0] = 0\n",
    "        forecasts_kaggle = pd.concat([local_df_indexes['id'], df_forecasts.set_index(local_df_indexes.index)], axis=1)\n",
    "        forecasts_kaggle = forecasts_kaggle.reset_index(drop=True)\n",
    "\n",
    "        # Submission\n",
    "        print(f'Start Submission {cnt}')\n",
    "        submission_kaggle_list.append(forecasts_kaggle)\n",
    "        cnt += 1\n",
    "    \n",
    "    return submission_kaggle_list, local_df_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b1be95e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:33:31.021775Z",
     "iopub.status.busy": "2023-10-15T15:33:31.021338Z",
     "iopub.status.idle": "2023-10-15T15:33:31.029522Z",
     "shell.execute_reply": "2023-10-15T15:33:31.028617Z"
    },
    "papermill": {
     "duration": 0.041193,
     "end_time": "2023-10-15T15:33:31.031539",
     "exception": false,
     "start_time": "2023-10-15T15:33:30.990346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = [\n",
    "    {\"lags\" : 63, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]},\n",
    "    {\"lags\" : 7, \"lags_future_covariates\" : (16,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]},  \n",
    "    {\"lags\" : 31, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]},\n",
    "    {\"lags\" : 365, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]}, \n",
    "    {\"lags\" : 730, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]}, \n",
    "    {\"lags\" : 1095, \"lags_future_covariates\" : (14,1), \"lags_past_covariates\" : [-16,-17,-18,-19,-20,-21,-22]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4778918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T15:33:31.075284Z",
     "iopub.status.busy": "2023-10-15T15:33:31.074863Z",
     "iopub.status.idle": "2023-10-15T16:32:40.267117Z",
     "shell.execute_reply": "2023-10-15T16:32:40.265418Z"
    },
    "papermill": {
     "duration": 3549.217569,
     "end_time": "2023-10-15T16:32:40.269665",
     "exception": false,
     "start_time": "2023-10-15T15:33:31.052096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fit model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [05:11<00:00,  9.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predictions...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predict model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:24<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start transform Back 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:30<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Prepare Submission 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 45.74it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 63.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start No Negative Forecasts 1\n",
      "Start Submission 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fit model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [04:34<00:00,  8.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predictions...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predict model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:20<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start transform Back 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:23<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Prepare Submission 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 48.83it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 66.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start No Negative Forecasts 2\n",
      "Start Submission 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fit model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [04:32<00:00,  8.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predictions...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predict model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:23<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start transform Back 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Prepare Submission 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 47.89it/s]\n",
      "100%|██████████| 54/54 [00:01<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start No Negative Forecasts 3\n",
      "Start Submission 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fit model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [10:29<00:00, 19.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predictions...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predict model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:23<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start transform Back 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:29<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Prepare Submission 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 46.90it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 62.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start No Negative Forecasts 4\n",
      "Start Submission 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fit model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [14:14<00:00, 25.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predictions...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predict model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:24<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start transform Back 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:29<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Prepare Submission 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:00<00:00, 49.65it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 63.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start No Negative Forecasts 5\n",
      "Start Submission 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fit model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [14:49<00:00, 26.96s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predictions...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predict model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:24<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start transform Back 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:27<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Prepare Submission 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:02<00:00, 16.24it/s]\n",
      "100%|██████████| 54/54 [00:00<00:00, 62.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start No Negative Forecasts 6\n",
      "Start Submission 6\n"
     ]
    }
   ],
   "source": [
    "submission_kaggle_list, clipped_indexes = lgbm_predictions(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8ba4db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T16:32:40.392648Z",
     "iopub.status.busy": "2023-10-15T16:32:40.392226Z",
     "iopub.status.idle": "2023-10-15T16:32:40.427199Z",
     "shell.execute_reply": "2023-10-15T16:32:40.426096Z"
    },
    "papermill": {
     "duration": 0.09847,
     "end_time": "2023-10-15T16:32:40.429179",
     "exception": false,
     "start_time": "2023-10-15T16:32:40.330709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y_pred_0</th>\n",
       "      <th>y_pred_1</th>\n",
       "      <th>y_pred_2</th>\n",
       "      <th>y_pred_3</th>\n",
       "      <th>y_pred_4</th>\n",
       "      <th>y_pred_5</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888.0</td>\n",
       "      <td>3.466254</td>\n",
       "      <td>3.328092</td>\n",
       "      <td>3.507580</td>\n",
       "      <td>3.068898</td>\n",
       "      <td>3.731862</td>\n",
       "      <td>4.001414</td>\n",
       "      <td>3.517350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3002670.0</td>\n",
       "      <td>2.890935</td>\n",
       "      <td>2.603473</td>\n",
       "      <td>3.216886</td>\n",
       "      <td>3.253258</td>\n",
       "      <td>3.681850</td>\n",
       "      <td>4.065727</td>\n",
       "      <td>3.285355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3004452.0</td>\n",
       "      <td>3.972446</td>\n",
       "      <td>2.813861</td>\n",
       "      <td>4.004264</td>\n",
       "      <td>3.852360</td>\n",
       "      <td>3.615720</td>\n",
       "      <td>2.842600</td>\n",
       "      <td>3.516875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3006234.0</td>\n",
       "      <td>5.056782</td>\n",
       "      <td>3.124398</td>\n",
       "      <td>5.022578</td>\n",
       "      <td>4.502551</td>\n",
       "      <td>5.044515</td>\n",
       "      <td>4.717491</td>\n",
       "      <td>4.578052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3008016.0</td>\n",
       "      <td>1.801655</td>\n",
       "      <td>1.053930</td>\n",
       "      <td>1.463690</td>\n",
       "      <td>1.787588</td>\n",
       "      <td>2.311553</td>\n",
       "      <td>2.026005</td>\n",
       "      <td>1.740737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  y_pred_0  y_pred_1  y_pred_2  y_pred_3  y_pred_4  y_pred_5  \\\n",
       "0  3000888.0  3.466254  3.328092  3.507580  3.068898  3.731862  4.001414   \n",
       "1  3002670.0  2.890935  2.603473  3.216886  3.253258  3.681850  4.065727   \n",
       "2  3004452.0  3.972446  2.813861  4.004264  3.852360  3.615720  2.842600   \n",
       "3  3006234.0  5.056782  3.124398  5.022578  4.502551  5.044515  4.717491   \n",
       "4  3008016.0  1.801655  1.053930  1.463690  1.787588  2.311553  2.026005   \n",
       "\n",
       "      sales  \n",
       "0  3.517350  \n",
       "1  3.285355  \n",
       "2  3.516875  \n",
       "3  4.578052  \n",
       "4  1.740737  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions = submission_kaggle_list[0].copy()\n",
    "submissions = submissions.rename(columns={'y_pred': 'y_pred_0'})\n",
    "\n",
    "if len(submission_kaggle_list) > 1:\n",
    "    for i in range(1, len(submission_kaggle_list)):\n",
    "        y_pred = submission_kaggle_list[i]\n",
    "        y_pred = y_pred.rename(columns={'y_pred': f'y_pred_{i}'})\n",
    "        submissions = pd.concat([submissions, y_pred.drop(['id'], axis=1)], axis=1)\n",
    "\n",
    "submissions['sales'] = submissions.loc[:, submissions.columns!='id'].mean(axis=1)\n",
    "submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "063bcd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T16:32:40.550276Z",
     "iopub.status.busy": "2023-10-15T16:32:40.549869Z",
     "iopub.status.idle": "2023-10-15T16:32:40.567763Z",
     "shell.execute_reply": "2023-10-15T16:32:40.566495Z"
    },
    "papermill": {
     "duration": 0.081073,
     "end_time": "2023-10-15T16:32:40.569890",
     "exception": false,
     "start_time": "2023-10-15T16:32:40.488817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>3.517350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3000889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3000890</td>\n",
       "      <td>4.315871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2288.981609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3000892</td>\n",
       "      <td>0.031684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        sales\n",
       "0   3000888     3.517350\n",
       "16  3000889     0.000000\n",
       "32  3000890     4.315871\n",
       "48  3000891  2288.981609\n",
       "64  3000892     0.031684"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = submissions[['id', 'sales']]\n",
    "submission = submission.sort_values('id')\n",
    "submission.id = submission.id.astype('int32')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebe16d5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T16:32:40.763046Z",
     "iopub.status.busy": "2023-10-15T16:32:40.762656Z",
     "iopub.status.idle": "2023-10-15T16:32:40.848458Z",
     "shell.execute_reply": "2023-10-15T16:32:40.847077Z"
    },
    "papermill": {
     "duration": 0.150679,
     "end_time": "2023-10-15T16:32:40.851854",
     "exception": false,
     "start_time": "2023-10-15T16:32:40.701175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33bcf58",
   "metadata": {
    "papermill": {
     "duration": 0.064752,
     "end_time": "2023-10-15T16:32:40.982364",
     "exception": false,
     "start_time": "2023-10-15T16:32:40.917612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4325.715068,
   "end_time": "2023-10-15T16:32:43.989742",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-15T15:20:38.274674",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
