{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026757,
     "end_time": "2021-01-08T21:24:25.184555",
     "exception": false,
     "start_time": "2021-01-08T21:24:25.157798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kickoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:24:25.243297Z",
     "iopub.status.busy": "2021-01-08T21:24:25.242223Z",
     "iopub.status.idle": "2021-01-08T21:24:25.244730Z",
     "shell.execute_reply": "2021-01-08T21:24:25.245346Z"
    },
    "papermill": {
     "duration": 0.03612,
     "end_time": "2021-01-08T21:24:25.245516",
     "exception": false,
     "start_time": "2021-01-08T21:24:25.209396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresh = 0.125 # threshold of initial predictions\n",
    "num_thresh = 3 # number of prediction required to be used for final output\n",
    "step = 30\n",
    "\n",
    "nmin = 10\n",
    "nmax = 2000 # Higher recall\n",
    "\n",
    "IMSIZE = 1024\n",
    "prediou = 0.55 # use qishen's value\n",
    "\n",
    "fastcommit = True # if true, uses a shortened inference for commit.\n",
    "\n",
    "# Detection models\n",
    "check_end = \"../input/nfleffdetmodel/effdet4-end-1024-epoch8.bin\"\n",
    "check_side = \"../input/nfleffdetmodel/best-side-1024-effdet4-epoch6.bin\"\n",
    "\n",
    "# Classification models\n",
    "checkpoint_classification_128_0 = \"../input/classification-nfl/resnet3d_128_mixup_all_epoch6_fold0.pth\"\n",
    "checkpoint_classification_128_1 = \"../input/classification-nfl/resnet3d_128_mixup_all_epoch7_fold0.pth\"\n",
    "checkpoint_classification_128_2 = \"../input/classification-nfl/resnet3d_128_mixup_all_epoch8_fold0.pth\"\n",
    "checkpoint_classification_128_3 = \"../input/classification-nfl/res3d-ishigamifold.pth\"\n",
    "checkpoint_classification_96_0 = \"../input/nfl-classification-models/res3d_ishigamisplit_96x96_best.pth\"\n",
    "checkpoint_classification_96_1 = \"../input/nfl-classification-models/res3d_96x96_ishigamisplit_last.pth\"\n",
    "checkpoint_classification_96_2 = \"../input/nfl-classification-models/mc3_96x96_ishigamisplit_last.pth\"\n",
    "checkpoint_classification_96_3 = \"../input/nfl-classification-models/mc3_96x96_ishigamisplit_best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:24:25.299036Z",
     "iopub.status.busy": "2021-01-08T21:24:25.298261Z",
     "iopub.status.idle": "2021-01-08T21:24:25.304932Z",
     "shell.execute_reply": "2021-01-08T21:24:25.304148Z"
    },
    "papermill": {
     "duration": 0.035491,
     "end_time": "2021-01-08T21:24:25.305049",
     "exception": false,
     "start_time": "2021-01-08T21:24:25.269558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SubmissionかCommit時かどうか存在するファイル名を見て確認する。commit時ならば高速化のために俵さんのデータセットを読みに行く。\n",
    "import os\n",
    "if os.path.exists(\"../input/nfl-impact-detection/test/57906_000718_Endzone.mp4\"):\n",
    "    commit = True\n",
    "else:\n",
    "    commit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-01-08T21:24:25.363153Z",
     "iopub.status.busy": "2021-01-08T21:24:25.362150Z",
     "iopub.status.idle": "2021-01-08T21:24:57.420604Z",
     "shell.execute_reply": "2021-01-08T21:24:57.421259Z"
    },
    "papermill": {
     "duration": 32.092064,
     "end_time": "2021-01-08T21:24:57.421443",
     "exception": false,
     "start_time": "2021-01-08T21:24:25.329379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/nfl-lib/timm-0.1.26-py3-none-any.whl\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.1.26) (0.7.0)\r\n",
      "Requirement already satisfied: torch>=1.0 in /opt/conda/lib/python3.7/site-packages (from timm==0.1.26) (1.6.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.1.26) (1.18.5)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.1.26) (8.0.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.0->timm==0.1.26) (0.18.2)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.1.26\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/nfl-lib/timm-0.1.26-py3-none-any.whl\n",
    "!tar xfz ../input/nfl-lib/pkgs.tgz\n",
    "# for pytorch1.6\n",
    "cmd = \"sed -i -e 's/ \\/ / \\/\\/ /' timm-efficientdet-pytorch/effdet/bench.py\"\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:24:57.493633Z",
     "iopub.status.busy": "2021-01-08T21:24:57.489817Z",
     "iopub.status.idle": "2021-01-08T21:25:02.768791Z",
     "shell.execute_reply": "2021-01-08T21:25:02.767491Z"
    },
    "incorrectly_encoded_metadata": "_kg_hide-input=true _kg_hide-output=true",
    "papermill": {
     "duration": 5.319707,
     "end_time": "2021-01-08T21:25:02.768943",
     "exception": false,
     "start_time": "2021-01-08T21:24:57.449236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"timm-efficientdet-pytorch\")\n",
    "sys.path.insert(0, \"../input/ttach-kaggle/ttach\")\n",
    "sys.path.insert(0, \"omegaconf\")\n",
    "sys.path.insert(0, \"../input/odachkaggle/ODA-Object-Detection-ttA-main\")\n",
    "import odach as oda\n",
    "import ttach as tta\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import gc\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchEval\n",
    "from effdet.efficientdet import HeadNet\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:02.838661Z",
     "iopub.status.busy": "2021-01-08T21:25:02.836721Z",
     "iopub.status.idle": "2021-01-08T21:25:02.839436Z",
     "shell.execute_reply": "2021-01-08T21:25:02.839990Z"
    },
    "papermill": {
     "duration": 0.043898,
     "end_time": "2021-01-08T21:25:02.840150",
     "exception": false,
     "start_time": "2021-01-08T21:25:02.796252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mk_images(video_name, video_labels, video_dir, out_dir, only_with_impact=True):\n",
    "    video_path=f\"{video_dir}/{video_name}\"\n",
    "    video_name = os.path.basename(video_path)\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    if only_with_impact:\n",
    "        boxes_all = video_labels.query(\"video == @video_name\")\n",
    "        print(video_path, boxes_all[boxes_all.impact == 1.0].shape[0])\n",
    "    else:\n",
    "        print(video_path)\n",
    "    frame = 0\n",
    "    while True:\n",
    "        it_worked, img = vidcap.read()\n",
    "        if not it_worked:\n",
    "            break\n",
    "        frame += 1\n",
    "        if only_with_impact:\n",
    "            boxes = video_labels.query(\"video == @video_name and frame == @frame\")\n",
    "            boxes_with_impact = boxes[boxes.impact == 1.0]\n",
    "            if boxes_with_impact.shape[0] == 0:\n",
    "                continue\n",
    "        img_name = f\"{video_name}_frame{frame}\"\n",
    "        image_path = f'{out_dir}/{video_name}'.replace('.mp4',f'_{str(frame).zfill(3)}.png')\n",
    "        _ = cv2.imwrite(image_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:02.907460Z",
     "iopub.status.busy": "2021-01-08T21:25:02.906434Z",
     "iopub.status.idle": "2021-01-08T21:25:02.920095Z",
     "shell.execute_reply": "2021-01-08T21:25:02.919287Z"
    },
    "papermill": {
     "duration": 0.052674,
     "end_time": "2021-01-08T21:25:02.920254",
     "exception": false,
     "start_time": "2021-01-08T21:25:02.867580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['57906_000718_Endzone.mp4', '57906_000718_Sideline.mp4', '57995_000109_Endzone.mp4', '57995_000109_Sideline.mp4', '58102_002798_Endzone.mp4', '58102_002798_Sideline.mp4']\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT_PATH = 'test_images'\n",
    "# Use dataset if in commitmode to save GPU\n",
    "if commit:\n",
    "    DATA_ROOT_PATH= \"../input/nfl-impact-detection-train-frames\"\n",
    "out_dir = DATA_ROOT_PATH\n",
    "\n",
    "video_dir = '/kaggle/input/nfl-impact-detection/test'\n",
    "uniq_video = sorted([path.split('/')[-1] for path in glob(f'{video_dir}/*.mp4')])\n",
    "print(uniq_video)\n",
    "\n",
    "# Generate images if in Test mode\n",
    "if not os.path.exists(out_dir):\n",
    "    !mkdir -p $out_dir\n",
    "    for video_name in uniq_video:\n",
    "        mk_images(video_name, pd.DataFrame(), video_dir, out_dir, only_with_impact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:02.983331Z",
     "iopub.status.busy": "2021-01-08T21:25:02.982429Z",
     "iopub.status.idle": "2021-01-08T21:25:02.987112Z",
     "shell.execute_reply": "2021-01-08T21:25:02.986509Z"
    },
    "papermill": {
     "duration": 0.038468,
     "end_time": "2021-01-08T21:25:02.987236",
     "exception": false,
     "start_time": "2021-01-08T21:25:02.948768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.Resize(height=IMSIZE, width=IMSIZE, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:03.057488Z",
     "iopub.status.busy": "2021-01-08T21:25:03.056428Z",
     "iopub.status.idle": "2021-01-08T21:25:03.059405Z",
     "shell.execute_reply": "2021-01-08T21:25:03.059941Z"
    },
    "papermill": {
     "duration": 0.044474,
     "end_time": "2021-01-08T21:25:03.060095",
     "exception": false,
     "start_time": "2021-01-08T21:25:03.015621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, image_ids, dir=None, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.transforms = transforms\n",
    "        self.dir = dir\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        if not commit:\n",
    "            image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}', cv2.IMREAD_COLOR).copy().astype(np.float32)\n",
    "        else:\n",
    "            image = cv2.imread(f'{DATA_ROOT_PATH}/{self.dir}/{image_id}', cv2.IMREAD_COLOR).copy().astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "        return image, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027986,
     "end_time": "2021-01-08T21:25:03.116288",
     "exception": false,
     "start_time": "2021-01-08T21:25:03.088302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## make classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:03.189329Z",
     "iopub.status.busy": "2021-01-08T21:25:03.188056Z",
     "iopub.status.idle": "2021-01-08T21:25:03.191771Z",
     "shell.execute_reply": "2021-01-08T21:25:03.191191Z"
    },
    "papermill": {
     "duration": 0.047333,
     "end_time": "2021-01-08T21:25:03.192122",
     "exception": false,
     "start_time": "2021-01-08T21:25:03.144789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "\n",
    "def load_classification_model(ckpt_path: str):\n",
    "    if \"mc3\" in ckpt_path:\n",
    "        model = torchvision.models.video.mc3_18(pretrained=False)\n",
    "    else:\n",
    "        model = torchvision.models.video.r3d_18(pretrained=False)\n",
    "    model.fc = torch.nn.Linear(512, 1)\n",
    "    \n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    if \"model_state_dict\" in ckpt.keys():\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(ckpt)\n",
    "    model.to(\"cuda\").eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:03.260388Z",
     "iopub.status.busy": "2021-01-08T21:25:03.259502Z",
     "iopub.status.idle": "2021-01-08T21:25:25.833966Z",
     "shell.execute_reply": "2021-01-08T21:25:25.833270Z"
    },
    "papermill": {
     "duration": 22.613137,
     "end_time": "2021-01-08T21:25:25.834109",
     "exception": false,
     "start_time": "2021-01-08T21:25:03.220972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan  8 21:25:25 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    34W / 250W |   1651MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "model_128_0 = load_classification_model(checkpoint_classification_128_0)\n",
    "model_128_1 = load_classification_model(checkpoint_classification_128_1)\n",
    "model_128_2 = load_classification_model(checkpoint_classification_128_2)\n",
    "model_128_3 = load_classification_model(checkpoint_classification_128_3)\n",
    "model_96_0 = load_classification_model(checkpoint_classification_96_0)\n",
    "model_96_1 = load_classification_model(checkpoint_classification_96_1)\n",
    "model_96_2 = load_classification_model(checkpoint_classification_96_2)\n",
    "model_96_3 = load_classification_model(checkpoint_classification_96_3)\n",
    "\n",
    "models_128 = [model_128_0, model_128_1, model_128_2, model_128_3]\n",
    "models_96 = []\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029558,
     "end_time": "2021-01-08T21:25:25.893054",
     "exception": false,
     "start_time": "2021-01-08T21:25:25.863496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## detector misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:25.978567Z",
     "iopub.status.busy": "2021-01-08T21:25:25.977449Z",
     "iopub.status.idle": "2021-01-08T21:25:36.133410Z",
     "shell.execute_reply": "2021-01-08T21:25:36.132586Z"
    },
    "papermill": {
     "duration": 10.211187,
     "end_time": "2021-01-08T21:25:36.133552",
     "exception": false,
     "start_time": "2021-01-08T21:25:25.922365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    if \"effdet4\"in checkpoint_path:\n",
    "        config = get_efficientdet_config('tf_efficientdet_d4')\n",
    "    else:\n",
    "        config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    config.num_classes = 2\n",
    "    config.image_size=IMSIZE\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval();\n",
    "    return net.cuda()\n",
    "\n",
    "netend = load_net(check_end)\n",
    "netside = load_net(check_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:36.211812Z",
     "iopub.status.busy": "2021-01-08T21:25:36.209595Z",
     "iopub.status.idle": "2021-01-08T21:25:36.212569Z",
     "shell.execute_reply": "2021-01-08T21:25:36.213174Z"
    },
    "papermill": {
     "duration": 0.048868,
     "end_time": "2021-01-08T21:25:36.213321",
     "exception": false,
     "start_time": "2021-01-08T21:25:36.164453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(A, B) -> float:\n",
    "    xA = max(A[0], B[0])\n",
    "    yA = max(A[1], B[1])\n",
    "    xB = min(A[2], B[2])\n",
    "    yB = min(A[3], B[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    if interArea == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth rectangles\n",
    "    boxAArea = (A[2] - A[0]) * (A[3] - A[1])\n",
    "    boxBArea = (B[2] - B[0]) * (B[3] - B[1])\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "def df2box(df):\n",
    "    return np.array([df[\"x\"],df[\"y\"],df[\"w\"]+df[\"x\"],df[\"h\"]+df[\"y\"]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:36.296254Z",
     "iopub.status.busy": "2021-01-08T21:25:36.294116Z",
     "iopub.status.idle": "2021-01-08T21:25:36.297228Z",
     "shell.execute_reply": "2021-01-08T21:25:36.297843Z"
    },
    "papermill": {
     "duration": 0.054926,
     "end_time": "2021-01-08T21:25:36.298025",
     "exception": false,
     "start_time": "2021-01-08T21:25:36.243099",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions(images, net, score_threshold=0.1):\n",
    "    images = torch.stack(images).cuda().float()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "            scores = det[i].detach().cpu().numpy()[:,4]\n",
    "            labels = det[i].detach().cpu().numpy()[:,5]\n",
    "            indexes = np.where((scores > score_threshold)*(labels==2))[0]\n",
    "            #boxes = boxes[indexes]\n",
    "            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "            predictions.append({\n",
    "                'boxes': boxes[indexes],\n",
    "                'scores': scores[indexes],\n",
    "                'labels': labels[indexes],\n",
    "            })\n",
    "    return [predictions]\n",
    "\n",
    "from odach.wbf import *\n",
    "def run_wbf(predictions, image_index, image_size=IMSIZE, iou_thr=prediou, skip_box_thr=thresh, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    \n",
    "    labels = [prediction[image_index]['labels'].tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    \n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030893,
     "end_time": "2021-01-08T21:25:36.358966",
     "exception": false,
     "start_time": "2021-01-08T21:25:36.328073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## filter functions.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:36.433114Z",
     "iopub.status.busy": "2021-01-08T21:25:36.432006Z",
     "iopub.status.idle": "2021-01-08T21:25:36.435802Z",
     "shell.execute_reply": "2021-01-08T21:25:36.435209Z"
    },
    "papermill": {
     "duration": 0.045785,
     "end_time": "2021-01-08T21:25:36.435924",
     "exception": false,
     "start_time": "2021-01-08T21:25:36.390139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_match(boxes_list, new_box, idx, target_iou):\n",
    "    best_index = []\n",
    "    for i in range(len(boxes_list)):\n",
    "        box = boxes_list[i]\n",
    "\n",
    "        iou = bb_intersection_over_union(box, new_box)\n",
    "        if iou > target_iou:\n",
    "            best_index.append(idx[i])\n",
    "\n",
    "    return best_index\n",
    "\n",
    "def find_matching_box(boxes_list, new_box, idx, target_iou):\n",
    "    best_index = []\n",
    "    for i in range(len(boxes_list)):\n",
    "        box = boxes_list[i]\n",
    "\n",
    "        iou = bb_intersection_over_union(box, new_box)\n",
    "        if iou > target_iou:\n",
    "            best_index.append(idx[i])\n",
    "\n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030574,
     "end_time": "2021-01-08T21:25:36.497142",
     "exception": false,
     "start_time": "2021-01-08T21:25:36.466568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1st stage: Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:36.587816Z",
     "iopub.status.busy": "2021-01-08T21:25:36.577460Z",
     "iopub.status.idle": "2021-01-08T21:25:36.594050Z",
     "shell.execute_reply": "2021-01-08T21:25:36.593461Z"
    },
    "papermill": {
     "duration": 0.066384,
     "end_time": "2021-01-08T21:25:36.594194",
     "exception": false,
     "start_time": "2021-01-08T21:25:36.527810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(imgs, net, dir=None):\n",
    "    \n",
    "    dataset = DatasetRetriever(\n",
    "    image_ids=imgs,\n",
    "    dir=dir,\n",
    "    transforms=get_valid_transforms()\n",
    "    )\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        return tuple(zip(*batch))\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        drop_last=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    result_image_ids = []\n",
    "    results_boxes = []\n",
    "    results_scores = []\n",
    "    results_frames = []\n",
    "    cnt = 0\n",
    "    # Inference!\n",
    "    for images, image_ids in data_loader:\n",
    "        predictions = make_predictions(images, net)\n",
    "        for i, image in enumerate(images):\n",
    "            box_list, score_list, label_list = run_wbf(predictions, image_index=i, skip_box_thr=thresh)\n",
    "            boxes = box_list\n",
    "            scores = score_list\n",
    "            image_id = image_ids[i]\n",
    "            boxes[:, 0] = (boxes[:, 0] * 1280 / IMSIZE)\n",
    "            boxes[:, 1] = (boxes[:, 1] * 720 / IMSIZE)\n",
    "            boxes[:, 2] = (boxes[:, 2] * 1280 / IMSIZE)\n",
    "            boxes[:, 3] = (boxes[:, 3] * 720 / IMSIZE)\n",
    "            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "            boxes = boxes.astype(np.int32)\n",
    "            boxes[:, 0] = boxes[:, 0].clip(min=0, max=1280-1)\n",
    "            boxes[:, 2] = boxes[:, 2].clip(min=0, max=1280-1)\n",
    "            boxes[:, 1] = boxes[:, 1].clip(min=0, max=720-1)\n",
    "            boxes[:, 3] = boxes[:, 3].clip(min=0, max=720-1)\n",
    "            result_image_ids += [image_id]*len(boxes)\n",
    "            results_boxes.append(boxes)\n",
    "            results_scores.append(scores)\n",
    "            cnt+=1\n",
    "    \n",
    "    box_df = pd.DataFrame(np.concatenate(results_boxes), columns=['x', 'y', 'w', 'h'])\n",
    "    test_df = pd.DataFrame({'scores':np.concatenate(results_scores), 'image_name':result_image_ids})\n",
    "    test_df = pd.concat([test_df, box_df], axis=1)\n",
    "    test_df['frame'] = test_df.image_name.str.split('_').str[3].str.replace('.png','').astype(int)\n",
    "    test_df['gameKey'] = test_df.image_name.str.split('_').str[0].astype(int)\n",
    "    test_df['playID'] = test_df.image_name.str.split('_').str[1].astype(int)\n",
    "    test_df['view'] = test_df.image_name.str.split('_').str[2]\n",
    "    test_df['frame'] = test_df.image_name.str.split('_').str[3].str.replace('.png','').astype(int)\n",
    "    test_df['video'] = test_df.image_name.str.rsplit('_',1).str[0] + '.mp4'\n",
    "    test_df.sort_values('frame', inplace=True)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:25:36.685044Z",
     "iopub.status.busy": "2021-01-08T21:25:36.679870Z",
     "iopub.status.idle": "2021-01-08T21:27:19.698532Z",
     "shell.execute_reply": "2021-01-08T21:27:19.699134Z"
    },
    "papermill": {
     "duration": 103.074968,
     "end_time": "2021-01-08T21:27:19.699308",
     "exception": false,
     "start_time": "2021-01-08T21:25:36.624340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['57906_000718_Endzone.mp4', '57906_000718_Sideline.mp4']\n",
      "videoend:57906_000718_Endzone.mp4, videoside:57906_000718_Sideline.mp4\n",
      "../input/nfl-impact-detection-train-frames/57906_000718_Endzone/\n",
      "end len: 1073\n",
      "../input/nfl-impact-detection-train-frames/57906_000718_Sideline/\n",
      "side len: 1375\n",
      "(1073, 5)\n",
      "                     image_name  left  top  width  height  frame\n",
      "0  57906_000718_Endzone_165.png   573  298     21      14     13\n",
      "1  57906_000718_Endzone_165.png   573  297     20      15     14\n",
      "2  57906_000718_Endzone_165.png   783  286     21      16     16\n",
      "3  57906_000718_Endzone_165.png   575  296     20      13     16\n",
      "4  57906_000718_Endzone_165.png   578  293     18      14     17\n",
      "(1375, 5)\n",
      "                      image_name  left  top  width  height  frame\n",
      "0  57906_000718_Sideline_340.png   793  365      8       9      1\n",
      "1  57906_000718_Sideline_340.png   793  373      8       8      1\n",
      "2  57906_000718_Sideline_340.png   793  373      8       8      2\n",
      "3  57906_000718_Sideline_340.png   793  365      8       9      2\n",
      "4  57906_000718_Sideline_340.png   793  373      8       8      3\n"
     ]
    }
   ],
   "source": [
    "if fastcommit and commit:\n",
    "    uniq_video = uniq_video[0:2]\n",
    "    \n",
    "print(uniq_video)\n",
    "\n",
    "for iii,videoname in enumerate(uniq_video[::2]):\n",
    "    videoend = videoname\n",
    "    videoside = videoname[:-11]+\"Sideline.mp4\"\n",
    "    print(\"videoend:{}, videoside:{}\".format(videoend, videoside))\n",
    "    \n",
    "    ######################################\n",
    "    # Inference Videos\n",
    "    ######################################\n",
    "    for phase, vid in enumerate([videoend, videoside]):\n",
    "        # clear\n",
    "        if commit:\n",
    "            print(f'{DATA_ROOT_PATH}/{vid[:-4]}/')\n",
    "            imgs = np.array([path.split('/')[-1] for path in glob(f'{DATA_ROOT_PATH}/{vid[:-4]}/*.png')])\n",
    "        else:\n",
    "            # for testmode\n",
    "            imgs = np.array([path.split('/')[-1] for path in glob(f'{DATA_ROOT_PATH}/{vid[:-4]}*.png')])\n",
    "            \n",
    "        # Get predictions\n",
    "        if phase == 0:\n",
    "            end_df = predict(imgs, netend, dir=vid[:-4])\n",
    "            print(\"end len:\", len(end_df))\n",
    "        else:\n",
    "            side_df = predict(imgs, netside, dir=vid[:-4])\n",
    "            print(\"side len:\", len(side_df))\n",
    "    \n",
    "    final_side = side_df[['x', 'y', 'w', 'h', 'frame']].values\n",
    "    final_end = end_df[['x', 'y', 'w', 'h', 'frame']].values\n",
    "    \n",
    "    # Make submission for both Side and Ends\n",
    "    for phase, final_outs in enumerate([final_end, final_side]):\n",
    "        if phase == 0:\n",
    "            result_image_ids = []\n",
    "            for i in final_outs:\n",
    "                result_image_ids.append(end_df.loc[0].image_name)\n",
    "        else:\n",
    "            result_image_ids = []\n",
    "            for i in final_outs:\n",
    "                result_image_ids.append(side_df.loc[0].image_name)\n",
    "        print(final_outs.shape)   \n",
    "\n",
    "        # make df if final_out has boxes..\n",
    "        try:\n",
    "            box_df = pd.DataFrame(final_outs[:, 0:4].astype(int), columns=['left', 'top', 'width', 'height'])\n",
    "            test_df = pd.DataFrame({'image_name':result_image_ids})\n",
    "            test_df = pd.concat([test_df, box_df], axis=1)\n",
    "            test_df['frame'] = final_outs[:,4].astype(int)\n",
    "            print(test_df.head())\n",
    "\n",
    "            #gameKey,playID,view,video,frame,left,width,top,height\n",
    "            test_df['gameKey'] = test_df.image_name.str.split('_').str[0].astype(int)\n",
    "            test_df['playID'] = test_df.image_name.str.split('_').str[1].astype(int)\n",
    "            test_df['view'] = test_df.image_name.str.split('_').str[2]\n",
    "            test_df['video'] = test_df.image_name.str.rsplit('_',1).str[0] + '.mp4'\n",
    "            test_df = test_df[[\"gameKey\",\"playID\",\"view\",\"video\",\"frame\",\"left\",\"width\",\"top\",\"height\"]]\n",
    "            # concat\n",
    "            if (iii==0) and (phase==0):\n",
    "                submit_df=test_df\n",
    "            else:\n",
    "                submit_df=pd.concat([test_df, submit_df], axis=0)\n",
    "        except:\n",
    "            # no prediction found\n",
    "            print(\"boxes not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:27:19.781333Z",
     "iopub.status.busy": "2021-01-08T21:27:19.780585Z",
     "iopub.status.idle": "2021-01-08T21:27:19.794099Z",
     "shell.execute_reply": "2021-01-08T21:27:19.794688Z"
    },
    "papermill": {
     "duration": 0.063007,
     "end_time": "2021-01-08T21:27:19.794840",
     "exception": false,
     "start_time": "2021-01-08T21:27:19.731833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameKey</th>\n",
       "      <th>playID</th>\n",
       "      <th>view</th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>left</th>\n",
       "      <th>width</th>\n",
       "      <th>top</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>793</td>\n",
       "      <td>8</td>\n",
       "      <td>365</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>793</td>\n",
       "      <td>8</td>\n",
       "      <td>373</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>793</td>\n",
       "      <td>8</td>\n",
       "      <td>373</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>793</td>\n",
       "      <td>8</td>\n",
       "      <td>365</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>793</td>\n",
       "      <td>8</td>\n",
       "      <td>373</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Endzone</td>\n",
       "      <td>57906_000718_Endzone.mp4</td>\n",
       "      <td>405</td>\n",
       "      <td>227</td>\n",
       "      <td>20</td>\n",
       "      <td>529</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Endzone</td>\n",
       "      <td>57906_000718_Endzone.mp4</td>\n",
       "      <td>406</td>\n",
       "      <td>226</td>\n",
       "      <td>20</td>\n",
       "      <td>528</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Endzone</td>\n",
       "      <td>57906_000718_Endzone.mp4</td>\n",
       "      <td>406</td>\n",
       "      <td>226</td>\n",
       "      <td>18</td>\n",
       "      <td>527</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Endzone</td>\n",
       "      <td>57906_000718_Endzone.mp4</td>\n",
       "      <td>407</td>\n",
       "      <td>224</td>\n",
       "      <td>20</td>\n",
       "      <td>527</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Endzone</td>\n",
       "      <td>57906_000718_Endzone.mp4</td>\n",
       "      <td>408</td>\n",
       "      <td>223</td>\n",
       "      <td>21</td>\n",
       "      <td>526</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2448 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gameKey  playID      view                      video  frame  left  \\\n",
       "0       57906     718  Sideline  57906_000718_Sideline.mp4      1   793   \n",
       "1       57906     718  Sideline  57906_000718_Sideline.mp4      1   793   \n",
       "2       57906     718  Sideline  57906_000718_Sideline.mp4      2   793   \n",
       "3       57906     718  Sideline  57906_000718_Sideline.mp4      2   793   \n",
       "4       57906     718  Sideline  57906_000718_Sideline.mp4      3   793   \n",
       "...       ...     ...       ...                        ...    ...   ...   \n",
       "1068    57906     718   Endzone   57906_000718_Endzone.mp4    405   227   \n",
       "1069    57906     718   Endzone   57906_000718_Endzone.mp4    406   226   \n",
       "1070    57906     718   Endzone   57906_000718_Endzone.mp4    406   226   \n",
       "1071    57906     718   Endzone   57906_000718_Endzone.mp4    407   224   \n",
       "1072    57906     718   Endzone   57906_000718_Endzone.mp4    408   223   \n",
       "\n",
       "      width  top  height  \n",
       "0         8  365       9  \n",
       "1         8  373       8  \n",
       "2         8  373       8  \n",
       "3         8  365       9  \n",
       "4         8  373       8  \n",
       "...     ...  ...     ...  \n",
       "1068     20  529      28  \n",
       "1069     20  528      28  \n",
       "1070     18  527      17  \n",
       "1071     20  527      27  \n",
       "1072     21  526      28  \n",
       "\n",
       "[2448 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032558,
     "end_time": "2021-01-08T21:27:19.860031",
     "exception": false,
     "start_time": "2021-01-08T21:27:19.827473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2nd Stage: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:27:19.945947Z",
     "iopub.status.busy": "2021-01-08T21:27:19.944832Z",
     "iopub.status.idle": "2021-01-08T21:27:19.947541Z",
     "shell.execute_reply": "2021-01-08T21:27:19.948112Z"
    },
    "papermill": {
     "duration": 0.055265,
     "end_time": "2021-01-08T21:27:19.948269",
     "exception": false,
     "start_time": "2021-01-08T21:27:19.893004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_ops(positive_df):\n",
    "    # New Post-Processing Function!\n",
    "    start = positive_df[\"frame\"].min()\n",
    "    end = positive_df[\"frame\"].max()\n",
    "    step = 30\n",
    "    target_iou = 0.25\n",
    "\n",
    "    boxes = positive_df[['x', 'y', 'w', 'h', 'frame']].values\n",
    "    boxes[:,2] = boxes[:,0] + boxes[:,2]\n",
    "    boxes[:,3] = boxes[:,1] + boxes[:,3]\n",
    "    keep = np.ones(len(boxes))\n",
    "    idx = np.array(range(len(boxes)))\n",
    "\n",
    "    outs = []\n",
    "    \n",
    "    # Time-nms\n",
    "    for t in np.arange(start, end, step):\n",
    "        keys = (boxes[:,4]>=t)*((boxes[:,4]<=t+step)*(keep==1))\n",
    "        loop_boxes_init = boxes[keys]\n",
    "        loop_boxes = loop_boxes_init\n",
    "        loop_idx = idx[keys]\n",
    "\n",
    "        for box in loop_boxes_init:\n",
    "            # Find box that overlaps with box\n",
    "            hits = find_matching_box(loop_boxes, box, loop_idx, target_iou)\n",
    "            keep[hits] = 0\n",
    "            outs.append(hits)\n",
    "            # Remove the hit boxes from loop_boxes\n",
    "            keys = (boxes[:,4]>=t)*((boxes[:,4]<=t+step)*(keep==1))\n",
    "            loop_boxes = boxes[keys]\n",
    "            loop_idx = idx[keys]\n",
    "\n",
    "    # filter outputs by nms\n",
    "    choose_centerframe = False\n",
    "    final_outs = []\n",
    "    for out in outs:\n",
    "        if len(out)>=num_thresh: # threshold of detection num!\n",
    "            box = boxes[out]\n",
    "            o = np.array(np.median(box, axis=0))\n",
    "            # TODO: 最もスコアが高いものを選択\n",
    "            final_outs.append(o)\n",
    "    return np.array(final_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:27:20.046531Z",
     "iopub.status.busy": "2021-01-08T21:27:20.045394Z",
     "iopub.status.idle": "2021-01-08T21:27:20.047880Z",
     "shell.execute_reply": "2021-01-08T21:27:20.048421Z"
    },
    "papermill": {
     "duration": 0.066459,
     "end_time": "2021-01-08T21:27:20.048563",
     "exception": false,
     "start_time": "2021-01-08T21:27:19.982104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def threshold_opt(preds_df, thresh, nmax=25, nmin=15):\n",
    "    videos = preds_df.video.unique()\n",
    "    for i,video in enumerate(videos):\n",
    "        dfs = preds_df[preds_df[\"video\"]==video].reset_index()\n",
    "        # Inference\n",
    "        val_dataset = HeadClassificationDataset(dfs, image_dir=Path(\"\"), img_size=128, transforms=get_valid_transforms(128), transforms2=get_valid_transforms(96))\n",
    "        val_loader = torchdata.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "        targets = []\n",
    "        count = 0\n",
    "        for img_128, img_96 in val_loader:\n",
    "            img_128 = img_128.to(\"cuda\")\n",
    "            img_96 = img_96.to(\"cuda\")\n",
    "            tmp = []\n",
    "            for model in models_128:\n",
    "                target = (torch.sigmoid(model(img_128)) + torch.sigmoid(model(torch.flip(img_128, [4])))) / 2\n",
    "                tmp.append(target.cpu().detach().numpy())\n",
    "\n",
    "            for model in models_96:\n",
    "                target = (torch.sigmoid(model(img_96)) + torch.sigmoid(model(torch.flip(img_96, [4])))) / 2\n",
    "                tmp.append(target.cpu().detach().numpy())\n",
    "\n",
    "            targets.append(np.mean(tmp, axis=0))\n",
    "            count += 1\n",
    "        # to array\n",
    "        ts = []\n",
    "        for t in targets:\n",
    "            ts.append(t[0])\n",
    "        targets = np.array(ts).reshape(-1)\n",
    "\n",
    "        # threshold loop\n",
    "        run_th = thresh\n",
    "        numbox = 0\n",
    "        tries = 0\n",
    "        while (numbox>nmax or numbox<nmin) and tries<=20:\n",
    "            try:\n",
    "                positive_df = dfs[targets>run_th]\n",
    "                pred = positive_df[positive_df[\"video\"]==video]\n",
    "                final_outs = filter_ops(pred)\n",
    "                numbox = len(final_outs)\n",
    "            except:\n",
    "                pass\n",
    "            if numbox>nmax:\n",
    "                run_th += 0.02\n",
    "            elif numbox<nmin:\n",
    "                run_th -= 0.02\n",
    "            tries += 1\n",
    "            \n",
    "        final_outs[:,2] = final_outs[:,2] - final_outs[:,0]\n",
    "        final_outs[:,3] = final_outs[:,3] - final_outs[:,1]\n",
    "        # to dataframe\n",
    "        box_df = pd.DataFrame(final_outs[:, 0:4].astype(int), columns=['left', 'top', 'width', 'height'])\n",
    "        test_df = pd.DataFrame({'gameKey':dfs.gameKey[:len(box_df)], \"playID\":dfs.playID[:len(box_df)], \"view\":dfs.view[:len(box_df)], \"video\":dfs.video[:len(box_df)]})\n",
    "        test_df = pd.concat([test_df, box_df], axis=1)\n",
    "        test_df['frame'] = final_outs[:,4].astype(int)\n",
    "\n",
    "        #gameKey,playID,view,video,frame,left,width,top,height\n",
    "        test_df = test_df[[\"gameKey\",\"playID\",\"view\",\"video\",\"frame\",\"left\",\"width\",\"top\",\"height\"]]\n",
    "\n",
    "        if i == 0:\n",
    "            out_df = test_df\n",
    "        else:\n",
    "            out_df = pd.concat([out_df, test_df], axis=0)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:27:20.145910Z",
     "iopub.status.busy": "2021-01-08T21:27:20.140755Z",
     "iopub.status.idle": "2021-01-08T21:27:20.158423Z",
     "shell.execute_reply": "2021-01-08T21:27:20.157871Z"
    },
    "papermill": {
     "duration": 0.076506,
     "end_time": "2021-01-08T21:27:20.158541",
     "exception": false,
     "start_time": "2021-01-08T21:27:20.082035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as torchdata\n",
    "from pathlib import Path\n",
    "class HeadClassificationDataset(torchdata.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, image_dir: Path, img_size=128, transforms=None, transforms2=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.transforms2 = transforms2\n",
    "        self.img_size = img_size\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.df.loc[idx, :]\n",
    "        x, y, w, h,frame = sample.x, sample.y, sample.w, sample.h, sample.frame\n",
    "        #x = x + (np.random.randn(1)).astype(int)\n",
    "        #y = y + (np.random.randn(1)).astype(int)\n",
    "        #w = w + (np.random.randn(1)*2).astype(int)\n",
    "        #h = h + (np.random.randn(1)*2).astype(int)\n",
    "        image_id = sample.video[:-4]\n",
    "        vid = sample.video\n",
    "        frame_idx = sample.frame\n",
    "        prefix = image_id\n",
    "        if commit:\n",
    "            image_dir = Path(f\"{DATA_ROOT_PATH}/{vid[:-4]}/\")\n",
    "        else:\n",
    "            # for testmode\n",
    "            image_dir = Path(f\"{DATA_ROOT_PATH}\")\n",
    "        try:\n",
    "            all_images = []\n",
    "            for frame_diff in [-4, -3, -2, -1, 0, 1, 2, 3, 4]:\n",
    "                image_id = prefix + '_' + str(frame_idx+frame_diff).zfill(3) + '.png'\n",
    "                image = cv2.imread(str(image_dir / image_id))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0))\n",
    "                all_images.append(image)\n",
    "        except:\n",
    "            print(\"oops\")\n",
    "            all_images = []\n",
    "            for frame_diff in [-0, -0, -0, -0, 0, 0, 0, 0, 0]:                    \n",
    "                image_id = prefix + '_' + str(frame_idx+frame_diff).zfill(3) + '.png'\n",
    "                print(image_id)\n",
    "                image = cv2.imread(str(image_dir / image_id))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0))\n",
    "                all_images.append(image)\n",
    "        x, y, w, h,frame = sample.x, sample.y, sample.w, sample.h, sample.frame\n",
    "        all_images = np.concatenate(all_images, axis=2)\n",
    "        woffset = (self.img_size - w) // 2\n",
    "        hoffset = (self.img_size - h) // 2\n",
    "        left = max(x - woffset, 0)\n",
    "        right = min(left + self.img_size, all_images.shape[1])\n",
    "        top = max(y - hoffset, 0)\n",
    "        bottom = min(top + self.img_size, all_images.shape[0])\n",
    "        #print(top)\n",
    "        #print(all_images.shape)\n",
    "        cropped = all_images[top:bottom, left:right, :].astype(np.float32)\n",
    "        cropped /= 255.0\n",
    "        if self.transforms is not None:\n",
    "            cropped = self.transforms(image=cropped)[\"image\"]\n",
    "        cropped = cropped.view(9,3,self.img_size,self.img_size).transpose(1,0)\n",
    "        ### 96 IMAGES\n",
    "        woffset = (96 - w) // 2\n",
    "        hoffset = (96 - h) // 2\n",
    "        left = max(x - woffset, 0)\n",
    "        right = min(left + 96, all_images.shape[1])\n",
    "        top = max(y - hoffset, 0)\n",
    "        bottom = min(top + 96, all_images.shape[0])\n",
    "        #print(top)\n",
    "        #print(all_images.shape)\n",
    "        cropped2 = all_images[top:bottom, left:right, :].astype(np.float32)\n",
    "        cropped2 /= 255.0\n",
    "        if self.transforms2 is not None:\n",
    "            cropped2 = self.transforms2(image=cropped2)[\"image\"]\n",
    "        cropped2 = cropped2.view(9, 3, 96, 96).transpose(1,0)\n",
    "        return cropped, cropped2\n",
    "\n",
    "def get_valid_transforms(img_size=128):\n",
    "    return A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size, p=1),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:27:20.236232Z",
     "iopub.status.busy": "2021-01-08T21:27:20.234571Z",
     "iopub.status.idle": "2021-01-08T21:27:20.239051Z",
     "shell.execute_reply": "2021-01-08T21:27:20.238522Z"
    },
    "papermill": {
     "duration": 0.048698,
     "end_time": "2021-01-08T21:27:20.239173",
     "exception": false,
     "start_time": "2021-01-08T21:27:20.190475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_df[\"x\"] = submit_df[\"left\"]\n",
    "submit_df[\"y\"] = submit_df[\"top\"]\n",
    "submit_df[\"w\"] = submit_df[\"width\"]\n",
    "submit_df[\"h\"] = submit_df[\"height\"]\n",
    "\n",
    "submit_df = submit_df[submit_df[\"frame\"]>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:27:20.315330Z",
     "iopub.status.busy": "2021-01-08T21:27:20.313987Z",
     "iopub.status.idle": "2021-01-08T21:39:07.243823Z",
     "shell.execute_reply": "2021-01-08T21:39:07.242861Z"
    },
    "papermill": {
     "duration": 706.971591,
     "end_time": "2021-01-08T21:39:07.243984",
     "exception": false,
     "start_time": "2021-01-08T21:27:20.272393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oops\n",
      "57906_000718_Sideline_440.png\n",
      "57906_000718_Sideline_440.png\n",
      "57906_000718_Sideline_440.png\n",
      "57906_000718_Sideline_440.png\n",
      "57906_000718_Sideline_440.png\n",
      "57906_000718_Sideline_440.png\n",
      "oops\n",
      "57906_000718_Sideline_439.png\n",
      "57906_000718_Sideline_440.png\n",
      "57906_000718_Sideline_439.png\n",
      "57906_000718_Sideline_440.png\n",
      "57906_000718_Sideline_440.png\n",
      "57906_000718_Sideline_439.png\n",
      "57906_000718_Sideline_439.png\n",
      "57906_000718_Sideline_439.png\n",
      "57906_000718_Sideline_439.png\n",
      "57906_000718_Sideline_439.png\n",
      "57906_000718_Sideline_439.png\n",
      "57906_000718_Sideline_439.png\n",
      "2438 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameKey</th>\n",
       "      <th>playID</th>\n",
       "      <th>view</th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>left</th>\n",
       "      <th>width</th>\n",
       "      <th>top</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>31</td>\n",
       "      <td>759</td>\n",
       "      <td>7</td>\n",
       "      <td>334</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>33</td>\n",
       "      <td>765</td>\n",
       "      <td>8</td>\n",
       "      <td>333</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>31</td>\n",
       "      <td>773</td>\n",
       "      <td>7</td>\n",
       "      <td>332</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>36</td>\n",
       "      <td>760</td>\n",
       "      <td>6</td>\n",
       "      <td>331</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>33</td>\n",
       "      <td>767</td>\n",
       "      <td>6</td>\n",
       "      <td>332</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gameKey  playID      view                      video  frame  left  width  \\\n",
       "0    57906     718  Sideline  57906_000718_Sideline.mp4     31   759      7   \n",
       "1    57906     718  Sideline  57906_000718_Sideline.mp4     33   765      8   \n",
       "2    57906     718  Sideline  57906_000718_Sideline.mp4     31   773      7   \n",
       "3    57906     718  Sideline  57906_000718_Sideline.mp4     36   760      6   \n",
       "4    57906     718  Sideline  57906_000718_Sideline.mp4     33   767      6   \n",
       "\n",
       "   top  height  \n",
       "0  334       7  \n",
       "1  333       9  \n",
       "2  332       9  \n",
       "3  331       5  \n",
       "4  332       5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df2 = threshold_opt(submit_df, 0.9, nmax=25, nmin=15)\n",
    "print(len(submit_df), len(submit_df2))\n",
    "submit_df2.reset_index(inplace=True, drop=True)\n",
    "submit_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:39:07.388036Z",
     "iopub.status.busy": "2021-01-08T21:39:07.387057Z",
     "iopub.status.idle": "2021-01-08T21:39:07.395246Z",
     "shell.execute_reply": "2021-01-08T21:39:07.396455Z"
    },
    "papermill": {
     "duration": 0.090111,
     "end_time": "2021-01-08T21:39:07.396685",
     "exception": false,
     "start_time": "2021-01-08T21:39:07.306574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameKey</th>\n",
       "      <th>playID</th>\n",
       "      <th>view</th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>left</th>\n",
       "      <th>width</th>\n",
       "      <th>top</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>31</td>\n",
       "      <td>759</td>\n",
       "      <td>7</td>\n",
       "      <td>334</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>33</td>\n",
       "      <td>765</td>\n",
       "      <td>8</td>\n",
       "      <td>333</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>31</td>\n",
       "      <td>773</td>\n",
       "      <td>7</td>\n",
       "      <td>332</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>36</td>\n",
       "      <td>760</td>\n",
       "      <td>6</td>\n",
       "      <td>331</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57906</td>\n",
       "      <td>718</td>\n",
       "      <td>Sideline</td>\n",
       "      <td>57906_000718_Sideline.mp4</td>\n",
       "      <td>33</td>\n",
       "      <td>767</td>\n",
       "      <td>6</td>\n",
       "      <td>332</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gameKey  playID      view                      video  frame  left  width  \\\n",
       "0    57906     718  Sideline  57906_000718_Sideline.mp4     31   759      7   \n",
       "1    57906     718  Sideline  57906_000718_Sideline.mp4     33   765      8   \n",
       "2    57906     718  Sideline  57906_000718_Sideline.mp4     31   773      7   \n",
       "3    57906     718  Sideline  57906_000718_Sideline.mp4     36   760      6   \n",
       "4    57906     718  Sideline  57906_000718_Sideline.mp4     33   767      6   \n",
       "\n",
       "   top  height  \n",
       "0  334       7  \n",
       "1  333       9  \n",
       "2  332       9  \n",
       "3  331       5  \n",
       "4  332       5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:39:07.538033Z",
     "iopub.status.busy": "2021-01-08T21:39:07.537053Z",
     "iopub.status.idle": "2021-01-08T21:39:08.346789Z",
     "shell.execute_reply": "2021-01-08T21:39:08.346169Z"
    },
    "papermill": {
     "duration": 0.885627,
     "end_time": "2021-01-08T21:39:08.346938",
     "exception": false,
     "start_time": "2021-01-08T21:39:07.461311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clearing working dir\n",
    "# be careful when running this code on local environment!\n",
    "# !rm -rf *\n",
    "!mv * /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-08T21:39:08.440995Z",
     "iopub.status.busy": "2021-01-08T21:39:08.440082Z",
     "iopub.status.idle": "2021-01-08T21:39:08.947707Z",
     "shell.execute_reply": "2021-01-08T21:39:08.946733Z"
    },
    "papermill": {
     "duration": 0.556999,
     "end_time": "2021-01-08T21:39:08.947845",
     "exception": false,
     "start_time": "2021-01-08T21:39:08.390846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nflimpact\n",
    "env = nflimpact.make_env()\n",
    "env.predict(submit_df2) # df is a pandas dataframe of your entire submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.043052,
     "end_time": "2021-01-08T21:39:09.035295",
     "exception": false,
     "start_time": "2021-01-08T21:39:08.992243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 890.537968,
   "end_time": "2021-01-08T21:39:10.627949",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-08T21:24:20.089981",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
