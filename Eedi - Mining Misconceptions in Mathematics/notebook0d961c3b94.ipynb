{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49d367c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:53:03.514122Z",
     "iopub.status.busy": "2024-12-12T14:53:03.513873Z",
     "iopub.status.idle": "2024-12-12T14:56:28.617065Z",
     "shell.execute_reply": "2024-12-12T14:56:28.615614Z"
    },
    "papermill": {
     "duration": 205.114318,
     "end_time": "2024-12-12T14:56:28.620336",
     "exception": false,
     "start_time": "2024-12-12T14:53:03.506018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/logits-processor-zoo/logits_processor_zoo-0.1.0-py3-none-any.whl\r\n",
      "Installing collected packages: logits-processor-zoo\r\n",
      "Successfully installed logits-processor-zoo-0.1.0\r\n",
      "CPU times: user 2.08 s, sys: 532 ms, total: 2.62 s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python -m pip install -q --no-index --find-links=/kaggle/input/eedi-dependencies/dependencies-tv/ -r /kaggle/input/eedi-dependencies/requirements-tv.txt\n",
    "!python -m pip install -q --no-index --find-links=/kaggle/input/eedi-dependencies/dependencies-vllm/ -r /kaggle/input/eedi-dependencies/requirements-vllm.txt\n",
    "!pip install --no-deps --no-index /kaggle/input/logits-processor-zoo/logits_processor_zoo-0.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e4dd7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:56:28.642622Z",
     "iopub.status.busy": "2024-12-12T14:56:28.642287Z",
     "iopub.status.idle": "2024-12-12T14:57:17.266791Z",
     "shell.execute_reply": "2024-12-12T14:57:17.265722Z"
    },
    "papermill": {
     "duration": 48.644651,
     "end_time": "2024-12-12T14:57:17.276061",
     "exception": false,
     "start_time": "2024-12-12T14:56:28.631410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./AutoAWQ\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.7.post2) (2.4.0)\r\n",
      "Requirement already satisfied: triton in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.7.post2) (3.0.0)\r\n",
      "Requirement already satisfied: transformers>=4.35.0 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.7.post2) (4.46.2)\r\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.7.post2) (0.20.3)\r\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.7.post2) (4.12.2)\r\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.7.post2) (0.34.2)\r\n",
      "Requirement already satisfied: datasets>=2.20 in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.7.post2) (3.0.1)\r\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from autoawq==0.2.7.post2) (0.23.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (3.15.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (17.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (4.66.4)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.20->autoawq==0.2.7.post2) (2024.6.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (3.9.5)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (0.26.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.20->autoawq==0.2.7.post2) (6.0.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (3.1.4)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.4.0->autoawq==0.2.7.post2) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->autoawq==0.2.7.post2) (12.6.85)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.7.post2) (2024.5.15)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.0->autoawq==0.2.7.post2) (0.4.5)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->autoawq==0.2.7.post2) (5.9.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.7.post2) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.7.post2) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.7.post2) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.7.post2) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.7.post2) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.20->autoawq==0.2.7.post2) (4.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets>=2.20->autoawq==0.2.7.post2) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.20->autoawq==0.2.7.post2) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.20->autoawq==0.2.7.post2) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.20->autoawq==0.2.7.post2) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.20->autoawq==0.2.7.post2) (2024.6.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->autoawq==0.2.7.post2) (2.1.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.20->autoawq==0.2.7.post2) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.20->autoawq==0.2.7.post2) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.20->autoawq==0.2.7.post2) (2024.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.4.0->autoawq==0.2.7.post2) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.20->autoawq==0.2.7.post2) (1.16.0)\r\n",
      "Building wheels for collected packages: autoawq\r\n",
      "  Building wheel for autoawq (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for autoawq: filename=autoawq-0.2.7.post2-py3-none-any.whl size=106958 sha256=33abab1f20c6977409eb47935bcaf5c5d71c84ba345f4f2f93533fdc3927f7e1\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ishw80iq/wheels/e1/d4/ec/8ae90063250f3f09fc58d9ea8b2026549874540925fa9ed089\r\n",
      "Successfully built autoawq\r\n",
      "Installing collected packages: autoawq\r\n",
      "Successfully installed autoawq-0.2.7.post2\r\n",
      "CPU times: user 447 ms, sys: 136 ms, total: 582 ms\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!cp -r /kaggle/input/eedi-dependencies/AutoAWQ ./AutoAWQ\n",
    "!pip install ./AutoAWQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90af23e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:57:17.291858Z",
     "iopub.status.busy": "2024-12-12T14:57:17.291573Z",
     "iopub.status.idle": "2024-12-12T14:57:52.309062Z",
     "shell.execute_reply": "2024-12-12T14:57:52.308217Z"
    },
    "papermill": {
     "duration": 35.027962,
     "end_time": "2024-12-12T14:57:52.311229",
     "exception": false,
     "start_time": "2024-12-12T14:57:17.283267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-ignite                           0.5.1\r\n",
      "pytorch-lightning                        2.4.0\r\n",
      "torch                                    2.4.0\r\n",
      "torchaudio                               2.4.0\r\n",
      "torchinfo                                1.8.0\r\n",
      "torchmetrics                             1.6.0\r\n",
      "torchvision                              0.19.0\r\n",
      "transformers                             4.46.2\r\n",
      "vllm                                     0.6.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -e vllm -e torch -e transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0093d50d",
   "metadata": {
    "papermill": {
     "duration": 0.00744,
     "end_time": "2024-12-12T14:57:52.326877",
     "exception": false,
     "start_time": "2024-12-12T14:57:52.319437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf57aee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:57:52.343326Z",
     "iopub.status.busy": "2024-12-12T14:57:52.342951Z",
     "iopub.status.idle": "2024-12-12T14:57:52.349989Z",
     "shell.execute_reply": "2024-12-12T14:57:52.349114Z"
    },
    "papermill": {
     "duration": 0.017101,
     "end_time": "2024-12-12T14:57:52.351569",
     "exception": false,
     "start_time": "2024-12-12T14:57:52.334468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing eedi_metrics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile eedi_metrics.py\n",
    "\n",
    "# Credit: https://www.kaggle.com/code/abdullahmeda/eedi-map-k-metric\n",
    "\n",
    "import numpy as np\n",
    "def apk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    \n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    \n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        # first condition checks whether it is valid prediction\n",
    "        # second condition checks if prediction is not repeated\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    \n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34029f76",
   "metadata": {
    "papermill": {
     "duration": 0.007186,
     "end_time": "2024-12-12T14:57:52.366037",
     "exception": false,
     "start_time": "2024-12-12T14:57:52.358851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# first retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94d7b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:57:52.381571Z",
     "iopub.status.busy": "2024-12-12T14:57:52.381343Z",
     "iopub.status.idle": "2024-12-12T14:57:55.364014Z",
     "shell.execute_reply": "2024-12-12T14:57:55.363128Z"
    },
    "papermill": {
     "duration": 2.992837,
     "end_time": "2024-12-12T14:57:55.366151",
     "exception": false,
     "start_time": "2024-12-12T14:57:52.373314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, math, numpy as np\n",
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re, gc\n",
    "import torch\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d763dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:57:55.382955Z",
     "iopub.status.busy": "2024-12-12T14:57:55.382551Z",
     "iopub.status.idle": "2024-12-12T14:57:55.443805Z",
     "shell.execute_reply": "2024-12-12T14:57:55.442906Z"
    },
    "papermill": {
     "duration": 0.071314,
     "end_time": "2024-12-12T14:57:55.445376",
     "exception": false,
     "start_time": "2024-12-12T14:57:55.374062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS_SUBMISSION: False\n"
     ]
    }
   ],
   "source": [
    "IS_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n",
    "\n",
    "\n",
    "print('IS_SUBMISSION:', IS_SUBMISSION)\n",
    "\n",
    "model_path = \"/kaggle/input/qwen2.5/transformers/32b-instruct-awq/1\"\n",
    "df_train = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\").fillna(-1).sample(10, random_state=42).reset_index(drop=True)\n",
    "df_test = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n",
    "df_misconception_mapping = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac99976f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:57:55.461440Z",
     "iopub.status.busy": "2024-12-12T14:57:55.461168Z",
     "iopub.status.idle": "2024-12-12T14:57:55.484004Z",
     "shell.execute_reply": "2024-12-12T14:57:55.483188Z"
    },
    "papermill": {
     "duration": 0.032672,
     "end_time": "2024-12-12T14:57:55.485619",
     "exception": false,
     "start_time": "2024-12-12T14:57:55.452947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>AnswerAText</th>\n",
       "      <th>AnswerBText</th>\n",
       "      <th>AnswerCText</th>\n",
       "      <th>AnswerDText</th>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <th>MisconceptionDId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700</td>\n",
       "      <td>321</td>\n",
       "      <td>Divide two decimals with the same number of de...</td>\n",
       "      <td>224</td>\n",
       "      <td>Multiplying and Dividing with Decimals</td>\n",
       "      <td>D</td>\n",
       "      <td>\\( 0.9 \\div 0.3= \\)</td>\n",
       "      <td>\\( 0.3 \\)</td>\n",
       "      <td>\\( 9.3 \\)</td>\n",
       "      <td>\\( 0.333 \\ldots \\)</td>\n",
       "      <td>\\( 3 \\)</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1488</td>\n",
       "      <td>469</td>\n",
       "      <td>Understand the notation for powers</td>\n",
       "      <td>245</td>\n",
       "      <td>Squares, Cubes, etc</td>\n",
       "      <td>C</td>\n",
       "      <td>To calculate \\( 53^{2} \\) you need to do...</td>\n",
       "      <td>\\( 53+2 \\)</td>\n",
       "      <td>\\( 53 \\times 2 \\)</td>\n",
       "      <td>\\( 53 \\times 53 \\)</td>\n",
       "      <td>\\( 532 \\times 1 \\)</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>2316.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>921</td>\n",
       "      <td>219</td>\n",
       "      <td>Round numbers to three or more decimal places</td>\n",
       "      <td>214</td>\n",
       "      <td>Rounding to Decimal Places</td>\n",
       "      <td>A</td>\n",
       "      <td>What is \\( 20.15349 \\) rounded to \\( 3 \\) deci...</td>\n",
       "      <td>\\( 20.153 \\)</td>\n",
       "      <td>\\( 20.15 \\)</td>\n",
       "      <td>\\( 20.154 \\)</td>\n",
       "      <td>\\( 20.253 \\)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275</td>\n",
       "      <td>306</td>\n",
       "      <td>Subtract decimals where the numbers involved h...</td>\n",
       "      <td>223</td>\n",
       "      <td>Adding and Subtracting with Decimals</td>\n",
       "      <td>A</td>\n",
       "      <td>\\( 50.09-0.1= \\)</td>\n",
       "      <td>\\( 49.99 \\)</td>\n",
       "      <td>\\( 50.99 \\)</td>\n",
       "      <td>\\( 50.08 \\)</td>\n",
       "      <td>\\( 38.98 \\)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>2346.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>416</td>\n",
       "      <td>703</td>\n",
       "      <td>Express pictorial representations of objects a...</td>\n",
       "      <td>334</td>\n",
       "      <td>Writing Ratios</td>\n",
       "      <td>C</td>\n",
       "      <td>Tom says for every one circle there are two sq...</td>\n",
       "      <td>Only\\nTom</td>\n",
       "      <td>Only Katie</td>\n",
       "      <td>Both Tom and Katie</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1654</td>\n",
       "      <td>1556</td>\n",
       "      <td>Given a positive x value, find the correspondi...</td>\n",
       "      <td>57</td>\n",
       "      <td>Cubics and Reciprocals</td>\n",
       "      <td>A</td>\n",
       "      <td>This is a part of the table of values for the ...</td>\n",
       "      <td>\\( 1 \\)</td>\n",
       "      <td>\\( 3 \\)</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>\\( 0 \\)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2349.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>247</td>\n",
       "      <td>71</td>\n",
       "      <td>Solve problems that combine addition and subtr...</td>\n",
       "      <td>206</td>\n",
       "      <td>Written Subtraction</td>\n",
       "      <td>B</td>\n",
       "      <td>At the start of the day, there was \\( £ 1,456 ...</td>\n",
       "      <td>\\( £ 13,180 \\)</td>\n",
       "      <td>\\( £ 4,426 \\)</td>\n",
       "      <td>\\( £ 2,970 \\)</td>\n",
       "      <td>\\( £ 10,268 \\)</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>1787.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>383</td>\n",
       "      <td>1525</td>\n",
       "      <td>Substitute positive integer values into expres...</td>\n",
       "      <td>67</td>\n",
       "      <td>Substitution into Formula</td>\n",
       "      <td>B</td>\n",
       "      <td>When \\( h=15 \\)\\n\\n\\(\\n\\frac{h}{3}=\\n\\)\\n</td>\n",
       "      <td>\\( 12 \\)</td>\n",
       "      <td>\\( 5 \\)</td>\n",
       "      <td>\\( -9 \\)</td>\n",
       "      <td>\\( -5 \\)</td>\n",
       "      <td>2093.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>322</td>\n",
       "      <td>311</td>\n",
       "      <td>Multiply a decimal by an integer</td>\n",
       "      <td>224</td>\n",
       "      <td>Multiplying and Dividing with Decimals</td>\n",
       "      <td>B</td>\n",
       "      <td>Work out:\\n\\[\\n0.3 \\times 12\\n\\]</td>\n",
       "      <td>\\( 36 \\)</td>\n",
       "      <td>\\( 3.6 \\)</td>\n",
       "      <td>\\( 0.36 \\)</td>\n",
       "      <td>\\( 0.036 \\)</td>\n",
       "      <td>189.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>2187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>203</td>\n",
       "      <td>1399</td>\n",
       "      <td>Calculate the distance between two coordinates...</td>\n",
       "      <td>410</td>\n",
       "      <td>Distance Between Two Co-ordinates</td>\n",
       "      <td>B</td>\n",
       "      <td>Mark is working out the distance between these...</td>\n",
       "      <td>Isosceles</td>\n",
       "      <td>Right-angled</td>\n",
       "      <td>Equilateral</td>\n",
       "      <td>Scalene</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1658.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  ConstructId                                      ConstructName  \\\n",
       "0        1700          321  Divide two decimals with the same number of de...   \n",
       "1        1488          469                 Understand the notation for powers   \n",
       "2         921          219      Round numbers to three or more decimal places   \n",
       "3         275          306  Subtract decimals where the numbers involved h...   \n",
       "4         416          703  Express pictorial representations of objects a...   \n",
       "5        1654         1556  Given a positive x value, find the correspondi...   \n",
       "6         247           71  Solve problems that combine addition and subtr...   \n",
       "7         383         1525  Substitute positive integer values into expres...   \n",
       "8         322          311                   Multiply a decimal by an integer   \n",
       "9         203         1399  Calculate the distance between two coordinates...   \n",
       "\n",
       "   SubjectId                             SubjectName CorrectAnswer  \\\n",
       "0        224  Multiplying and Dividing with Decimals             D   \n",
       "1        245                     Squares, Cubes, etc             C   \n",
       "2        214              Rounding to Decimal Places             A   \n",
       "3        223    Adding and Subtracting with Decimals             A   \n",
       "4        334                          Writing Ratios             C   \n",
       "5         57                  Cubics and Reciprocals             A   \n",
       "6        206                     Written Subtraction             B   \n",
       "7         67               Substitution into Formula             B   \n",
       "8        224  Multiplying and Dividing with Decimals             B   \n",
       "9        410       Distance Between Two Co-ordinates             B   \n",
       "\n",
       "                                        QuestionText     AnswerAText  \\\n",
       "0                                \\( 0.9 \\div 0.3= \\)       \\( 0.3 \\)   \n",
       "1        To calculate \\( 53^{2} \\) you need to do...      \\( 53+2 \\)   \n",
       "2  What is \\( 20.15349 \\) rounded to \\( 3 \\) deci...    \\( 20.153 \\)   \n",
       "3                                   \\( 50.09-0.1= \\)     \\( 49.99 \\)   \n",
       "4  Tom says for every one circle there are two sq...       Only\\nTom   \n",
       "5  This is a part of the table of values for the ...         \\( 1 \\)   \n",
       "6  At the start of the day, there was \\( £ 1,456 ...  \\( £ 13,180 \\)   \n",
       "7          When \\( h=15 \\)\\n\\n\\(\\n\\frac{h}{3}=\\n\\)\\n        \\( 12 \\)   \n",
       "8                   Work out:\\n\\[\\n0.3 \\times 12\\n\\]        \\( 36 \\)   \n",
       "9  Mark is working out the distance between these...       Isosceles   \n",
       "\n",
       "         AnswerBText         AnswerCText         AnswerDText  \\\n",
       "0          \\( 9.3 \\)  \\( 0.333 \\ldots \\)             \\( 3 \\)   \n",
       "1  \\( 53 \\times 2 \\)  \\( 53 \\times 53 \\)  \\( 532 \\times 1 \\)   \n",
       "2        \\( 20.15 \\)        \\( 20.154 \\)        \\( 20.253 \\)   \n",
       "3        \\( 50.99 \\)         \\( 50.08 \\)         \\( 38.98 \\)   \n",
       "4         Only Katie  Both Tom and Katie  Neither is correct   \n",
       "5            \\( 3 \\)   \\( \\frac{1}{3} \\)             \\( 0 \\)   \n",
       "6      \\( £ 4,426 \\)       \\( £ 2,970 \\)      \\( £ 10,268 \\)   \n",
       "7            \\( 5 \\)            \\( -9 \\)            \\( -5 \\)   \n",
       "8          \\( 3.6 \\)          \\( 0.36 \\)         \\( 0.036 \\)   \n",
       "9       Right-angled         Equilateral             Scalene   \n",
       "\n",
       "   MisconceptionAId  MisconceptionBId  MisconceptionCId  MisconceptionDId  \n",
       "0             153.0              -1.0            2359.0              -1.0  \n",
       "1            2445.0            2316.0              -1.0              -1.0  \n",
       "2              -1.0            2392.0            1988.0            2330.0  \n",
       "3              -1.0             699.0            2346.0              -1.0  \n",
       "4              -1.0            1846.0              -1.0            1150.0  \n",
       "5              -1.0            2349.0              -1.0             832.0  \n",
       "6            2009.0              -1.0             791.0            1787.0  \n",
       "7            2093.0              -1.0              -1.0            1648.0  \n",
       "8             189.0              -1.0            1035.0            2187.0  \n",
       "9            1658.0              -1.0            1658.0            1658.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "if not IS_SUBMISSION:\n",
    "    df_ret = df_train.copy()\n",
    "else:\n",
    "    df_ret = df_test.copy()\n",
    "\n",
    "df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc003f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:57:55.504125Z",
     "iopub.status.busy": "2024-12-12T14:57:55.503871Z",
     "iopub.status.idle": "2024-12-12T14:57:55.513349Z",
     "shell.execute_reply": "2024-12-12T14:57:55.512627Z"
    },
    "papermill": {
     "duration": 0.020959,
     "end_time": "2024-12-12T14:57:55.514873",
     "exception": false,
     "start_time": "2024-12-12T14:57:55.493914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEMPLATE_INPUT_V3 = '{QUESTION}\\nCorrect answer: {CORRECT_ANSWER}\\nStudent wrong answer: {STUDENT_WRONG_ANSWER}'\n",
    "def format_input_v3(row, wrong_choice):\n",
    "\n",
    "    assert wrong_choice in \"ABCD\"\n",
    "    # Extract values from the row\n",
    "    question_text = row.get(\"QuestionText\", \"No question text provided\")\n",
    "    subject_name = row.get(\"SubjectName\", \"Unknown subject\")\n",
    "    construct_name = row.get(\"ConstructName\", \"Unknown construct\")\n",
    "    # Extract the correct and wrong answer text based on the choice\n",
    "    correct_answer = row.get(\"CorrectAnswer\", \"Unknown\")\n",
    "    assert wrong_choice != correct_answer\n",
    "    correct_answer_text = row.get(f\"Answer{correct_answer}Text\", \"No correct answer text available\")\n",
    "    wrong_answer_text = row.get(f\"Answer{wrong_choice}Text\", \"No wrong answer text available\")\n",
    "\n",
    "    # Construct the question format\n",
    "    formatted_question = f\"\"\"Question: {question_text}\n",
    "    \n",
    "SubjectName: {subject_name}\n",
    "ConstructName: {construct_name}\"\"\"\n",
    "\n",
    "    # Return the extracted data\n",
    "    ret = {\n",
    "        \"QUESTION\": formatted_question,\n",
    "        \"CORRECT_ANSWER\": correct_answer_text,\n",
    "        \"STUDENT_WRONG_ANSWER\": wrong_answer_text,\n",
    "        \"MISCONCEPTION_ID\": row.get('Misconception{wrong_choice}Id'),\n",
    "    }\n",
    "    ret[\"PROMPT\"] = TEMPLATE_INPUT_V3.format(**ret)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "items = []\n",
    "target_ids = []\n",
    "for _, row in df_ret.iterrows():\n",
    "    for choice in ['A', 'B', 'C', 'D']:\n",
    "        if choice == row[\"CorrectAnswer\"]:\n",
    "            continue\n",
    "        if not IS_SUBMISSION and row[f'Misconception{choice}Id'] == -1:\n",
    "            continue\n",
    "            \n",
    "        correct_col = f\"Answer{row['CorrectAnswer']}Text\"\n",
    "        item = {'QuestionId_Answer': '{}_{}'.format(row['QuestionId'], choice)}\n",
    "        item['Prompt'] = format_input_v3(row, choice)['PROMPT']\n",
    "        items.append(item)\n",
    "        target_ids.append(int(row.get(f'Misconception{choice}Id', -1)))\n",
    "        \n",
    "df_input = pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c7ae1f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:57:55.531125Z",
     "iopub.status.busy": "2024-12-12T14:57:55.530904Z",
     "iopub.status.idle": "2024-12-12T14:58:06.842818Z",
     "shell.execute_reply": "2024-12-12T14:58:06.841882Z"
    },
    "papermill": {
     "duration": 11.322445,
     "end_time": "2024-12-12T14:58:06.844910",
     "exception": false,
     "start_time": "2024-12-12T14:57:55.522465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'<instruct>{task_description}\\n<query>{query}'\n",
    "\n",
    "def get_detailed_example(task_description: str, query: str, response: str) -> str:\n",
    "    return f'<instruct>{task_description}\\n<query>{query}\\n<response>{response}'\n",
    "\n",
    "def get_new_queries(queries, query_max_len, examples_prefix, tokenizer):\n",
    "    inputs = tokenizer(\n",
    "        queries,\n",
    "        max_length=query_max_len - len(tokenizer('<s>', add_special_tokens=False)['input_ids']) - len(\n",
    "            tokenizer('\\n<response></s>', add_special_tokens=False)['input_ids']),\n",
    "        return_token_type_ids=False,\n",
    "        truncation=True,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    prefix_ids = tokenizer(examples_prefix, add_special_tokens=False)['input_ids']\n",
    "    suffix_ids = tokenizer('\\n<response>', add_special_tokens=False)['input_ids']\n",
    "    new_max_length = (len(prefix_ids) + len(suffix_ids) + query_max_len + 8) // 8 * 8 + 8\n",
    "    new_queries = tokenizer.batch_decode(inputs['input_ids'])\n",
    "    for i in range(len(new_queries)):\n",
    "        new_queries[i] = examples_prefix + new_queries[i] + '\\n<response>'\n",
    "    return new_max_length, new_queries\n",
    "task =  \"Given a math multiple-choice problem with a student's wrong answer, retrieve the math misconceptions\"\n",
    "queries = [\n",
    "    get_detailed_instruct(task, q) for q in df_input['Prompt']\n",
    "]\n",
    "documents = df_misconception_mapping['MisconceptionName'].tolist()\n",
    "query_max_len, doc_max_len = 320, 48\n",
    "LORA_PATH = '/kaggle/input/2211-lora-14b/transformers/default/1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(LORA_PATH)\n",
    "examples_prefix = ''\n",
    "new_query_max_len, new_queries = get_new_queries(queries, query_max_len, examples_prefix, tokenizer)\n",
    "\n",
    "\n",
    "import json\n",
    "with open('data.json', 'w') as f:\n",
    "    data = {'texts': new_queries+ documents}\n",
    "    f.write(json.dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1545a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:58:06.862773Z",
     "iopub.status.busy": "2024-12-12T14:58:06.862265Z",
     "iopub.status.idle": "2024-12-12T14:58:06.867671Z",
     "shell.execute_reply": "2024-12-12T14:58:06.866881Z"
    },
    "papermill": {
     "duration": 0.016064,
     "end_time": "2024-12-12T14:58:06.869170",
     "exception": false,
     "start_time": "2024-12-12T14:58:06.853106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "582c12a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:58:06.886113Z",
     "iopub.status.busy": "2024-12-12T14:58:06.885852Z",
     "iopub.status.idle": "2024-12-12T14:58:06.891826Z",
     "shell.execute_reply": "2024-12-12T14:58:06.891073Z"
    },
    "papermill": {
     "duration": 0.016552,
     "end_time": "2024-12-12T14:58:06.893372",
     "exception": false,
     "start_time": "2024-12-12T14:58:06.876820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_embed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_embed.py\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import peft\n",
    "\n",
    "MAX_LENGTH = 320\n",
    "\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = attention_mask[:, -1].sum() == attention_mask.shape[0]\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[\n",
    "            torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths\n",
    "        ]\n",
    "\n",
    "\n",
    "def get_embeddings_in_batches(model, tokenizer, texts, max_length, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\"):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        batch_dict = tokenizer(\n",
    "            batch_texts,\n",
    "            max_length=max_length,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda\")\n",
    "        with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n",
    "            outputs = model(**batch_dict)\n",
    "            batch_embeddings = last_token_pool(\n",
    "                outputs.last_hidden_state, batch_dict[\"attention_mask\"]\n",
    "            )\n",
    "            batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1).cpu()\n",
    "        embeddings.append(batch_embeddings)\n",
    "    return torch.cat(embeddings, dim=0)\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(base_model_path, lora_path, load_in_4bit=True):\n",
    "    model = AutoModel.from_pretrained(\n",
    "        base_model_path,\n",
    "        device_map=0,\n",
    "        torch_dtype=torch.float16,\n",
    "        load_in_4bit=load_in_4bit,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        lora_path if lora_path else base_model_path\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    if lora_path:\n",
    "        model = peft.PeftModel.from_pretrained(model, lora_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    output_file = args.input_text.replace(\n",
    "        \".json\", \".pt.fold.{}.{}.embed\".format(*args.fold)\n",
    "    )\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Output file {output_file} already exists. Skipping...\")\n",
    "        return\n",
    "    model, tokenizer = load_model_and_tokenizer(\n",
    "        args.base_model, args.lora_path, load_in_4bit=args.load_in_4bit\n",
    "    )\n",
    "    texts = json.load(open(args.input_text))[\"texts\"][args.fold[0] :: args.fold[1]]\n",
    "    embeddings = get_embeddings_in_batches(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        texts,\n",
    "        max_length=MAX_LENGTH,\n",
    "        batch_size=4,\n",
    "    )\n",
    "    text2embeds = {text: emb for text, emb in zip(texts, embeddings)}\n",
    "    torch.save(text2embeds, output_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--base_model\",\n",
    "        type=str,\n",
    "        default=\"Qwen/Qwen2.5-7B\",\n",
    "        help=\"Path to the base model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lora_path\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Path to the LoRA model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--input_text\",\n",
    "        type=str,\n",
    "        default=\".cache/data.json\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--load_in_4bit\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Load model in 4-bit mode\",\n",
    "    )\n",
    "    parser.add_argument(\"--fold\", nargs=2, type=int, default=[0, 1])\n",
    "    args = parser.parse_args()\n",
    "    if not os.path.exists(args.lora_path):\n",
    "        args.lora_path = None\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd268226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:58:06.910389Z",
     "iopub.status.busy": "2024-12-12T14:58:06.909901Z",
     "iopub.status.idle": "2024-12-12T14:58:10.916739Z",
     "shell.execute_reply": "2024-12-12T14:58:10.915582Z"
    },
    "papermill": {
     "duration": 4.017401,
     "end_time": "2024-12-12T14:58:10.918718",
     "exception": false,
     "start_time": "2024-12-12T14:58:06.901317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!sleep 1 & sleep 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42692860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T14:58:10.936461Z",
     "iopub.status.busy": "2024-12-12T14:58:10.936136Z",
     "iopub.status.idle": "2024-12-12T15:04:42.307802Z",
     "shell.execute_reply": "2024-12-12T15:04:42.306878Z"
    },
    "papermill": {
     "duration": 391.382503,
     "end_time": "2024-12-12T15:04:42.309572",
     "exception": false,
     "start_time": "2024-12-12T14:58:10.927069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:05<00:00, 62.72s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:05<00:00, 62.89s/it]\n",
      "Embedding: 100%|██████████| 327/327 [03:25<00:00,  1.59it/s]\n",
      "Embedding: 100%|██████████| 327/327 [03:36<00:00,  1.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_path = '/kaggle/input/2211-lora-14b/transformers/default/1'\n",
    "cmd = f\"(CUDA_VISIBLE_DEVICES=0 python run_embed.py --base_model /kaggle/input/qw14b-awq/transformers/default/1 --lora_path {lora_path} --input_text data.json --fold 0 2) & (CUDA_VISIBLE_DEVICES=1 python run_embed.py --base_model /kaggle/input/qw14b-awq/transformers/default/1 --lora_path {lora_path} --input_text data.json --fold 1 2)\"\n",
    "import os\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db586a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:42.366745Z",
     "iopub.status.busy": "2024-12-12T15:04:42.366000Z",
     "iopub.status.idle": "2024-12-12T15:04:53.370960Z",
     "shell.execute_reply": "2024-12-12T15:04:53.370079Z"
    },
    "papermill": {
     "duration": 11.034928,
     "end_time": "2024-12-12T15:04:53.372999",
     "exception": false,
     "start_time": "2024-12-12T15:04:42.338071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "! sleep 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "673085b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:53.428451Z",
     "iopub.status.busy": "2024-12-12T15:04:53.428098Z",
     "iopub.status.idle": "2024-12-12T15:04:56.507125Z",
     "shell.execute_reply": "2024-12-12T15:04:56.506119Z"
    },
    "papermill": {
     "duration": 3.109036,
     "end_time": "2024-12-12T15:04:56.509263",
     "exception": false,
     "start_time": "2024-12-12T15:04:53.400227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.pt.fold.1.2.embed\n",
      "data.pt.fold.0.2.embed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3626513216.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_to_embed.update(torch.load(path))\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import time\n",
    "text_to_embed = {}\n",
    "files = glob('*.pt*')\n",
    "while len(files) != 2:\n",
    "    time.sleep(1)\n",
    "    files = glob('*.pt*')\n",
    "\n",
    "\n",
    "time.sleep(3)    \n",
    "for path in files:\n",
    "    print(path)\n",
    "    text_to_embed.update(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d411081d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:56.564794Z",
     "iopub.status.busy": "2024-12-12T15:04:56.564546Z",
     "iopub.status.idle": "2024-12-12T15:04:56.612813Z",
     "shell.execute_reply": "2024-12-12T15:04:56.612020Z"
    },
    "papermill": {
     "duration": 0.077623,
     "end_time": "2024-12-12T15:04:56.614473",
     "exception": false,
     "start_time": "2024-12-12T15:04:56.536850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 5120]), torch.Size([2587, 5120]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embeddings = torch.stack([text_to_embed[t] for t in new_queries])\n",
    "doc_embeddings = torch.stack([text_to_embed[t] for t in documents])\n",
    "query_embeddings.shape, doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3348422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:56.669483Z",
     "iopub.status.busy": "2024-12-12T15:04:56.669200Z",
     "iopub.status.idle": "2024-12-12T15:04:56.701277Z",
     "shell.execute_reply": "2024-12-12T15:04:56.700451Z"
    },
    "papermill": {
     "duration": 0.061361,
     "end_time": "2024-12-12T15:04:56.702885",
     "exception": false,
     "start_time": "2024-12-12T15:04:56.641524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>MisconceptionId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700_A</td>\n",
       "      <td>2359 151 2525 1155 1074 153 565 195 2461 1922 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700_C</td>\n",
       "      <td>2359 151 419 1155 2525 2542 1629 339 1259 58 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1488_A</td>\n",
       "      <td>948 2445 952 2175 2352 2316 1072 1337 2010 923...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1488_B</td>\n",
       "      <td>1072 2175 2316 1792 2445 948 1337 2010 1346 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>921_B</td>\n",
       "      <td>1529 2392 1248 1379 1355 1272 739 663 1742 233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>921_C</td>\n",
       "      <td>1988 322 2392 2330 1379 2412 1248 794 1449 152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>921_D</td>\n",
       "      <td>2330 1675 2392 1248 1742 1988 2412 1529 322 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>275_B</td>\n",
       "      <td>2346 496 699 2203 611 1730 1795 980 1898 467 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>275_C</td>\n",
       "      <td>2346 496 2203 90 539 1730 699 980 2044 1317 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>416_B</td>\n",
       "      <td>1846 843 1556 2373 1864 1224 473 1232 105 1895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>416_D</td>\n",
       "      <td>1846 843 1224 2373 1895 862 255 1975 142 1864 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1654_B</td>\n",
       "      <td>1933 662 136 2349 916 2547 413 176 1924 2447 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1654_D</td>\n",
       "      <td>1924 176 832 1933 385 136 1617 2093 1860 49 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>247_A</td>\n",
       "      <td>1773 2009 1514 1787 1978 791 1078 2172 1999 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>247_C</td>\n",
       "      <td>1787 791 1078 1978 2172 1999 1453 1773 2009 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>247_D</td>\n",
       "      <td>1773 2009 1787 1978 1514 791 1078 2172 1999 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>383_A</td>\n",
       "      <td>2093 1241 2273 1875 1589 934 997 1190 2274 215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>383_D</td>\n",
       "      <td>1648 2093 934 1241 1875 1800 1542 623 1589 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>322_A</td>\n",
       "      <td>2350 2055 1482 189 1035 1404 301 2335 394 2288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>322_C</td>\n",
       "      <td>1035 2187 2350 2055 394 301 2481 2288 1482 955...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>322_D</td>\n",
       "      <td>2187 1035 2350 2481 394 2335 2055 2288 189 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>203_A</td>\n",
       "      <td>1970 1658 1602 745 1813 110 1279 992 517 1176 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>203_C</td>\n",
       "      <td>1279 1658 423 1602 2467 992 110 745 1176 204 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>203_D</td>\n",
       "      <td>646 2423 204 1192 1658 1279 1097 1602 1813 213...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId_Answer                                    MisconceptionId\n",
       "0             1700_A  2359 151 2525 1155 1074 153 565 195 2461 1922 ...\n",
       "1             1700_C  2359 151 419 1155 2525 2542 1629 339 1259 58 6...\n",
       "2             1488_A  948 2445 952 2175 2352 2316 1072 1337 2010 923...\n",
       "3             1488_B  1072 2175 2316 1792 2445 948 1337 2010 1346 14...\n",
       "4              921_B  1529 2392 1248 1379 1355 1272 739 663 1742 233...\n",
       "5              921_C  1988 322 2392 2330 1379 2412 1248 794 1449 152...\n",
       "6              921_D  2330 1675 2392 1248 1742 1988 2412 1529 322 13...\n",
       "7              275_B  2346 496 699 2203 611 1730 1795 980 1898 467 1...\n",
       "8              275_C  2346 496 2203 90 539 1730 699 980 2044 1317 18...\n",
       "9              416_B  1846 843 1556 2373 1864 1224 473 1232 105 1895...\n",
       "10             416_D  1846 843 1224 2373 1895 862 255 1975 142 1864 ...\n",
       "11            1654_B  1933 662 136 2349 916 2547 413 176 1924 2447 2...\n",
       "12            1654_D  1924 176 832 1933 385 136 1617 2093 1860 49 23...\n",
       "13             247_A  1773 2009 1514 1787 1978 791 1078 2172 1999 21...\n",
       "14             247_C  1787 791 1078 1978 2172 1999 1453 1773 2009 23...\n",
       "15             247_D  1773 2009 1787 1978 1514 791 1078 2172 1999 14...\n",
       "16             383_A  2093 1241 2273 1875 1589 934 997 1190 2274 215...\n",
       "17             383_D  1648 2093 934 1241 1875 1800 1542 623 1589 155...\n",
       "18             322_A  2350 2055 1482 189 1035 1404 301 2335 394 2288...\n",
       "19             322_C  1035 2187 2350 2055 394 301 2481 2288 1482 955...\n",
       "20             322_D  2187 1035 2350 2481 394 2335 2055 2288 189 200...\n",
       "21             203_A  1970 1658 1602 745 1813 110 1279 992 517 1176 ...\n",
       "22             203_C  1279 1658 423 1602 2467 992 110 745 1176 204 1...\n",
       "23             203_D  646 2423 204 1192 1658 1279 1097 1602 1813 213..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = query_embeddings @ doc_embeddings.T  # Shape: (M, N)\n",
    "sorted_indices = torch.argsort(scores,1, descending=True)[:,:25].tolist()\n",
    "df_input[\"MisconceptionId\"] = [\" \".join([str(x) for x in row]) for row in sorted_indices]\n",
    "df_input[[\"QuestionId_Answer\", \"MisconceptionId\"]].to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "495c43b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:56.760340Z",
     "iopub.status.busy": "2024-12-12T15:04:56.760036Z",
     "iopub.status.idle": "2024-12-12T15:04:56.764636Z",
     "shell.execute_reply": "2024-12-12T15:04:56.763968Z"
    },
    "papermill": {
     "duration": 0.034143,
     "end_time": "2024-12-12T15:04:56.766126",
     "exception": false,
     "start_time": "2024-12-12T15:04:56.731983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = np.array(sorted_indices, dtype=int)\n",
    "np.save(\"indices.npy\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b269d0d",
   "metadata": {
    "papermill": {
     "duration": 0.027798,
     "end_time": "2024-12-12T15:04:56.820829",
     "exception": false,
     "start_time": "2024-12-12T15:04:56.793031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "559e08d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:56.875917Z",
     "iopub.status.busy": "2024-12-12T15:04:56.875656Z",
     "iopub.status.idle": "2024-12-12T15:04:56.913021Z",
     "shell.execute_reply": "2024-12-12T15:04:56.912170Z"
    },
    "papermill": {
     "duration": 0.066588,
     "end_time": "2024-12-12T15:04:56.914463",
     "exception": false,
     "start_time": "2024-12-12T15:04:56.847875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>incorrect_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### SubjectName: Multiplying and Dividing with...</td>\n",
       "      <td>1700_A</td>\n",
       "      <td>Divide two decimals with the same number of de...</td>\n",
       "      <td>Multiplying and Dividing with Decimals</td>\n",
       "      <td>\\( 0.9 \\div 0.3= \\)</td>\n",
       "      <td>\\( 3 \\)</td>\n",
       "      <td>\\( 0.3 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### SubjectName: Multiplying and Dividing with...</td>\n",
       "      <td>1700_C</td>\n",
       "      <td>Divide two decimals with the same number of de...</td>\n",
       "      <td>Multiplying and Dividing with Decimals</td>\n",
       "      <td>\\( 0.9 \\div 0.3= \\)</td>\n",
       "      <td>\\( 3 \\)</td>\n",
       "      <td>\\( 0.333 \\ldots \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### SubjectName: Squares, Cubes, etc\\n### Cons...</td>\n",
       "      <td>1488_A</td>\n",
       "      <td>Understand the notation for powers</td>\n",
       "      <td>Squares, Cubes, etc</td>\n",
       "      <td>To calculate \\( 53^{2} \\) you need to do...</td>\n",
       "      <td>\\( 53 \\times 53 \\)</td>\n",
       "      <td>\\( 53+2 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### SubjectName: Squares, Cubes, etc\\n### Cons...</td>\n",
       "      <td>1488_B</td>\n",
       "      <td>Understand the notation for powers</td>\n",
       "      <td>Squares, Cubes, etc</td>\n",
       "      <td>To calculate \\( 53^{2} \\) you need to do...</td>\n",
       "      <td>\\( 53 \\times 53 \\)</td>\n",
       "      <td>\\( 53 \\times 2 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### SubjectName: Rounding to Decimal Places\\n#...</td>\n",
       "      <td>921_B</td>\n",
       "      <td>Round numbers to three or more decimal places</td>\n",
       "      <td>Rounding to Decimal Places</td>\n",
       "      <td>What is \\( 20.15349 \\) rounded to \\( 3 \\) deci...</td>\n",
       "      <td>\\( 20.153 \\)</td>\n",
       "      <td>\\( 20.15 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>### SubjectName: Rounding to Decimal Places\\n#...</td>\n",
       "      <td>921_C</td>\n",
       "      <td>Round numbers to three or more decimal places</td>\n",
       "      <td>Rounding to Decimal Places</td>\n",
       "      <td>What is \\( 20.15349 \\) rounded to \\( 3 \\) deci...</td>\n",
       "      <td>\\( 20.153 \\)</td>\n",
       "      <td>\\( 20.154 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>### SubjectName: Rounding to Decimal Places\\n#...</td>\n",
       "      <td>921_D</td>\n",
       "      <td>Round numbers to three or more decimal places</td>\n",
       "      <td>Rounding to Decimal Places</td>\n",
       "      <td>What is \\( 20.15349 \\) rounded to \\( 3 \\) deci...</td>\n",
       "      <td>\\( 20.153 \\)</td>\n",
       "      <td>\\( 20.253 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>### SubjectName: Adding and Subtracting with D...</td>\n",
       "      <td>275_B</td>\n",
       "      <td>Subtract decimals where the numbers involved h...</td>\n",
       "      <td>Adding and Subtracting with Decimals</td>\n",
       "      <td>\\( 50.09-0.1= \\)</td>\n",
       "      <td>\\( 49.99 \\)</td>\n",
       "      <td>\\( 50.99 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>### SubjectName: Adding and Subtracting with D...</td>\n",
       "      <td>275_C</td>\n",
       "      <td>Subtract decimals where the numbers involved h...</td>\n",
       "      <td>Adding and Subtracting with Decimals</td>\n",
       "      <td>\\( 50.09-0.1= \\)</td>\n",
       "      <td>\\( 49.99 \\)</td>\n",
       "      <td>\\( 50.08 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>### SubjectName: Writing Ratios\\n### Construct...</td>\n",
       "      <td>416_B</td>\n",
       "      <td>Express pictorial representations of objects a...</td>\n",
       "      <td>Writing Ratios</td>\n",
       "      <td>Tom says for every one circle there are two sq...</td>\n",
       "      <td>Both Tom and Katie</td>\n",
       "      <td>Only Katie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>### SubjectName: Writing Ratios\\n### Construct...</td>\n",
       "      <td>416_D</td>\n",
       "      <td>Express pictorial representations of objects a...</td>\n",
       "      <td>Writing Ratios</td>\n",
       "      <td>Tom says for every one circle there are two sq...</td>\n",
       "      <td>Both Tom and Katie</td>\n",
       "      <td>Neither is correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>### SubjectName: Cubics and Reciprocals\\n### C...</td>\n",
       "      <td>1654_B</td>\n",
       "      <td>Given a positive x value, find the correspondi...</td>\n",
       "      <td>Cubics and Reciprocals</td>\n",
       "      <td>This is a part of the table of values for the ...</td>\n",
       "      <td>\\( 1 \\)</td>\n",
       "      <td>\\( 3 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>### SubjectName: Cubics and Reciprocals\\n### C...</td>\n",
       "      <td>1654_D</td>\n",
       "      <td>Given a positive x value, find the correspondi...</td>\n",
       "      <td>Cubics and Reciprocals</td>\n",
       "      <td>This is a part of the table of values for the ...</td>\n",
       "      <td>\\( 1 \\)</td>\n",
       "      <td>\\( 0 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>### SubjectName: Written Subtraction\\n### Cons...</td>\n",
       "      <td>247_A</td>\n",
       "      <td>Solve problems that combine addition and subtr...</td>\n",
       "      <td>Written Subtraction</td>\n",
       "      <td>At the start of the day, there was \\( £ 1,456 ...</td>\n",
       "      <td>\\( £ 4,426 \\)</td>\n",
       "      <td>\\( £ 13,180 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>### SubjectName: Written Subtraction\\n### Cons...</td>\n",
       "      <td>247_C</td>\n",
       "      <td>Solve problems that combine addition and subtr...</td>\n",
       "      <td>Written Subtraction</td>\n",
       "      <td>At the start of the day, there was \\( £ 1,456 ...</td>\n",
       "      <td>\\( £ 4,426 \\)</td>\n",
       "      <td>\\( £ 2,970 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>### SubjectName: Written Subtraction\\n### Cons...</td>\n",
       "      <td>247_D</td>\n",
       "      <td>Solve problems that combine addition and subtr...</td>\n",
       "      <td>Written Subtraction</td>\n",
       "      <td>At the start of the day, there was \\( £ 1,456 ...</td>\n",
       "      <td>\\( £ 4,426 \\)</td>\n",
       "      <td>\\( £ 10,268 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>### SubjectName: Substitution into Formula\\n##...</td>\n",
       "      <td>383_A</td>\n",
       "      <td>Substitute positive integer values into expres...</td>\n",
       "      <td>Substitution into Formula</td>\n",
       "      <td>When \\( h=15 \\)\\n\\n\\(\\n\\frac{h}{3}=\\n\\)\\n</td>\n",
       "      <td>\\( 5 \\)</td>\n",
       "      <td>\\( 12 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>### SubjectName: Substitution into Formula\\n##...</td>\n",
       "      <td>383_D</td>\n",
       "      <td>Substitute positive integer values into expres...</td>\n",
       "      <td>Substitution into Formula</td>\n",
       "      <td>When \\( h=15 \\)\\n\\n\\(\\n\\frac{h}{3}=\\n\\)\\n</td>\n",
       "      <td>\\( 5 \\)</td>\n",
       "      <td>\\( -5 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>### SubjectName: Multiplying and Dividing with...</td>\n",
       "      <td>322_A</td>\n",
       "      <td>Multiply a decimal by an integer</td>\n",
       "      <td>Multiplying and Dividing with Decimals</td>\n",
       "      <td>Work out:\\n\\[\\n0.3 \\times 12\\n\\]</td>\n",
       "      <td>\\( 3.6 \\)</td>\n",
       "      <td>\\( 36 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>### SubjectName: Multiplying and Dividing with...</td>\n",
       "      <td>322_C</td>\n",
       "      <td>Multiply a decimal by an integer</td>\n",
       "      <td>Multiplying and Dividing with Decimals</td>\n",
       "      <td>Work out:\\n\\[\\n0.3 \\times 12\\n\\]</td>\n",
       "      <td>\\( 3.6 \\)</td>\n",
       "      <td>\\( 0.36 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>### SubjectName: Multiplying and Dividing with...</td>\n",
       "      <td>322_D</td>\n",
       "      <td>Multiply a decimal by an integer</td>\n",
       "      <td>Multiplying and Dividing with Decimals</td>\n",
       "      <td>Work out:\\n\\[\\n0.3 \\times 12\\n\\]</td>\n",
       "      <td>\\( 3.6 \\)</td>\n",
       "      <td>\\( 0.036 \\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>### SubjectName: Distance Between Two Co-ordin...</td>\n",
       "      <td>203_A</td>\n",
       "      <td>Calculate the distance between two coordinates...</td>\n",
       "      <td>Distance Between Two Co-ordinates</td>\n",
       "      <td>Mark is working out the distance between these...</td>\n",
       "      <td>Right-angled</td>\n",
       "      <td>Isosceles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>### SubjectName: Distance Between Two Co-ordin...</td>\n",
       "      <td>203_C</td>\n",
       "      <td>Calculate the distance between two coordinates...</td>\n",
       "      <td>Distance Between Two Co-ordinates</td>\n",
       "      <td>Mark is working out the distance between these...</td>\n",
       "      <td>Right-angled</td>\n",
       "      <td>Equilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>### SubjectName: Distance Between Two Co-ordin...</td>\n",
       "      <td>203_D</td>\n",
       "      <td>Calculate the distance between two coordinates...</td>\n",
       "      <td>Distance Between Two Co-ordinates</td>\n",
       "      <td>Mark is working out the distance between these...</td>\n",
       "      <td>Right-angled</td>\n",
       "      <td>Scalene</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query_text QuestionId_Answer  \\\n",
       "0   ### SubjectName: Multiplying and Dividing with...            1700_A   \n",
       "1   ### SubjectName: Multiplying and Dividing with...            1700_C   \n",
       "2   ### SubjectName: Squares, Cubes, etc\\n### Cons...            1488_A   \n",
       "3   ### SubjectName: Squares, Cubes, etc\\n### Cons...            1488_B   \n",
       "4   ### SubjectName: Rounding to Decimal Places\\n#...             921_B   \n",
       "5   ### SubjectName: Rounding to Decimal Places\\n#...             921_C   \n",
       "6   ### SubjectName: Rounding to Decimal Places\\n#...             921_D   \n",
       "7   ### SubjectName: Adding and Subtracting with D...             275_B   \n",
       "8   ### SubjectName: Adding and Subtracting with D...             275_C   \n",
       "9   ### SubjectName: Writing Ratios\\n### Construct...             416_B   \n",
       "10  ### SubjectName: Writing Ratios\\n### Construct...             416_D   \n",
       "11  ### SubjectName: Cubics and Reciprocals\\n### C...            1654_B   \n",
       "12  ### SubjectName: Cubics and Reciprocals\\n### C...            1654_D   \n",
       "13  ### SubjectName: Written Subtraction\\n### Cons...             247_A   \n",
       "14  ### SubjectName: Written Subtraction\\n### Cons...             247_C   \n",
       "15  ### SubjectName: Written Subtraction\\n### Cons...             247_D   \n",
       "16  ### SubjectName: Substitution into Formula\\n##...             383_A   \n",
       "17  ### SubjectName: Substitution into Formula\\n##...             383_D   \n",
       "18  ### SubjectName: Multiplying and Dividing with...             322_A   \n",
       "19  ### SubjectName: Multiplying and Dividing with...             322_C   \n",
       "20  ### SubjectName: Multiplying and Dividing with...             322_D   \n",
       "21  ### SubjectName: Distance Between Two Co-ordin...             203_A   \n",
       "22  ### SubjectName: Distance Between Two Co-ordin...             203_C   \n",
       "23  ### SubjectName: Distance Between Two Co-ordin...             203_D   \n",
       "\n",
       "                                        ConstructName  \\\n",
       "0   Divide two decimals with the same number of de...   \n",
       "1   Divide two decimals with the same number of de...   \n",
       "2                  Understand the notation for powers   \n",
       "3                  Understand the notation for powers   \n",
       "4       Round numbers to three or more decimal places   \n",
       "5       Round numbers to three or more decimal places   \n",
       "6       Round numbers to three or more decimal places   \n",
       "7   Subtract decimals where the numbers involved h...   \n",
       "8   Subtract decimals where the numbers involved h...   \n",
       "9   Express pictorial representations of objects a...   \n",
       "10  Express pictorial representations of objects a...   \n",
       "11  Given a positive x value, find the correspondi...   \n",
       "12  Given a positive x value, find the correspondi...   \n",
       "13  Solve problems that combine addition and subtr...   \n",
       "14  Solve problems that combine addition and subtr...   \n",
       "15  Solve problems that combine addition and subtr...   \n",
       "16  Substitute positive integer values into expres...   \n",
       "17  Substitute positive integer values into expres...   \n",
       "18                   Multiply a decimal by an integer   \n",
       "19                   Multiply a decimal by an integer   \n",
       "20                   Multiply a decimal by an integer   \n",
       "21  Calculate the distance between two coordinates...   \n",
       "22  Calculate the distance between two coordinates...   \n",
       "23  Calculate the distance between two coordinates...   \n",
       "\n",
       "                               SubjectName  \\\n",
       "0   Multiplying and Dividing with Decimals   \n",
       "1   Multiplying and Dividing with Decimals   \n",
       "2                      Squares, Cubes, etc   \n",
       "3                      Squares, Cubes, etc   \n",
       "4               Rounding to Decimal Places   \n",
       "5               Rounding to Decimal Places   \n",
       "6               Rounding to Decimal Places   \n",
       "7     Adding and Subtracting with Decimals   \n",
       "8     Adding and Subtracting with Decimals   \n",
       "9                           Writing Ratios   \n",
       "10                          Writing Ratios   \n",
       "11                  Cubics and Reciprocals   \n",
       "12                  Cubics and Reciprocals   \n",
       "13                     Written Subtraction   \n",
       "14                     Written Subtraction   \n",
       "15                     Written Subtraction   \n",
       "16               Substitution into Formula   \n",
       "17               Substitution into Formula   \n",
       "18  Multiplying and Dividing with Decimals   \n",
       "19  Multiplying and Dividing with Decimals   \n",
       "20  Multiplying and Dividing with Decimals   \n",
       "21       Distance Between Two Co-ordinates   \n",
       "22       Distance Between Two Co-ordinates   \n",
       "23       Distance Between Two Co-ordinates   \n",
       "\n",
       "                                         QuestionText      correct_answer  \\\n",
       "0                                 \\( 0.9 \\div 0.3= \\)             \\( 3 \\)   \n",
       "1                                 \\( 0.9 \\div 0.3= \\)             \\( 3 \\)   \n",
       "2         To calculate \\( 53^{2} \\) you need to do...  \\( 53 \\times 53 \\)   \n",
       "3         To calculate \\( 53^{2} \\) you need to do...  \\( 53 \\times 53 \\)   \n",
       "4   What is \\( 20.15349 \\) rounded to \\( 3 \\) deci...        \\( 20.153 \\)   \n",
       "5   What is \\( 20.15349 \\) rounded to \\( 3 \\) deci...        \\( 20.153 \\)   \n",
       "6   What is \\( 20.15349 \\) rounded to \\( 3 \\) deci...        \\( 20.153 \\)   \n",
       "7                                    \\( 50.09-0.1= \\)         \\( 49.99 \\)   \n",
       "8                                    \\( 50.09-0.1= \\)         \\( 49.99 \\)   \n",
       "9   Tom says for every one circle there are two sq...  Both Tom and Katie   \n",
       "10  Tom says for every one circle there are two sq...  Both Tom and Katie   \n",
       "11  This is a part of the table of values for the ...             \\( 1 \\)   \n",
       "12  This is a part of the table of values for the ...             \\( 1 \\)   \n",
       "13  At the start of the day, there was \\( £ 1,456 ...       \\( £ 4,426 \\)   \n",
       "14  At the start of the day, there was \\( £ 1,456 ...       \\( £ 4,426 \\)   \n",
       "15  At the start of the day, there was \\( £ 1,456 ...       \\( £ 4,426 \\)   \n",
       "16          When \\( h=15 \\)\\n\\n\\(\\n\\frac{h}{3}=\\n\\)\\n             \\( 5 \\)   \n",
       "17          When \\( h=15 \\)\\n\\n\\(\\n\\frac{h}{3}=\\n\\)\\n             \\( 5 \\)   \n",
       "18                   Work out:\\n\\[\\n0.3 \\times 12\\n\\]           \\( 3.6 \\)   \n",
       "19                   Work out:\\n\\[\\n0.3 \\times 12\\n\\]           \\( 3.6 \\)   \n",
       "20                   Work out:\\n\\[\\n0.3 \\times 12\\n\\]           \\( 3.6 \\)   \n",
       "21  Mark is working out the distance between these...        Right-angled   \n",
       "22  Mark is working out the distance between these...        Right-angled   \n",
       "23  Mark is working out the distance between these...        Right-angled   \n",
       "\n",
       "      incorrect_answer  \n",
       "0            \\( 0.3 \\)  \n",
       "1   \\( 0.333 \\ldots \\)  \n",
       "2           \\( 53+2 \\)  \n",
       "3    \\( 53 \\times 2 \\)  \n",
       "4          \\( 20.15 \\)  \n",
       "5         \\( 20.154 \\)  \n",
       "6         \\( 20.253 \\)  \n",
       "7          \\( 50.99 \\)  \n",
       "8          \\( 50.08 \\)  \n",
       "9           Only Katie  \n",
       "10  Neither is correct  \n",
       "11             \\( 3 \\)  \n",
       "12             \\( 0 \\)  \n",
       "13      \\( £ 13,180 \\)  \n",
       "14       \\( £ 2,970 \\)  \n",
       "15      \\( £ 10,268 \\)  \n",
       "16            \\( 12 \\)  \n",
       "17            \\( -5 \\)  \n",
       "18            \\( 36 \\)  \n",
       "19          \\( 0.36 \\)  \n",
       "20         \\( 0.036 \\)  \n",
       "21           Isosceles  \n",
       "22         Equilateral  \n",
       "23             Scalene  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "IS_SUBMISSION = bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n",
    "if IS_SUBMISSION:\n",
    "    full_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv\")\n",
    "else:\n",
    "    full_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv\").fillna(-1).sample(10, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "rows = []\n",
    "for idx, row in full_df.iterrows():\n",
    "    for option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        if option == row.CorrectAnswer:\n",
    "            continue\n",
    "\n",
    "        if not IS_SUBMISSION and row[f\"Misconception{option}Id\"]==-1:\n",
    "            continue\n",
    "            \n",
    "        correct_answer = row[f\"Answer{row.CorrectAnswer}Text\"]\n",
    "\n",
    "        query_text =f\"### SubjectName: {row['SubjectName']}\\n### ConstructName: {row['ConstructName']}\\n### Question: {row['QuestionText']}\\n### Correct Answer: {correct_answer}\\n### Misconcepte Incorrect answer: {option}.{row[f'Answer{option}Text']}\"\n",
    "        rows.append({\"query_text\": query_text, \n",
    "                     \"QuestionId_Answer\": f\"{row.QuestionId}_{option}\",\n",
    "                     \"ConstructName\": row.ConstructName,\n",
    "                     \"SubjectName\": row.SubjectName,\n",
    "                     \"QuestionText\": row.QuestionText,\n",
    "                     \"correct_answer\": correct_answer,\n",
    "                     \"incorrect_answer\": row[f\"Answer{option}Text\"]\n",
    "                     })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0a85a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:56.970900Z",
     "iopub.status.busy": "2024-12-12T15:04:56.970631Z",
     "iopub.status.idle": "2024-12-12T15:04:57.054329Z",
     "shell.execute_reply": "2024-12-12T15:04:57.053272Z"
    },
    "papermill": {
     "duration": 0.113964,
     "end_time": "2024-12-12T15:04:57.055884",
     "exception": false,
     "start_time": "2024-12-12T15:04:56.941920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   QuestionId_Answer MisconceptionId\n",
      "0             1700_A         [153.0]\n",
      "1             1700_C        [2359.0]\n",
      "2             1488_A        [2445.0]\n",
      "3             1488_B        [2316.0]\n",
      "4              921_B        [2392.0]\n",
      "5              921_C        [1988.0]\n",
      "6              921_D        [2330.0]\n",
      "7              275_B         [699.0]\n",
      "8              275_C        [2346.0]\n",
      "9              416_B        [1846.0]\n",
      "10             416_D        [1150.0]\n",
      "11            1654_B        [2349.0]\n",
      "12            1654_D         [832.0]\n",
      "13             247_A        [2009.0]\n",
      "14             247_C         [791.0]\n",
      "15             247_D        [1787.0]\n",
      "16             383_A        [2093.0]\n",
      "17             383_D        [1648.0]\n",
      "18             322_A         [189.0]\n",
      "19             322_C        [1035.0]\n",
      "20             322_D        [2187.0]\n",
      "21             203_A        [1658.0]\n",
      "22             203_C        [1658.0]\n",
      "23             203_D        [1658.0]\n"
     ]
    }
   ],
   "source": [
    "if not IS_SUBMISSION:\n",
    "    df_label = {}\n",
    "    for idx, row in full_df.iterrows():\n",
    "        for option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            if (row.CorrectAnswer!=option) & (row[f\"Misconception{option}Id\"]!=-1):\n",
    "                df_label[f\"{row.QuestionId}_{option}\"] = [row[f\"Misconception{option}Id\"]]             \n",
    "                \n",
    "    df_label = pd.DataFrame([df_label]).T.reset_index()\n",
    "    df_label.columns = [\"QuestionId_Answer\", \"MisconceptionId\"]\n",
    "    df_label.to_parquet(\"label.parquet\", index=False)\n",
    "    print(df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e67b4f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:57.113255Z",
     "iopub.status.busy": "2024-12-12T15:04:57.112953Z",
     "iopub.status.idle": "2024-12-12T15:04:57.119475Z",
     "shell.execute_reply": "2024-12-12T15:04:57.118868Z"
    },
    "papermill": {
     "duration": 0.036903,
     "end_time": "2024-12-12T15:04:57.120980",
     "exception": false,
     "start_time": "2024-12-12T15:04:57.084077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_parquet(\"df.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511edfb",
   "metadata": {
    "papermill": {
     "duration": 0.027741,
     "end_time": "2024-12-12T15:04:57.176752",
     "exception": false,
     "start_time": "2024-12-12T15:04:57.149011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LLM Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4ec6f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:57.233589Z",
     "iopub.status.busy": "2024-12-12T15:04:57.233282Z",
     "iopub.status.idle": "2024-12-12T15:04:57.240798Z",
     "shell.execute_reply": "2024-12-12T15:04:57.239930Z"
    },
    "papermill": {
     "duration": 0.038134,
     "end_time": "2024-12-12T15:04:57.242460",
     "exception": false,
     "start_time": "2024-12-12T15:04:57.204326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_vllm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_vllm.py\n",
    "\n",
    "import vllm\n",
    "from vllm.lora.request import LoRARequest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import PreTrainedTokenizer, AutoTokenizer\n",
    "from typing import List\n",
    "import torch\n",
    "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "import re\n",
    "\n",
    "model_path = \"/kaggle/input/qwen32b/qwen-awq\"\n",
    "lora_path = '/kaggle/input/eedi-gather/lora/qwen2-32b/last_checkpoint/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def preprocess_text(x):\n",
    "    x = re.sub(\"http\\w+\", '',x)   # Delete URL\n",
    "    x = re.sub(r\"\\.+\", \".\", x)    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = re.sub(r\"\\\\\\(\", \" \", x)\n",
    "    x = re.sub(r\"\\\\\\)\", \" \", x)\n",
    "    x = re.sub(r\"[ ]{1,}\", \" \", x)\n",
    "    x = x.strip()                 # Remove empty characters at the beginning and end\n",
    "    return x\n",
    "\n",
    "PROMPT  = \"\"\"Here is a question about {ConstructName}({SubjectName}).\n",
    "Question: {Question}\n",
    "Correct Answer: {CorrectAnswer}\n",
    "Incorrect Answer: {IncorrectAnswer}\n",
    "\n",
    "You are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\n",
    "Answer concisely what misconception it is to lead to getting the incorrect answer.\n",
    "Pick the correct misconception number from the below:\n",
    "\n",
    "{Retrival}\n",
    "\"\"\"\n",
    "# just directly give your answers.\n",
    "\n",
    "def apply_template(row, tokenizer):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": preprocess_text(\n",
    "                PROMPT.format(\n",
    "                    ConstructName=row[\"ConstructName\"],\n",
    "                    SubjectName=row[\"SubjectName\"],\n",
    "                    Question=row[\"QuestionText\"],\n",
    "                    IncorrectAnswer=row[\"incorrect_answer\"],\n",
    "                    CorrectAnswer=row[\"correct_answer\"],\n",
    "                    Retrival=row[\"retrieval\"]\n",
    "                )\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    return text\n",
    "\n",
    "\n",
    "misconception_df = pd.read_csv(\"/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv\")\n",
    "\n",
    "df = pd.read_parquet(\"df.parquet\")\n",
    "indices = np.load(\"indices.npy\")\n",
    "\n",
    "model_path = \"/kaggle/input/qwen32b/qwen-awq\"\n",
    "\n",
    "llm = vllm.LLM(\n",
    "    model_path,\n",
    "    quantization=\"awq\",\n",
    "    tensor_parallel_size=2,\n",
    "    gpu_memory_utilization=0.90, \n",
    "    trust_remote_code=True,\n",
    "    dtype=\"half\", \n",
    "    enforce_eager=True,\n",
    "    max_model_len=5120,\n",
    "    disable_log_stats=True,\n",
    "    enable_prefix_caching=True,\n",
    "    enable_lora=True,\n",
    "    max_lora_rank=64,\n",
    "    max_loras=1\n",
    ")\n",
    "tokenizer = llm.get_tokenizer()\n",
    "\n",
    "\n",
    "def get_candidates(c_indices):\n",
    "    candidates = []\n",
    "\n",
    "    mis_names = misconception_df[\"MisconceptionName\"].values\n",
    "    for ix in c_indices:\n",
    "        c_names = []\n",
    "        for i, name in enumerate(mis_names[ix]):\n",
    "            c_names.append(f\"{i+1}. {name}\")\n",
    "\n",
    "        candidates.append(\"\\n\".join(c_names))\n",
    "        \n",
    "    return candidates\n",
    "\n",
    "\n",
    "# cache\n",
    "select_rounds = 3\n",
    "single_round_len = 24 // select_rounds\n",
    "numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "print(f'select_rounds: {select_rounds}, single_round_len: {single_round_len+1}')\n",
    "print(numbers[:single_round_len+1])\n",
    "\n",
    "sample_r = get_candidates(indices[0:1,0:1])\n",
    "print(sample_r)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": preprocess_text(\n",
    "            PROMPT.format(\n",
    "                ConstructName=df.loc[0, \"ConstructName\"],\n",
    "                SubjectName=df.loc[0, \"SubjectName\"],\n",
    "                Question=df.loc[0, \"QuestionText\"],\n",
    "                IncorrectAnswer=df.loc[0, \"incorrect_answer\"],\n",
    "                CorrectAnswer=df.loc[0, \"correct_answer\"],\n",
    "                Retrival=sample_r\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "]\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(text[0])\n",
    "\n",
    "llm.generate(\n",
    "    text[0],\n",
    "    vllm.SamplingParams(\n",
    "        n=1,  # Number of output sequences to return for each prompt.\n",
    "        top_k=1,  # Float that controls the cumulative probability of the top tokens to consider.\n",
    "        temperature=0,  # randomness of the sampling\n",
    "        seed=777, # Seed for reprodicibility\n",
    "        skip_special_tokens=False,  # Whether to skip special tokens in the output.\n",
    "        max_tokens=1,  # Maximum number of tokens to generate per output sequence.\n",
    "        logits_processors=[MultipleChoiceLogitsProcessor(tokenizer, choices=numbers[:single_round_len+1])]\n",
    "    ),\n",
    "    use_tqdm=True,\n",
    "    lora_request=LoRARequest(\"myadapter\", 1, lora_path)\n",
    ")\n",
    "\n",
    "\n",
    "# loop\n",
    "survivors = indices[:, -1:]\n",
    "\n",
    "for i in range(select_rounds):\n",
    "    c_indices = np.concatenate([indices[:, -single_round_len*(i+1)-1:-single_round_len*i-1], survivors], axis=1)\n",
    "    \n",
    "    df[\"retrieval\"] = get_candidates(c_indices)\n",
    "    df[\"text\"] = df.apply(lambda row: apply_template(row, tokenizer), axis=1)\n",
    "    \n",
    "    print(\"Example:\")\n",
    "    print(df[\"text\"].values[0])\n",
    "    print()\n",
    "    \n",
    "    responses = llm.generate(\n",
    "        df[\"text\"].values,\n",
    "        vllm.SamplingParams(\n",
    "            n=1,  # Number of output sequences to return for each prompt.\n",
    "            top_k=1,  # Float that controls the cumulative probability of the top tokens to consider.\n",
    "            temperature=0,  # randomness of the sampling\n",
    "            seed=777, # Seed for reprodicibility\n",
    "            skip_special_tokens=False,  # Whether to skip special tokens in the output.\n",
    "            max_tokens=1,  # Maximum number of tokens to generate per output sequence.\n",
    "            logits_processors=[MultipleChoiceLogitsProcessor(tokenizer, choices=numbers[:single_round_len+1])]\n",
    "        ),\n",
    "        use_tqdm=True,\n",
    "        lora_request=LoRARequest(\"myadapter\", 1, lora_path)\n",
    "    )\n",
    "    \n",
    "    responses = [x.outputs[0].text for x in responses]\n",
    "    df[\"response\"] = responses\n",
    "    \n",
    "    \n",
    "    llm_choices = df[\"response\"].astype(int).values - 1\n",
    "    \n",
    "    survivors = np.array([cix[best] for best, cix in zip(llm_choices, c_indices)]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(indices.shape[0]):\n",
    "    ix = indices[i]\n",
    "    llm_choice = survivors[i, 0]\n",
    "    \n",
    "    results.append(\" \".join([str(llm_choice)] + [str(x) for x in ix if x != llm_choice]))\n",
    "\n",
    "\n",
    "df[\"MisconceptionId\"] = results\n",
    "df.to_csv(\"submission.csv\", columns=[\"QuestionId_Answer\", \"MisconceptionId\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d74ddbb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:04:57.299424Z",
     "iopub.status.busy": "2024-12-12T15:04:57.299120Z",
     "iopub.status.idle": "2024-12-12T15:11:41.023108Z",
     "shell.execute_reply": "2024-12-12T15:11:41.022154Z"
    },
    "papermill": {
     "duration": 403.75609,
     "end_time": "2024-12-12T15:11:41.026501",
     "exception": false,
     "start_time": "2024-12-12T15:04:57.270411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-12 15:05:00 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead, and make sure to uninstall `pynvml`. When both of them are installed, `pynvml` will take precedence and cause errors. See https://pypi.org/project/pynvml for more information.\r\n",
      "/opt/conda/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\r\n",
      "No module named 'vllm._version'\r\n",
      "  from vllm.version import __version__ as VLLM_VERSION\r\n",
      "WARNING 12-12 15:05:15 config.py:306] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\r\n",
      "INFO 12-12 15:05:15 config.py:887] Defaulting to use mp for distributed inference\r\n",
      "WARNING 12-12 15:05:15 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\r\n",
      "INFO 12-12 15:05:15 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='/kaggle/input/qwen32b/qwen-awq', speculative_config=None, tokenizer='/kaggle/input/qwen32b/qwen-awq', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=5120, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/kaggle/input/qwen32b/qwen-awq, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)\r\n",
      "WARNING 12-12 15:05:16 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 2 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\r\n",
      "INFO 12-12 15:05:16 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\r\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\r\n",
      "  self.pid = os.fork()\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:16 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "INFO 12-12 15:05:16 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "INFO 12-12 15:05:16 selector.py:115] Using XFormers backend.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:16 selector.py:115] Using XFormers backend.\r\n",
      "/opt/conda/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\r\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m /opt/conda/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m   @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m /opt/conda/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m   @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\r\n",
      "/opt/conda/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\r\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:17 multiproc_worker_utils.py:216] Worker ready; awaiting tasks\r\n",
      "INFO 12-12 15:05:18 utils.py:1008] Found nccl from library libnccl.so.2\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:18 utils.py:1008] Found nccl from library libnccl.so.2\r\n",
      "INFO 12-12 15:05:18 pynccl.py:63] vLLM is using nccl==2.20.5\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:18 pynccl.py:63] vLLM is using nccl==2.20.5\r\n",
      "INFO 12-12 15:05:18 custom_all_reduce_utils.py:204] generating GPU P2P access cache in /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "INFO 12-12 15:05:36 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:36 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\r\n",
      "WARNING 12-12 15:05:36 custom_all_reduce.py:141] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m WARNING 12-12 15:05:36 custom_all_reduce.py:141] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\r\n",
      "INFO 12-12 15:05:36 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7911140213f0>, local_subscribe_port=47073, remote_subscribe_port=None)\r\n",
      "INFO 12-12 15:05:36 model_runner.py:1060] Starting to load model /kaggle/input/qwen32b/qwen-awq...\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:36 model_runner.py:1060] Starting to load model /kaggle/input/qwen32b/qwen-awq...\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:36 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:05:36 selector.py:115] Using XFormers backend.\r\n",
      "INFO 12-12 15:05:37 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\r\n",
      "INFO 12-12 15:05:37 selector.py:115] Using XFormers backend.\r\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\r\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [01:57<05:53, 117.89s/it]\r\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [02:47<02:35, 77.93s/it]\r\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [03:29<01:01, 61.58s/it]\r\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [04:29<00:00, 60.77s/it]\r\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [04:29<00:00, 67.38s/it]\r\n",
      "\r\n",
      "\u001b[1;36m(VllmWorkerProcess pid=227)\u001b[0;0m INFO 12-12 15:10:07 model_runner.py:1071] Loading model weights took 9.0933 GB\r\n",
      "INFO 12-12 15:10:07 model_runner.py:1071] Loading model weights took 9.0933 GB\r\n",
      "INFO 12-12 15:10:20 distributed_gpu_executor.py:57] # GPU blocks: 461, # CPU blocks: 2048\r\n",
      "INFO 12-12 15:10:20 distributed_gpu_executor.py:61] Maximum concurrency for 5120 tokens per request: 1.44x\r\n",
      "select_rounds: 3, single_round_len: 9\r\n",
      "['1', '2', '3', '4', '5', '6', '7', '8', '9']\r\n",
      "['1. Believes division is commutative ']\r\n",
      "<\r\n",
      "/kaggle/working/run_vllm.py:139: DeprecationWarning: The 'lora_local_path' attribute is deprecated and will be removed in a future version. Please use 'lora_path' instead.\r\n",
      "  lora_request=LoRARequest(\"myadapter\", 1, lora_path)\r\n",
      "Processed prompts: 100%|█| 1/1 [00:32<00:00, 32.14s/it, est. speed input: 0.03 t\r\n",
      "Example:\r\n",
      "<|im_start|>system\r\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\r\n",
      "<|im_start|>user\r\n",
      "Here is a question about Divide two decimals with the same number of decimal places(Multiplying and Dividing with Decimals).\r\n",
      "Question: 0.9 \\div 0.3= \r\n",
      "Correct Answer: 3 \r\n",
      "Incorrect Answer: 0.3 \r\n",
      "\r\n",
      "You are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\r\n",
      "Answer concisely what misconception it is to lead to getting the incorrect answer.\r\n",
      "Pick the correct misconception number from the below:\r\n",
      "\r\n",
      "1. Subtracts instead of divides\r\n",
      "2. Confusion over whether multiplication or division is the correct way to solve the problem.\r\n",
      "3. Misinterprets the order of division in worded problems\r\n",
      "4. Believes that the smaller a divisor is, the smaller the answer will be\r\n",
      "5. When solving an equation thinks they divide when in fact they need to multiply\r\n",
      "6. When dividing a decimal by a whole number, ignores decimal point and just divides the digits\r\n",
      "7. Cancels digits when dividing\r\n",
      "8. Assumes the denominator is divided by the numerator\r\n",
      "9. When solving a problem using written division (bus-stop method), puts the dividend in the wrong place<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "\r\n",
      "\r\n",
      "/kaggle/working/run_vllm.py:168: DeprecationWarning: The 'lora_local_path' attribute is deprecated and will be removed in a future version. Please use 'lora_path' instead.\r\n",
      "  lora_request=LoRARequest(\"myadapter\", 1, lora_path)\r\n",
      "Processed prompts: 100%|█| 24/24 [00:17<00:00,  1.36it/s, est. speed input: 395.\r\n",
      "Example:\r\n",
      "<|im_start|>system\r\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\r\n",
      "<|im_start|>user\r\n",
      "Here is a question about Divide two decimals with the same number of decimal places(Multiplying and Dividing with Decimals).\r\n",
      "Question: 0.9 \\div 0.3= \r\n",
      "Correct Answer: 3 \r\n",
      "Incorrect Answer: 0.3 \r\n",
      "\r\n",
      "You are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\r\n",
      "Answer concisely what misconception it is to lead to getting the incorrect answer.\r\n",
      "Pick the correct misconception number from the below:\r\n",
      "\r\n",
      "1. Believes that the larger the dividend, the smaller the answer.\r\n",
      "2. Gets the dividend and divisor the wrong way round when doing long division\r\n",
      "3. Believes division is sometimes commutative \r\n",
      "4. Swaps the dividend and divisor in order to get an integer answer\r\n",
      "5. Believes that dividing by a decimal is the same as dividing by its reciprocal\r\n",
      "6. When dividing, ignores any remainders\r\n",
      "7. When dividing, confuses the remainder with the quotient\r\n",
      "8. Believes that the larger the divisor, the larger the answer.\r\n",
      "9. Subtracts instead of divides<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "\r\n",
      "\r\n",
      "/kaggle/working/run_vllm.py:168: DeprecationWarning: The 'lora_local_path' attribute is deprecated and will be removed in a future version. Please use 'lora_path' instead.\r\n",
      "  lora_request=LoRARequest(\"myadapter\", 1, lora_path)\r\n",
      "Processed prompts: 100%|█| 24/24 [00:09<00:00,  2.40it/s, est. speed input: 696.\r\n",
      "Example:\r\n",
      "<|im_start|>system\r\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\r\n",
      "<|im_start|>user\r\n",
      "Here is a question about Divide two decimals with the same number of decimal places(Multiplying and Dividing with Decimals).\r\n",
      "Question: 0.9 \\div 0.3= \r\n",
      "Correct Answer: 3 \r\n",
      "Incorrect Answer: 0.3 \r\n",
      "\r\n",
      "You are a Mathematics teacher. Your task is to reason and identify the misconception behind the Incorrect Answer with the Question.\r\n",
      "Answer concisely what misconception it is to lead to getting the incorrect answer.\r\n",
      "Pick the correct misconception number from the below:\r\n",
      "\r\n",
      "1. Believes division is commutative \r\n",
      "2. When dividing decimals, does not realize that the order and position of the digits (relative to each other) has to remain constant.\r\n",
      "3. When dividing decimals, divides rather than multiplies when reinserting the decimal.\r\n",
      "4. Starts at the wrong end of the dividend when dividing\r\n",
      "5. Multiplies rather than divides\r\n",
      "6. When dividing decimals with the same number of decimal places as each other, assumes the answer also has the same number of decimal places\r\n",
      "7. Divides rather than multiplies \r\n",
      "8. When solving an equation, thinks the divisor and dividend are the opposite way around\r\n",
      "9. Subtracts instead of divides<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "\r\n",
      "\r\n",
      "/kaggle/working/run_vllm.py:168: DeprecationWarning: The 'lora_local_path' attribute is deprecated and will be removed in a future version. Please use 'lora_path' instead.\r\n",
      "  lora_request=LoRARequest(\"myadapter\", 1, lora_path)\r\n",
      "Processed prompts: 100%|█| 24/24 [00:08<00:00,  2.74it/s, est. speed input: 811.\r\n"
     ]
    }
   ],
   "source": [
    "!python run_vllm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10333096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:11:41.088550Z",
     "iopub.status.busy": "2024-12-12T15:11:41.088091Z",
     "iopub.status.idle": "2024-12-12T15:11:41.102109Z",
     "shell.execute_reply": "2024-12-12T15:11:41.101368Z"
    },
    "papermill": {
     "duration": 0.046478,
     "end_time": "2024-12-12T15:11:41.103744",
     "exception": false,
     "start_time": "2024-12-12T15:11:41.057266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId_Answer</th>\n",
       "      <th>MisconceptionId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700_A</td>\n",
       "      <td>153 2359 151 2525 1155 1074 565 195 2461 1922 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700_C</td>\n",
       "      <td>2359 151 419 1155 2525 2542 1629 339 1259 58 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1488_A</td>\n",
       "      <td>2445 948 952 2175 2352 2316 1072 1337 2010 923...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1488_B</td>\n",
       "      <td>2316 1072 2175 1792 2445 948 1337 2010 1346 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>921_B</td>\n",
       "      <td>2392 1529 1248 1379 1355 1272 739 663 1742 233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>921_C</td>\n",
       "      <td>1988 322 2392 2330 1379 2412 1248 794 1449 152...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>921_D</td>\n",
       "      <td>2330 1675 2392 1248 1742 1988 2412 1529 322 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>275_B</td>\n",
       "      <td>699 2346 496 2203 611 1730 1795 980 1898 467 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>275_C</td>\n",
       "      <td>2346 496 2203 90 539 1730 699 980 2044 1317 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>416_B</td>\n",
       "      <td>1846 843 1556 2373 1864 1224 473 1232 105 1895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>416_D</td>\n",
       "      <td>1846 843 1224 2373 1895 862 255 1975 142 1864 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1654_B</td>\n",
       "      <td>2349 1933 662 136 916 2547 413 176 1924 2447 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1654_D</td>\n",
       "      <td>1924 176 832 1933 385 136 1617 2093 1860 49 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>247_A</td>\n",
       "      <td>2009 1773 1514 1787 1978 791 1078 2172 1999 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>247_C</td>\n",
       "      <td>1787 791 1078 1978 2172 1999 1453 1773 2009 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>247_D</td>\n",
       "      <td>1787 1773 2009 1978 1514 791 1078 2172 1999 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>383_A</td>\n",
       "      <td>2093 1241 2273 1875 1589 934 997 1190 2274 215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>383_D</td>\n",
       "      <td>1648 2093 934 1241 1875 1800 1542 623 1589 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>322_A</td>\n",
       "      <td>2055 2350 1482 189 1035 1404 301 2335 394 2288...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>322_C</td>\n",
       "      <td>1035 2187 2350 2055 394 301 2481 2288 1482 955...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>322_D</td>\n",
       "      <td>2187 1035 2350 2481 394 2335 2055 2288 189 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>203_A</td>\n",
       "      <td>1658 1970 1602 745 1813 110 1279 992 517 1176 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>203_C</td>\n",
       "      <td>1658 1279 423 1602 2467 992 110 745 1176 204 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>203_D</td>\n",
       "      <td>1658 646 2423 204 1192 1279 1097 1602 1813 213...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId_Answer                                    MisconceptionId\n",
       "0             1700_A  153 2359 151 2525 1155 1074 565 195 2461 1922 ...\n",
       "1             1700_C  2359 151 419 1155 2525 2542 1629 339 1259 58 6...\n",
       "2             1488_A  2445 948 952 2175 2352 2316 1072 1337 2010 923...\n",
       "3             1488_B  2316 1072 2175 1792 2445 948 1337 2010 1346 14...\n",
       "4              921_B  2392 1529 1248 1379 1355 1272 739 663 1742 233...\n",
       "5              921_C  1988 322 2392 2330 1379 2412 1248 794 1449 152...\n",
       "6              921_D  2330 1675 2392 1248 1742 1988 2412 1529 322 13...\n",
       "7              275_B  699 2346 496 2203 611 1730 1795 980 1898 467 1...\n",
       "8              275_C  2346 496 2203 90 539 1730 699 980 2044 1317 18...\n",
       "9              416_B  1846 843 1556 2373 1864 1224 473 1232 105 1895...\n",
       "10             416_D  1846 843 1224 2373 1895 862 255 1975 142 1864 ...\n",
       "11            1654_B  2349 1933 662 136 916 2547 413 176 1924 2447 2...\n",
       "12            1654_D  1924 176 832 1933 385 136 1617 2093 1860 49 23...\n",
       "13             247_A  2009 1773 1514 1787 1978 791 1078 2172 1999 21...\n",
       "14             247_C  1787 791 1078 1978 2172 1999 1453 1773 2009 23...\n",
       "15             247_D  1787 1773 2009 1978 1514 791 1078 2172 1999 14...\n",
       "16             383_A  2093 1241 2273 1875 1589 934 997 1190 2274 215...\n",
       "17             383_D  1648 2093 934 1241 1875 1800 1542 623 1589 155...\n",
       "18             322_A  2055 2350 1482 189 1035 1404 301 2335 394 2288...\n",
       "19             322_C  1035 2187 2350 2055 394 301 2481 2288 1482 955...\n",
       "20             322_D  2187 1035 2350 2481 394 2335 2055 2288 189 200...\n",
       "21             203_A  1658 1970 1602 745 1813 110 1279 992 517 1176 ...\n",
       "22             203_C  1658 1279 423 1602 2467 992 110 745 1176 204 1...\n",
       "23             203_D  1658 646 2423 204 1192 1279 1097 1602 1813 213..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f45ef9c",
   "metadata": {
    "papermill": {
     "duration": 0.029514,
     "end_time": "2024-12-12T15:11:41.163779",
     "exception": false,
     "start_time": "2024-12-12T15:11:41.134265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5638c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T15:11:41.224818Z",
     "iopub.status.busy": "2024-12-12T15:11:41.223972Z",
     "iopub.status.idle": "2024-12-12T15:11:41.339154Z",
     "shell.execute_reply": "2024-12-12T15:11:41.338251Z"
    },
    "papermill": {
     "duration": 0.147463,
     "end_time": "2024-12-12T15:11:41.340897",
     "exception": false,
     "start_time": "2024-12-12T15:11:41.193434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  0.8784722222222222\n"
     ]
    }
   ],
   "source": [
    "if not IS_SUBMISSION:\n",
    "    import pandas as pd\n",
    "    from eedi_metrics import mapk\n",
    "    predicted = pd.read_csv(\"submission.csv\")[\"MisconceptionId\"].apply(lambda x: [int(y) for y in x.split()])\n",
    "    label = pd.read_parquet(\"label.parquet\")[\"MisconceptionId\"]\n",
    "    print(\"Validation: \", mapk(label, predicted))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9738540,
     "sourceId": 82695,
     "sourceType": "competition"
    },
    {
     "datasetId": 6117312,
     "sourceId": 9948011,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6202180,
     "sourceId": 10064022,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 210569625,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 212469724,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 171421,
     "modelInstanceId": 148911,
     "sourceId": 174909,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 171434,
     "modelInstanceId": 148923,
     "sourceId": 174921,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1121.838218,
   "end_time": "2024-12-12T15:11:42.994178",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-12T14:53:01.155960",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "523c18358ef34716849a0b23ebd951c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "66d1986e85314615bda8094474b938cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6e86d50117394056b4a65f5e6d5c880a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f4901668c4a4340bfd8fa7eed6140b9",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9f8024c4f69a4ef89677cf08fac892f7",
       "value": 4
      }
     },
     "7d08e2d22007410ab992e485dd2254a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f4901668c4a4340bfd8fa7eed6140b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d64e6a479c342f8914418baeb6eea58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b86163bcb2114521bd43acf5a176cbf1",
        "IPY_MODEL_6e86d50117394056b4a65f5e6d5c880a",
        "IPY_MODEL_ae8897a92b3f4bda974039ce9b60d01d"
       ],
       "layout": "IPY_MODEL_b35e7fa752ba4943a884f6ba70d39d83"
      }
     },
     "9f8024c4f69a4ef89677cf08fac892f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ae8897a92b3f4bda974039ce9b60d01d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b63fd599da2440d3987d55d284d3e026",
       "placeholder": "​",
       "style": "IPY_MODEL_66d1986e85314615bda8094474b938cf",
       "value": "Loading safetensors checkpoint shards: 100% Completed | 4/4 [03:38&lt;00:00, 54.60s/it]\n"
      }
     },
     "b35e7fa752ba4943a884f6ba70d39d83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b63fd599da2440d3987d55d284d3e026": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b86163bcb2114521bd43acf5a176cbf1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7d08e2d22007410ab992e485dd2254a3",
       "placeholder": "​",
       "style": "IPY_MODEL_523c18358ef34716849a0b23ebd951c4",
       "value": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
