{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30579,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Largely built on [@iqmansingh's](https://www.kaggle.com/iqmansingh) notebook, [4-Fold Time-Series Split Ensemble](https://www.kaggle.com/code/iqmansingh/optiver-4-fold-time-series-split-ensemble), although this borrows the `reduce_mem_usage` and `imbalance_features` snippets as well. The core idea is still to build a voting ensemble on time series splits, but with score tracking so it can reject models that degrade performance.\n\nI eventually learned that scikit-learn has a built-in [`VotingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html) class, *(shout-out to [@chinzorigtganbat's](https://www.kaggle.com/chinzorigtganbat) [VotingRegressor + Boosters](https://www.kaggle.com/code/chinzorigtganbat/votingregressor-boosters))*, but it's different enough that I couldn't use it here without a rewrite.\n\nI also learned about the [many selective ensemble papers](https://scholar.google.com/scholar?q=selective+ensemble+machine+learning&hl=en&as_sdt=0&as_vis=1&oi=scholart) put out in the last decade. At best this is a naive implementation of the concept, but I want to acknowldge the authors for their work.","metadata":{}},{"cell_type":"code","source":"MEMORY_CAP = 16.8 # GiB; if malloc starts to runaway reign it in","metadata":{"execution":{"iopub.status.busy":"2023-12-21T22:27:17.231014Z","iopub.execute_input":"2023-12-21T22:27:17.231531Z","iopub.status.idle":"2023-12-21T22:27:17.265189Z","shell.execute_reply.started":"2023-12-21T22:27:17.231478Z","shell.execute_reply":"2023-12-21T22:27:17.264113Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport time\nimport joblib\nimport psutil\n# import typing\nimport warnings\nimport itertools\nwarnings.simplefilter('ignore') # ignore FutureWarnings; must precede pandas import\nimport pandas as pd\nimport numpy as np\nimport numba as nb\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cat\nimport sklearn.metrics as met\nimport sklearn.model_selection as sel\nimport typing_extensions as ext # used over vanilla typing since it backports 3.11+ features\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # ignore bugged CUDA errors; must precede tf import\nimport tensorflow as tf\ntf.keras.utils.disable_interactive_logging() # ensemble will provide its own condensed version\nprint(('GPU available.' if len(tf.config.list_physical_devices('GPU')) > 0 else 'No GPU detected.'))","metadata":{"execution":{"iopub.status.busy":"2023-12-21T22:27:17.267198Z","iopub.execute_input":"2023-12-21T22:27:17.268012Z","iopub.status.idle":"2023-12-21T22:27:33.948589Z","shell.execute_reply.started":"2023-12-21T22:27:17.267967Z","shell.execute_reply":"2023-12-21T22:27:33.947673Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"No GPU detected.\n","output_type":"stream"}]},{"cell_type":"code","source":"@nb.njit(parallel=True)\ndef compute_triplet_imbalance(values:np.ndarray, combo_indices:list[tuple[int, int, int]]) -> np.ndarray:\n    num_rows = values.shape[0]\n    num_combinations = len(combo_indices)\n    imbalance_features = np.empty((num_rows, num_combinations))\n    for i in nb.prange(num_combinations): # enumerate() works but prange() lets us run in parallel\n        a, b, c = combo_indices[i]\n        for j in nb.prange(num_rows):\n            _a, _b, _c = values[j, a], values[j, b], values[j, c]\n            max_val = max(_a, _b, _c)\n            min_val = min(_a, _b, _c)\n            mid_val = sum([_a, _b, _c])-max_val-min_val\n            imbalance_features[j, i] = np.nan if mid_val == min_val else (max_val-mid_val)/(mid_val-min_val)\n    return imbalance_features   \n\ndef calculate_triplet_imbalance_numba(cols:list[str], data:pd.DataFrame) -> pd.DataFrame:\n    values = data[cols].values\n    combo_indices = []\n    columns = []\n    for a, b, c in itertools.combinations(cols, 3):\n        combo_indices.append(tuple([cols.index(col) for col in [a, b, c]]))\n        columns.append(f'{a}_{b}_{c}_imbalance')\n    features_array = compute_triplet_imbalance(values, combo_indices)\n    features = pd.DataFrame(features_array, columns=columns)\n    return features\n\ndef imbalance_features(data:pd.DataFrame) -> pd.DataFrame:\n    prices = [*[col for col in data.columns if 'price' in col], 'wap']\n    sizes = [col for col in data.columns if 'size' in col]\n    data['volume'] = data.eval('ask_size+bid_size')\n    data['mid_price'] = data.eval('(ask_price+bid_price)/2')\n    data['liquidity_imbalance'] = data.eval('(bid_size-ask_size)/volume')\n    data['matched_imbalance'] = data.eval('(imbalance_size-matched_size)/(imbalance_size+matched_size)')\n    data['size_imbalance'] = data.eval('bid_size/ask_size')\n    data['imbalance_momentum'] = data.groupby(level='stock_id').imbalance_size.diff(periods=1) / data.matched_size\n    data['price_spread'] = data.eval('ask_price-bid_price')\n    data['spread_intensity'] = data.groupby(level='stock_id').price_spread.diff()\n    data['price_pressure'] = data.eval('imbalance_size*price_spread')\n    data['market_urgency'] = data.eval('price_spread*liquidity_imbalance')\n    data['depth_pressure'] = data.eval('(ask_size-bid_size)*(far_price-near_price)')\n    for cols in itertools.combinations(prices, 2):\n        data[f'{cols[0]}_{cols[1]}_imbalance'] = data.eval(f'({cols[0]}-{cols[1]})/({cols[0]}+{cols[1]})')\n    for cols in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n        triplet_feature = calculate_triplet_imbalance_numba(cols, data)\n        data[triplet_feature.columns] = triplet_feature.values\n    for func in ['mean', 'std', 'skew', 'kurt']:\n        data[f'all_prices_{func}'] = data[prices].agg(func, axis=1)\n        data[f'all_sizes_{func}'] = data[sizes].agg(func, axis=1)\n    for win in [1, 2, 3, 5, 8, 13]:\n        for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n            data[f'{col}_shift_{win}'] = data.groupby(level='stock_id')[col].shift(win)\n            data[f'{col}_pct_{win}'] = data.groupby(level='stock_id')[col].pct_change(win)\n        for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n            data[f'{col}_diff_{win}'] = data.groupby(level='stock_id')[col].diff(win)\n    data = data.replace([np.inf, -np.inf], 0)\n    return data\n\ndef reduce_mem_usage(data:pd.DataFrame, verbose:bool=False) -> pd.DataFrame: # 3.10+\n    if verbose: mem_start = data.memory_usage().sum()\n    for col in data.columns:\n        match data[col].dtype:\n            case 'object' | 'bool': continue\n            case 'int32' | 'int64':\n                for int_size in [np.int8, np.int16, np.int32]:\n                    if data[col].min() > np.iinfo(int_size).min and data[col].max() < np.iinfo(int_size).max:\n                        data[col] = data[col].astype(int_size)\n            case 'float32' | 'float64':\n                for float_size in [np.float16, np.float32]:\n                    if data[col].min() > np.finfo(float_size).min and data[col].max() < np.finfo(float_size).max:\n                        data[col] = data[col].astype(float_size)\n            case _: raise Exception(data[col].dtype)\n    if verbose:\n        mem_end = data.memory_usage().sum()\n        print(f'DataFrame memory reduced from {mem_start} to {mem_end}.')\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-12-21T22:27:33.950067Z","iopub.execute_input":"2023-12-21T22:27:33.950777Z","iopub.status.idle":"2023-12-21T22:27:34.046359Z","shell.execute_reply.started":"2023-12-21T22:27:33.950744Z","shell.execute_reply":"2023-12-21T22:27:34.045181Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"LOCAL_DATA_TRAIN = '.data/train.csv'\nLOCAL_DATA_TEST_X = '.data/test.csv'\nLOCAL_DATA_TEST_Y = '.data/revealed_targets.csv'\n\nKAGGLE_DATA_TRAIN = '/kaggle/input/optiver-trading-at-the-close/train.csv'\nKAGGLE_DATA_TEST_X = '/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv'\nKAGGLE_DATA_TEST_Y = '/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv'\n\nDROPS = ['index', 'time_id', 'currently_scored', 'time_id_x', 'time_id_y', 'revealed_date_id', 'revealed_time_id', 'row_id']\nSORTS = ['date_id', 'stock_id', 'seconds_in_bucket'] # order matters here\nSKIPS = ['imbalance_buy_sell_flag', 'target']\n\ndef preprocess(data:pd.DataFrame) -> pd.DataFrame: # separate from load_data() for submission compat\n    data = data.set_index(SORTS).sort_index()      # pushing these into a multi-index makes life easier down the road\n    data = imbalance_features(data)                # must precede standardization; requires SKIPS in data\n    skip = data[[col for col in SKIPS if col in data.columns]]\n    data = data.drop([col for col in [*DROPS, *SKIPS] if col in data.columns], axis=1)\n    data = data.groupby(level='stock_id').ffill()  # impute with last observation; groupby() ensures ffill() is per-stock, per-day\n    data = (data - data.mean()) / data.std(ddof=0) # normalize/standardize (z-score)\n    data = data.fillna(0)                          # clean columns that didn't ffill or with a stdev of 0 (i.e., only 1 unique value)\n    data = pd.concat([skip, data], axis=1, join='inner') # re-join with skipped columns\n    temp = data.index.to_frame().seconds_in_bucket       # encode seconds as sin/cos waves\n    data['seconds_in_bucket_sin'] = np.sin((temp * 2 * np.pi / 540))\n    data['seconds_in_bucket_cos'] = np.cos((temp * 2 * np.pi / 540))\n    data = reduce_mem_usage(data)                  # 2nd pass doubles setup time but saves 2-3 GiB \n    return data\n\ndef load_vars(test:bool=False) -> tuple[pd.DataFrame, pd.Series]: # returns training (or test) data for either local or kaggle setup\n    def read_data(train, test_x, test_y): # wrap call to read_csv() since test X and y values are stored separately and must be merged\n        if test: return pd.merge(*[pd.read_csv(path) for path in [test_x, test_y]], on=SORTS).rename(columns={'revealed_target':'target'})\n        else: return pd.read_csv(train)\n    try: data = read_data(LOCAL_DATA_TRAIN, LOCAL_DATA_TEST_X, LOCAL_DATA_TEST_Y)\n    except FileNotFoundError: data = read_data(KAGGLE_DATA_TRAIN, KAGGLE_DATA_TEST_X, KAGGLE_DATA_TEST_Y)\n    data = data.dropna(subset=['target']) # some rows have null targets\n    data = reduce_mem_usage(data) # 1st pass must precede preprocess() or kaggle will run out of memory\n    data = preprocess(data)\n    return data.drop('target', axis=1), data.target","metadata":{"execution":{"iopub.status.busy":"2023-12-21T22:27:34.048660Z","iopub.execute_input":"2023-12-21T22:27:34.048968Z","iopub.status.idle":"2023-12-21T22:27:34.060676Z","shell.execute_reply.started":"2023-12-21T22:27:34.048942Z","shell.execute_reply":"2023-12-21T22:27:34.059830Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class PredictionError(Exception): pass # specific for training feedback\n\nclass IModel(ext.Protocol): # partial wrapper for sklearn API\n    def fit(self, X, y, **kwargs) -> ext.Self: ...\n    def predict(self, X, **kwargs) -> np.ndarray: ...\n    def get_params(self, deep=True) -> dict[str, ext.Any]: ...\n\nclass SelectiveEnsemble: # once len(models) >= limit, reject new models with scores above the mean\n    def __init__(self, limit:int=None) -> None:\n        self.limit = limit \n        self.models = dict[str, IModel]()\n        self.scores = dict[str, float]()\n        self.kwargs = dict[str, dict]()\n        self.test_x, self.test_y = load_vars(test=True)\n    \n    @property\n    def mean_score(self) -> float:\n        return sum(self.scores[m] for m in self.models) / len(self) if len(self) > 0 else None\n    \n    @property\n    def best_score(self) -> float:\n        return min(self.scores[m] for m in self.models) if len(self) > 0 else None\n    \n    @property\n    def best_model(self) -> tuple[IModel, str, dict]:\n        return [(self.models[m], m, self.kwargs[m].copy()) for m in self.models if self.scores[m] == self.best_score][0]\n    \n    def add(self, model:IModel, name:str, kwargs:dict) -> tuple[bool, float]: # raises PredictionError\n        if name in self.models: name = f'{name}(1)'\n        pred = model.predict(self.test_x, **kwargs)\n        if len(np.unique(pred)) == 1: raise PredictionError('Model is guessing a constant value.')\n        if np.isnan(pred).any(): raise PredictionError('Model is guessing NaN.')\n        score = met.mean_absolute_error(self.test_y, pred)\n        if self.limit and len(self) >= self.limit and self.mean_score < score: return False, score\n        self.models[name] = model\n        self.scores[name] = score\n        self.kwargs[name] = kwargs\n        return True, score\n\n    def prune(self, limit:int=None) -> ext.Self: # removes models with scores above the mean; recurses if limit is set\n        pruned = SelectiveEnsemble(limit=(limit or self.limit))\n        pruned.models = {m:self.models[m] for m in self.models if self.scores[m] <= self.mean_score}\n        pruned.scores = {m:self.scores[m] for m in pruned.models}\n        pruned.kwargs = {m:self.kwargs[m] for m in pruned.models}\n        if pruned.limit and len(pruned) > pruned.limit > 1: return pruned.prune()\n        return pruned\n    \n    def clone(self, limit:int=None) -> ext.Self:\n        clone = SelectiveEnsemble(limit=(limit or self.limit))\n        clone.models = self.models.copy()\n        clone.scores = self.scores.copy()\n        clone.kwargs = self.kwargs.copy()\n        return clone\n    \n    def predict(self, X:pd.DataFrame, **kwargs) -> np.ndarray: # wrapper for soft voting; kwargs for compat\n        y = np.zeros(len(X))\n        for m in self.models:\n            pred = self.models[m].predict(X, **self.kwargs[m])\n            pred = pred.reshape(-1) # reshape needed for tensorflow output; doesn't impact other model types\n            temp = np.ma.masked_invalid(pred) # mask NaN and +/- inf to find largest valid values\n            pred = np.nan_to_num(pred, posinf=temp.max()+temp.std(), neginf=temp.min()-temp.std()) # then use those to clamp the invalid ones\n            y += pred\n        y = y / len(self)\n        return y\n\n    def __len__(self) -> int:\n        return len(self.models)\n    \n    def __repr__(self) -> str:\n        return f'<SelectiveEnsemble ({len(self)} model(s); mean: {self.mean_score:.8f}; best: {self.best_score:.8f}; limit: {self.limit})>'","metadata":{"execution":{"iopub.status.busy":"2023-12-21T22:27:34.062116Z","iopub.execute_input":"2023-12-21T22:27:34.062636Z","iopub.status.idle":"2023-12-21T22:27:34.079964Z","shell.execute_reply.started":"2023-12-21T22:27:34.062600Z","shell.execute_reply":"2023-12-21T22:27:34.079055Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"MODEL_FOLDER = 'models/'\nif not os.path.exists(MODEL_FOLDER): os.makedirs(MODEL_FOLDER)\nprocess = psutil.Process() # defaults to current process\n\n# customize fit() and predict() kwargs for each model's type and params\ndef build_model_kwargs(model:IModel, val_data:tuple[pd.DataFrame, pd.Series]=None) -> tuple[dict, dict, dict]:\n    fit_kw = dict()\n    predict_kw = dict()\n    early_stop_kw = dict()\n    model_class = type(model).__name__\n    match model_class:\n        case 'Sequential':\n            keras_kw = dict(batch_size=256, verbose=0)\n            fit_kw.update(keras_kw)\n            predict_kw.update(keras_kw)\n            early_stop_kw['validation_data'] = val_data\n        case 'LGBMRegressor':\n            fit_kw.update(dict(verbose=False)) # verbose=0 throws an error\n            if 'early_stopping_round' in model.get_params():\n                early_stop_kw['eval_set'] = [val_data]\n                early_stop_kw['eval_metric'] = 'l1'\n        case 'XGBRegressor' | 'CatBoostRegressor':\n            fit_kw.update(dict(verbose=0))\n            if 'early_stopping_rounds' in model.get_params():\n                early_stop_kw['eval_set'] = [val_data]\n    fit_kw.update(early_stop_kw)\n    return fit_kw, predict_kw, early_stop_kw\n\n# builds an ensemble trained on the data from load_vars(). if an existing ensemble is provided, it will be updated instead.\ndef train_ensemble(models:list[IModel], folds:int=5, limit:int=None, ensemble:SelectiveEnsemble=None) -> SelectiveEnsemble:\n    setup_start = time.time()\n    print(f'Pre-training setup...', end='\\r')\n    ensemble = ensemble.clone(limit=(limit or len(ensemble))) if ensemble else SelectiveEnsemble(limit=(limit or len(models)))\n    cv = sel.TimeSeriesSplit(folds)\n    X, y = load_vars()\n    setup_time = time.time() - setup_start\n    print(f'Pre-training setup...Complete ({setup_time:.1f}s)')\n    for j, model in enumerate(models): # each model gets its own ensemble, then the best fold will be added to the main\n        name = type(model).__name__\n        is_sequential = name == 'Sequential'\n        if is_sequential:\n            model.compile(optimizer='adam', loss='mae')\n            name = model.name            \n        _msg = f'Model {j+1}/{len(models)}:'\n        for i, (i_train, i_valid) in enumerate(cv.split(X)):\n            try: # fail gracefully instead of giving up on the whole ensemble\n                fold_start = time.time()\n                _name = f'{name}_{int(time.time())}'\n                msg = f'{_msg} Fold {i+1}/{folds}:'\n                print(f'{msg} Training {name}...'+' '*48, end='\\r')\n                X_valid, y_valid = X.iloc[i_valid, :], y.iloc[i_valid]\n                fit_kw, predict_kw, early_stop_kw = build_model_kwargs(model, (X_valid, y_valid))\n                try: model.fit(X.iloc[i_train, :], y.iloc[i_train], **fit_kw) # some kwargs fail on kaggle\n                except: model.fit(X.iloc[i_train, :], y.iloc[i_train], **early_stop_kw) # fallback to early stop only\n                del X_valid, y_valid\n                mem_total = process.memory_info().rss / 1024**3 # B -> GiB\n                if MEMORY_CAP and mem_total > MEMORY_CAP: raise MemoryError(f'High memory allocation ({mem_total:.1f} > {MEMORY_CAP:.1f} GiB)') # plug memory leak\n                print(f'{msg} Adding {name} to ensemble...', end='\\r')\n                if is_sequential:\n                    clone = tf.keras.models.clone_model(model)\n                    clone.set_weights(model.get_weights())\n                else: clone = None\n                res, score = ensemble.add((clone or model), _name, predict_kw)\n                if (res): joblib.dump(model, os.path.join(MODEL_FOLDER, f'{_name}.joblib'))\n                fold_time = time.time()-fold_start\n                print(f'{msg} {(\"Accepted\" if res else \"Rejected\")} with score: {score:.8f}'\n                     +f' ({fold_time:.1f}s) ({mem_total:.1f} GiB)'+(f' ({_name})' if res else '')+' '*10)\n            except Exception as e:\n                print(f'{msg} Stopped: {type(e).__name__}: {e}')\n                if isinstance(e, PredictionError): break # these tend not to improve, so move on to the next model\n                if isinstance(e, MemoryError): break     # malloc resets with each model, so move on if exceeded\n            finally:\n                while gc.collect() > 0: pass # memory is at a premium\n    return ensemble\n\ndef load_ensemble(model_dir:str=MODEL_FOLDER) -> SelectiveEnsemble:\n    ensemble = SelectiveEnsemble()\n    for file in os.listdir(model_dir):\n        model = joblib.load(os.path.join(model_dir, file))\n        name = file.split('.joblib')[0]\n        kwargs = build_model_kwargs(model, (ensemble.test_x, ensemble.test_y))[1] # only need predict_kw\n        ensemble.add(model, name, kwargs)\n    if len(ensemble) == 0: raise FileNotFoundError(f'No models saved in {model_dir}.')\n    return ensemble","metadata":{"execution":{"iopub.status.busy":"2023-12-21T22:27:34.081535Z","iopub.execute_input":"2023-12-21T22:27:34.082162Z","iopub.status.idle":"2023-12-21T22:27:34.103195Z","shell.execute_reply.started":"2023-12-21T22:27:34.082132Z","shell.execute_reply":"2023-12-21T22:27:34.102307Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"N_FEATURES = len(load_vars(test=True)[0].columns)\nACTIVATION_1 = 'tanh' # inputs are standardized so keep negative range\nACTIVATION_2 = 'relu' # performed better than tanh, sigmoid\nDROPOUT = 0.5         # performed better than 0.3, 0.4\nRANDOM_STATE = 25     # funnier than 24\n\nlayers = tf.keras.layers\nSequential = tf.keras.Sequential\nregularizer = tf.keras.regularizers.l1(0.001)\ntf.keras.utils.set_random_seed(RANDOM_STATE)\n\nshared_kw = dict(random_state=RANDOM_STATE, learning_rate=0.2, max_depth=3, subsample=0.8)\nxgb_lgb_kw = dict(n_jobs=16, colsample_bytree=0.85, reg_alpha=500)                         \nxgb_cat_kw = dict(early_stopping_rounds=5)\nlgb_cat_kw = dict(num_leaves=8, min_child_samples=2000)\n\nmodels = [ # order matters if limit is set; frontloading stronger models will cause more rejections; the reverse will oversaturate\n    Sequential([ # 145 -> 18 -> 1\n        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(N_FEATURES//8, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(1)\n    ], name='octo'),\n    Sequential([ # 145 -> 36 -> 1\n        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(N_FEATURES//4, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(1)\n    ], name='quad'),\n    Sequential([ # 145 -> 72 -> 1\n        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(N_FEATURES//2, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(1)\n    ], name='duce'),\n    Sequential([ # 145 -> 145 -> 1\n        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(1)\n    ], name='mono'),\n    xgb.XGBRegressor(**shared_kw, **xgb_lgb_kw, **xgb_cat_kw, eval_metric='mae', tree_method='hist', gamma=0.2), #, nthread=1),\n    lgb.LGBMRegressor(**shared_kw, **xgb_lgb_kw, **lgb_cat_kw, early_stopping_round=5, metric='l1', min_split_gain=0.001, verbosity=-1),\n    cat.CatBoostRegressor(**shared_kw, **xgb_cat_kw, **lgb_cat_kw, eval_metric='MAE'),\n    Sequential([layers.Dense(1, activation=ACTIVATION_1, input_shape=[N_FEATURES])], name='linear'), # 145 -> 1\n    Sequential([ # 145 -> 72 -> 36 -> 18 -> 1\n        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(N_FEATURES//2, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(N_FEATURES//4, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(N_FEATURES//8, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(1)\n    ], name='deep'),\n    Sequential([ # 145 -> 89 -> 13 -> 5 -> 1 \n        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(89, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(13, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(5 , kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(1)\n    ], name='fib'),\n    Sequential([ # 145 -> 29 -> 5 -> 1\n        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(29, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(5 , kernel_regularizer=regularizer, activation=ACTIVATION_2),\n        layers.Dropout(DROPOUT),\n        layers.BatchNormalization(),\n        layers.Dense(1)\n    ], name='prime'),\n]\n\ntry: ensemble = train_ensemble(models, limit=1, folds=10, ensemble=load_ensemble())\nexcept FileNotFoundError: ensemble = train_ensemble(models, limit=21, folds=10)\nensemble","metadata":{"execution":{"iopub.status.busy":"2023-12-21T22:27:34.104511Z","iopub.execute_input":"2023-12-21T22:27:34.105063Z","iopub.status.idle":"2023-12-22T00:22:07.173339Z","shell.execute_reply.started":"2023-12-21T22:27:34.105024Z","shell.execute_reply":"2023-12-22T00:22:07.172178Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Pre-training setup...Complete (201.4s)\nModel 1/11: Fold 1/10: Accepted with score: 5.46674776 (14.3s) (7.1 GiB) (octo_1703197861)          \nModel 1/11: Fold 2/10: Accepted with score: 5.46028614 (24.4s) (7.7 GiB) (octo_1703197876)          \nModel 1/11: Fold 3/10: Accepted with score: 5.46843863 (28.4s) (8.2 GiB) (octo_1703197901)          \nModel 1/11: Fold 4/10: Accepted with score: 5.47055435 (38.9s) (8.8 GiB) (octo_1703197930)          \nModel 1/11: Fold 5/10: Accepted with score: 5.44443083 (43.6s) (9.8 GiB) (octo_1703197970)          \nModel 1/11: Fold 6/10: Accepted with score: 5.44809437 (91.4s) (10.4 GiB) (octo_1703198014)          \nModel 1/11: Fold 7/10: Accepted with score: 5.45909929 (92.8s) (10.9 GiB) (octo_1703198106)          \nModel 1/11: Fold 8/10: Accepted with score: 5.43582106 (67.4s) (11.5 GiB) (octo_1703198200)          \nModel 1/11: Fold 9/10: Accepted with score: 5.45244312 (78.6s) (11.9 GiB) (octo_1703198268)          \nModel 1/11: Fold 10/10: Accepted with score: 5.44761658 (157.1s) (12.7 GiB) (octo_1703198348)          \nModel 2/11: Fold 1/10: Accepted with score: 5.47326708 (14.4s) (7.3 GiB) (quad_1703198506)          \nModel 2/11: Fold 2/10: Accepted with score: 5.45058775 (20.8s) (8.4 GiB) (quad_1703198521)          \nModel 2/11: Fold 3/10: Accepted with score: 5.48031902 (29.2s) (8.9 GiB) (quad_1703198542)          \nModel 2/11: Fold 4/10: Accepted with score: 5.46366358 (47.6s) (9.4 GiB) (quad_1703198572)          \nModel 2/11: Fold 5/10: Accepted with score: 5.43980122 (46.0s) (9.9 GiB) (quad_1703198621)          \nModel 2/11: Fold 6/10: Accepted with score: 5.46292543 (92.6s) (10.5 GiB) (quad_1703198667)          \nModel 2/11: Fold 7/10: Accepted with score: 5.44852829 (66.0s) (11.0 GiB) (quad_1703198761)          \nModel 2/11: Fold 8/10: Accepted with score: 5.44694519 (75.4s) (11.6 GiB) (quad_1703198828)          \nModel 2/11: Fold 9/10: Accepted with score: 5.45261288 (86.0s) (12.1 GiB) (quad_1703198904)          \nModel 2/11: Fold 10/10: Accepted with score: 5.45315027 (158.9s) (12.9 GiB) (quad_1703198991)          \nModel 3/11: Fold 1/10: Accepted with score: 5.48633051 (17.3s) (8.0 GiB) (duce_1703199151)          \nModel 3/11: Fold 2/10: Rejected with score: 5.46021557 (22.8s) (8.5 GiB)               \nModel 3/11: Fold 3/10: Rejected with score: 5.49094343 (35.1s) (9.0 GiB)               \nModel 3/11: Fold 4/10: Rejected with score: 5.46809053 (43.2s) (9.0 GiB)               \nModel 3/11: Fold 5/10: Accepted with score: 5.43916082 (53.3s) (10.1 GiB) (duce_1703199272)          \nModel 3/11: Fold 6/10: Accepted with score: 5.45419884 (92.6s) (10.6 GiB) (duce_1703199326)          \nModel 3/11: Fold 7/10: Accepted with score: 5.45486259 (94.5s) (11.1 GiB) (duce_1703199420)          \nModel 3/11: Fold 8/10: Accepted with score: 5.44484949 (80.1s) (11.7 GiB) (duce_1703199515)          \nModel 3/11: Fold 9/10: Rejected with score: 5.45695400 (111.2s) (12.2 GiB)             \nModel 3/11: Fold 10/10: Accepted with score: 5.44944096 (104.3s) (13.0 GiB) (duce_1703199708)          \nModel 4/11: Fold 1/10: Rejected with score: 5.48737526 (17.8s) (7.6 GiB)               \nModel 4/11: Fold 2/10: Rejected with score: 5.47378111 (25.4s) (8.1 GiB)               \nModel 4/11: Fold 3/10: Rejected with score: 5.49622393 (35.6s) (8.6 GiB)               \nModel 4/11: Fold 4/10: Rejected with score: 5.47469425 (45.7s) (9.6 GiB)               \nModel 4/11: Fold 5/10: Accepted with score: 5.43767500 (57.4s) (10.2 GiB) (mono_1703199941)          \nModel 4/11: Fold 6/10: Rejected with score: 5.45920467 (67.7s) (10.7 GiB)              \nModel 4/11: Fold 7/10: Rejected with score: 5.45927286 (80.2s) (11.3 GiB)              \nModel 4/11: Fold 8/10: Accepted with score: 5.45226002 (87.0s) (11.8 GiB) (mono_1703200149)          \nModel 4/11: Fold 9/10: Accepted with score: 5.45478439 (109.3s) (12.5 GiB) (mono_1703200237)          \nModel 4/11: Fold 10/10: Accepted with score: 5.44629288 (110.3s) (13.3 GiB) (mono_1703200347)          \nModel 5/11: Fold 1/10: Rejected with score: 5.54980278 (29.2s) (7.2 GiB)                       \nModel 5/11: Fold 2/10: Rejected with score: 5.51867867 (43.6s) (7.3 GiB)                       \nModel 5/11: Fold 3/10: Rejected with score: 5.55416822 (84.4s) (7.3 GiB)                       \nModel 5/11: Fold 4/10: Rejected with score: 5.51191616 (51.1s) (7.3 GiB)                       \nModel 5/11: Fold 5/10: Rejected with score: 5.52359438 (64.3s) (7.3 GiB)                       \nModel 5/11: Fold 6/10: Rejected with score: 5.52167273 (83.9s) (7.3 GiB)                       \nModel 5/11: Fold 7/10: Rejected with score: 5.52643967 (161.9s) (7.3 GiB)                      \nModel 5/11: Fold 8/10: Rejected with score: 5.50472403 (117.6s) (7.3 GiB)                      \nModel 5/11: Fold 9/10: Rejected with score: 5.48516321 (114.0s) (7.4 GiB)                      \nModel 5/11: Fold 10/10: Rejected with score: 5.49676371 (148.1s) (7.7 GiB)                      \nModel 6/11: Fold 1/10: Rejected with score: 5.54017902 (13.3s) (7.3 GiB)                        \nModel 6/11: Fold 2/10: Rejected with score: 5.58886821 (30.0s) (7.3 GiB)                        \nModel 6/11: Fold 3/10: Rejected with score: 5.57379007 (43.4s) (7.3 GiB)                        \nModel 6/11: Fold 4/10: Rejected with score: 5.55170146 (53.5s) (7.3 GiB)                        \nModel 6/11: Fold 5/10: Rejected with score: 5.53560541 (61.0s) (7.3 GiB)                        \nModel 6/11: Fold 6/10: Rejected with score: 5.57378478 (80.4s) (7.3 GiB)                        \nModel 6/11: Fold 7/10: Rejected with score: 5.52543146 (77.3s) (7.6 GiB)                        \nModel 6/11: Fold 8/10: Rejected with score: 5.51058472 (78.3s) (7.6 GiB)                        \nModel 6/11: Fold 9/10: Rejected with score: 5.57687525 (113.9s) (8.3 GiB)                       \nModel 6/11: Fold 10/10: Rejected with score: 5.57378832 (144.8s) (8.7 GiB)                       \nModel 7/11: Fold 1/10: Rejected with score: 5.51967745 (7.1s) (8.9 GiB)                             \nModel 7/11: Fold 2/10: Rejected with score: 5.60041358 (26.1s) (9.1 GiB)                            \nModel 7/11: Fold 3/10: Rejected with score: 5.58158642 (57.2s) (9.4 GiB)                            \nModel 7/11: Fold 4/10: Rejected with score: 5.50244528 (27.7s) (9.7 GiB)                            \nModel 7/11: Fold 5/10: Rejected with score: 5.47462419 (23.6s) (10.0 GiB)                           \nModel 7/11: Fold 6/10: Rejected with score: 5.49399672 (30.7s) (10.2 GiB)                           \nModel 7/11: Fold 7/10: Rejected with score: 5.48048142 (37.4s) (10.4 GiB)                           \nModel 7/11: Fold 8/10: Rejected with score: 5.47830521 (39.9s) (10.6 GiB)                           \nModel 7/11: Fold 9/10: Rejected with score: 5.45652460 (40.3s) (11.0 GiB)                           \nModel 7/11: Fold 10/10: Rejected with score: 5.48325194 (58.8s) (11.3 GiB)                           \nModel 8/11: Fold 1/10: Accepted with score: 5.42330980 (9.3s) (12.4 GiB) (linear_1703202419)          \nModel 8/11: Fold 2/10: Accepted with score: 5.42662287 (13.1s) (12.9 GiB) (linear_1703202429)          \nModel 8/11: Fold 3/10: Accepted with score: 5.42855310 (16.6s) (13.4 GiB) (linear_1703202443)          \nModel 8/11: Fold 4/10: Accepted with score: 5.43060684 (20.1s) (13.9 GiB) (linear_1703202460)          \nModel 8/11: Fold 5/10: Accepted with score: 5.42556763 (23.8s) (14.5 GiB) (linear_1703202481)          \nModel 8/11: Fold 6/10: Accepted with score: 5.42849255 (27.2s) (15.0 GiB) (linear_1703202506)          \nModel 8/11: Fold 7/10: Accepted with score: 5.42994356 (31.4s) (15.5 GiB) (linear_1703202534)          \nModel 8/11: Fold 8/10: Accepted with score: 5.42969656 (36.5s) (16.0 GiB) (linear_1703202566)          \nModel 8/11: Fold 9/10: Accepted with score: 5.42966509 (39.2s) (16.6 GiB) (linear_1703202604)          \nModel 8/11: Fold 10/10: Stopped: MemoryError: High memory allocation (17.1 > 16.8 GiB)    \nModel 9/11: Fold 1/10: Accepted with score: 5.43695354 (18.8s) (12.5 GiB) (deep_1703202691)          \nModel 9/11: Fold 2/10: Accepted with score: 5.43885708 (26.8s) (13.0 GiB) (deep_1703202710)          \nModel 9/11: Fold 3/10: Rejected with score: 5.47060823 (37.6s) (13.5 GiB)              \nModel 9/11: Fold 4/10: Accepted with score: 5.44516802 (48.3s) (14.0 GiB) (deep_1703202777)          \nModel 9/11: Fold 5/10: Accepted with score: 5.42362404 (59.4s) (14.6 GiB) (deep_1703202826)          \nModel 9/11: Fold 6/10: Accepted with score: 5.43068886 (75.0s) (15.1 GiB) (deep_1703202886)          \nModel 9/11: Fold 7/10: Accepted with score: 5.42386675 (83.7s) (15.6 GiB) (deep_1703202962)          \nModel 9/11: Fold 8/10: Accepted with score: 5.43283319 (94.0s) (16.2 GiB) (deep_1703203047)          \nModel 9/11: Fold 9/10: Accepted with score: 5.42654181 (105.9s) (16.7 GiB) (deep_1703203142)          \nModel 9/11: Fold 10/10: Stopped: MemoryError: High memory allocation (17.2 > 16.8 GiB)  \nModel 10/11: Fold 1/10: Accepted with score: 5.41288519 (19.0s) (12.5 GiB) (fib_1703203363)          \nModel 10/11: Fold 2/10: Accepted with score: 5.42969179 (27.1s) (13.1 GiB) (fib_1703203383)          \nModel 10/11: Fold 3/10: Accepted with score: 5.42294884 (38.5s) (13.6 GiB) (fib_1703203411)          \nModel 10/11: Fold 4/10: Accepted with score: 5.42440224 (51.9s) (14.1 GiB) (fib_1703203450)          \nModel 10/11: Fold 5/10: Accepted with score: 5.41281843 (61.4s) (14.6 GiB) (fib_1703203503)          \nModel 10/11: Fold 6/10: Accepted with score: 5.41763163 (70.8s) (15.2 GiB) (fib_1703203566)          \nModel 10/11: Fold 7/10: Accepted with score: 5.40958977 (84.8s) (15.7 GiB) (fib_1703203637)          \nModel 10/11: Fold 8/10: Accepted with score: 5.41316938 (97.3s) (16.2 GiB) (fib_1703203723)          \nModel 10/11: Fold 9/10: Accepted with score: 5.40570974 (116.7s) (16.7 GiB) (fib_1703203822)          \nModel 10/11: Fold 10/10: Stopped: MemoryError: High memory allocation (17.3 > 16.8 GiB) \nModel 11/11: Fold 1/10: Accepted with score: 5.41626072 (24.9s) (12.6 GiB) (prime_1703204064)          \nModel 11/11: Fold 2/10: Accepted with score: 5.42283821 (23.0s) (13.2 GiB) (prime_1703204090)          \nModel 11/11: Fold 3/10: Accepted with score: 5.43606901 (31.1s) (13.7 GiB) (prime_1703204114)          \nModel 11/11: Fold 4/10: Accepted with score: 5.42892838 (40.3s) (14.2 GiB) (prime_1703204146)          \nModel 11/11: Fold 5/10: Accepted with score: 5.42352009 (54.4s) (14.7 GiB) (prime_1703204187)          \nModel 11/11: Fold 6/10: Accepted with score: 5.42590094 (58.3s) (15.3 GiB) (prime_1703204242)          \nModel 11/11: Fold 7/10: Accepted with score: 5.43689299 (67.2s) (15.8 GiB) (prime_1703204302)          \nModel 11/11: Fold 8/10: Accepted with score: 5.41525698 (73.5s) (16.3 GiB) (prime_1703204370)          \nModel 11/11: Fold 9/10: Stopped: MemoryError: High memory allocation (16.9 > 16.8 GiB)   \n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<SelectiveEnsemble (64 model(s); mean: 5.43922959; best: 5.40570974; limit: 21)>"},"metadata":{}}]},{"cell_type":"code","source":"cut1 = ensemble.prune()\ncut2 = cut1.prune()\nprint(f'Ensemble: {ensemble.mean_score:.8f}, {len(ensemble)} models ({\", \".join([m for m in ensemble.models])})')\nprint(f'1st Cut : {cut1.mean_score:.8f}, {len(cut1)} models ({\", \".join([m for m in cut1.models])})')\nprint(f'2nd Cut : {cut2.mean_score:.8f}, {len(cut2)} models ({\", \".join([m for m in cut2.models])})')","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:22:07.174877Z","iopub.execute_input":"2023-12-22T00:22:07.175191Z","iopub.status.idle":"2023-12-22T00:22:10.908464Z","shell.execute_reply.started":"2023-12-22T00:22:07.175167Z","shell.execute_reply":"2023-12-22T00:22:10.907552Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Ensemble: 5.43922959, 64 models (octo_1703197861, octo_1703197876, octo_1703197901, octo_1703197930, octo_1703197970, octo_1703198014, octo_1703198106, octo_1703198200, octo_1703198268, octo_1703198348, quad_1703198506, quad_1703198521, quad_1703198542, quad_1703198572, quad_1703198621, quad_1703198667, quad_1703198761, quad_1703198828, quad_1703198904, quad_1703198991, duce_1703199151, duce_1703199272, duce_1703199326, duce_1703199420, duce_1703199515, duce_1703199708, mono_1703199941, mono_1703200149, mono_1703200237, mono_1703200347, linear_1703202419, linear_1703202429, linear_1703202443, linear_1703202460, linear_1703202481, linear_1703202506, linear_1703202534, linear_1703202566, linear_1703202604, deep_1703202691, deep_1703202710, deep_1703202777, deep_1703202826, deep_1703202886, deep_1703202962, deep_1703203047, deep_1703203142, fib_1703203363, fib_1703203383, fib_1703203411, fib_1703203450, fib_1703203503, fib_1703203566, fib_1703203637, fib_1703203723, fib_1703203822, prime_1703204064, prime_1703204090, prime_1703204114, prime_1703204146, prime_1703204187, prime_1703204242, prime_1703204302, prime_1703204370)\n1st Cut : 5.41878237, 17 models (linear_1703202419, linear_1703202481, deep_1703202826, deep_1703202962, fib_1703203363, fib_1703203411, fib_1703203450, fib_1703203503, fib_1703203566, fib_1703203637, fib_1703203723, fib_1703203822, prime_1703204064, prime_1703204090, prime_1703204187, prime_1703204242, prime_1703204370)\n2nd Cut : 5.41291523, 8 models (fib_1703203363, fib_1703203503, fib_1703203566, fib_1703203637, fib_1703203723, fib_1703203822, prime_1703204064, prime_1703204370)\n","output_type":"stream"}]},{"cell_type":"code","source":"raise Exception # stop for manual eval\nmodel = cut1","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:33:28.418748Z","iopub.execute_input":"2023-12-22T00:33:28.419223Z","iopub.status.idle":"2023-12-22T00:33:28.424321Z","shell.execute_reply.started":"2023-12-22T00:33:28.419187Z","shell.execute_reply":"2023-12-22T00:33:28.423193Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import optiver2023\nenv = optiver2023.make_env()\niter_test = env.iter_test()\n\nfor (test, _, _) in iter_test:\n    X_test = preprocess(test)\n    y_pred = model.predict(X_test, verbose=0)\n    assert not np.isnan(y_pred).any() # sanity check 2\n    submission = test[['row_id']]\n    submission['target'] = y_pred\n    env.predict(submission)\n\ntry:\n    res = pd.read_csv('/kaggle/working/submission.csv') # sanity check\nexcept FileNotFoundError:\n    res = pd.read_csv('.data/submission.csv')\nres","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:22:11.649568Z","iopub.status.idle":"2023-12-22T00:22:11.650081Z","shell.execute_reply.started":"2023-12-22T00:22:11.649894Z","shell.execute_reply":"2023-12-22T00:22:11.649913Z"},"trusted":true},"execution_count":null,"outputs":[]}]}