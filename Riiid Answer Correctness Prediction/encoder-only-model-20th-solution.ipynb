{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-06T22:25:59.453198Z",
     "iopub.status.busy": "2021-01-06T22:25:59.452431Z",
     "iopub.status.idle": "2021-01-06T22:26:02.038708Z",
     "shell.execute_reply": "2021-01-06T22:26:02.037706Z"
    },
    "papermill": {
     "duration": 2.602791,
     "end_time": "2021-01-06T22:26:02.038844",
     "exception": false,
     "start_time": "2021-01-06T22:25:59.436053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008417,
     "end_time": "2021-01-06T22:26:02.056972",
     "exception": false,
     "start_time": "2021-01-06T22:26:02.048555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T22:26:02.077567Z",
     "iopub.status.busy": "2021-01-06T22:26:02.076896Z",
     "iopub.status.idle": "2021-01-06T22:26:37.111700Z",
     "shell.execute_reply": "2021-01-06T22:26:37.117151Z"
    },
    "papermill": {
     "duration": 35.052491,
     "end_time": "2021-01-06T22:26:37.117384",
     "exception": false,
     "start_time": "2021-01-06T22:26:02.064893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.89 s, sys: 3.64 s, total: 11.5 s\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('../input/rid-group-w-lag-time/group_w_lag_time.p','rb') as f:\n",
    "    group=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T22:26:37.155168Z",
     "iopub.status.busy": "2021-01-06T22:26:37.154410Z",
     "iopub.status.idle": "2021-01-06T22:26:38.139107Z",
     "shell.execute_reply": "2021-01-06T22:26:38.140197Z"
    },
    "papermill": {
     "duration": 1.012493,
     "end_time": "2021-01-06T22:26:38.140467",
     "exception": false,
     "start_time": "2021-01-06T22:26:37.127974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp ../input/rid-test110/Network.py .\n",
    "from Network import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T22:26:38.177524Z",
     "iopub.status.busy": "2021-01-06T22:26:38.176658Z",
     "iopub.status.idle": "2021-01-06T22:26:47.154267Z",
     "shell.execute_reply": "2021-01-06T22:26:47.155020Z"
    },
    "papermill": {
     "duration": 9.001319,
     "end_time": "2021-01-06T22:26:47.155250",
     "exception": false,
     "start_time": "2021-01-06T22:26:38.153931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "n_skill=13523\n",
    "MAX_SEQ=129\n",
    "\n",
    "models=[]\n",
    "layers=[6]\n",
    "for i, nlayer in enumerate(layers):\n",
    "    if nlayer is not None:\n",
    "        model = SAKTModel(n_skill, max_seq=MAX_SEQ, embed_dim=256, nlayers=nlayer).to(device)\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"../input/rid-test110-loss-weight/model1.pth\"))\n",
    "\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "        \n",
    "for i, nlayer in enumerate(layers):\n",
    "    if nlayer is not None:\n",
    "        model = SAKTModel(n_skill, max_seq=MAX_SEQ, embed_dim=384, nlayers=nlayer, nheads=12).to(device)\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "        model.load_state_dict(torch.load(f\"../input/rid-test110-loss-weight-12head/model1.pth\"))\n",
    "\n",
    "        model.eval()\n",
    "        models.append(model)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T22:26:47.227626Z",
     "iopub.status.busy": "2021-01-06T22:26:47.226758Z",
     "iopub.status.idle": "2021-01-06T22:26:54.663948Z",
     "shell.execute_reply": "2021-01-06T22:26:54.662826Z"
    },
    "papermill": {
     "duration": 7.479609,
     "end_time": "2021-01-06T22:26:54.664095",
     "exception": false,
     "start_time": "2021-01-06T22:26:47.184486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for user in group.index:\n",
    "    group[user]=group[user][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T22:26:54.821439Z",
     "iopub.status.busy": "2021-01-06T22:26:54.696503Z",
     "iopub.status.idle": "2021-01-06T22:26:55.109699Z",
     "shell.execute_reply": "2021-01-06T22:26:55.110216Z"
    },
    "papermill": {
     "duration": 0.436804,
     "end_time": "2021-01-06T22:26:55.110428",
     "exception": false,
     "start_time": "2021-01-06T22:26:54.673624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_cluster=pd.read_csv('../input/rid-tag-community/question_cmnts.csv')\n",
    "\n",
    "question_df=pd.read_csv('../input/riiid-test-answer-prediction/questions.csv')\n",
    "possible_tags=[]\n",
    "for i, tags in enumerate(question_df.tags):\n",
    "    try:\n",
    "        tags=tags.split()\n",
    "        for tag in tags:\n",
    "            tag=int(tag)\n",
    "            if tag not in possible_tags:\n",
    "                possible_tags.append(tag)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tag_encoding=np.zeros((len(question_df),len(possible_tags)))\n",
    "for i, tags in enumerate(question_df.tags):\n",
    "    try:\n",
    "        tags=tags.split()\n",
    "        for tag in tags:\n",
    "            tag=int(tag)\n",
    "            tag_encoding[i,tag]=1\n",
    "    except:\n",
    "\n",
    "        #exit()\n",
    "        #print(i)\n",
    "        pass#exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009292,
     "end_time": "2021-01-06T22:26:55.129399",
     "exception": false,
     "start_time": "2021-01-06T22:26:55.120107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T22:26:55.177672Z",
     "iopub.status.busy": "2021-01-06T22:26:55.167360Z",
     "iopub.status.idle": "2021-01-06T22:26:55.186138Z",
     "shell.execute_reply": "2021-01-06T22:26:55.185524Z"
    },
    "papermill": {
     "duration": 0.047391,
     "end_time": "2021-01-06T22:26:55.186268",
     "exception": false,
     "start_time": "2021-01-06T22:26:55.138877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def task_mask(tasks):\n",
    "    seq_length=len(tasks)\n",
    "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
    "    container_mask= np.ones((seq_length, seq_length))\n",
    "    container_mask=(container_mask*tasks.reshape(1,-1))==(container_mask*tasks.reshape(-1,1))\n",
    "    #comparison_mask=np.ones((seq_length, seq_length))*tasks.reshape(-1,1)\n",
    "    #mask=future_mask(task)\n",
    "    future_mask=future_mask+container_mask\n",
    "    np.fill_diagonal(future_mask,0)\n",
    "    return future_mask\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, samples, test_df, question_cluster=question_cluster, tag_encoding=tag_encoding, max_seq=MAX_SEQ):\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.samples = samples\n",
    "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
    "        self.test_df = test_df\n",
    "        self.n_skill = 13523\n",
    "        self.max_seq = max_seq\n",
    "        self.question_cluster=np.append(question_cluster.community.values,[5])\n",
    "        self.tag_encoding=np.concatenate([tag_encoding,np.zeros((1,188))],0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_info = self.test_df.iloc[index]\n",
    "    \n",
    "        user_id = test_info[\"user_id\"]\n",
    "        target_id = test_info[\"content_id\"]\n",
    "        elapsed_time=test_info[\"prior_question_elapsed_time\"]\n",
    "        explanation=test_info[\"prior_question_had_explanation\"]\n",
    "        time_stamp=test_info[\"timestamp\"]\n",
    "        task_container=test_info[\"task_container_id\"]\n",
    "        #et_ = test_info[\"prior_question_elapsed_time\"]\n",
    "        \n",
    "        \n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        q[:]=13523\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        et = np.zeros(self.max_seq, dtype=int)\n",
    "        pq = np.zeros(self.max_seq, dtype=int)\n",
    "        ts = np.zeros(self.max_seq, dtype=int)\n",
    "        tasks = np.zeros(self.max_seq, dtype=int)\n",
    "        \n",
    "        if user_id in self.samples.index:\n",
    "            q_, qa_, et_, pq_, ts_, tasks_ = self.samples[user_id]\n",
    "            \n",
    "            seq_len = len(q_)\n",
    "\n",
    "            if seq_len >= self.max_seq:\n",
    "                q = q_[-self.max_seq:]\n",
    "                qa = qa_[-self.max_seq:]\n",
    "                et = et_[-self.max_seq:]\n",
    "                pq = pq_[-self.max_seq:]\n",
    "                ts = ts_[-self.max_seq:]\n",
    "                tasks = tasks_[-self.max_seq:]\n",
    "                \n",
    "            else:\n",
    "                q[-seq_len:] = q_\n",
    "                qa[-seq_len:] = qa_\n",
    "                et[-seq_len:] = et_\n",
    "                pq[-seq_len:] = pq_\n",
    "                ts[-seq_len:] = ts_\n",
    "                tasks[-seq_len:] = tasks_\n",
    "        \n",
    "        x = q[1:].copy()\n",
    "        xa = qa[1:].copy()\n",
    "        #x += (qa[1:] == 1) * self.n_skill\n",
    "        \n",
    "        questions = np.append(q[2:], [target_id])\n",
    "        pq = np.append(pq[2:], [explanation])\n",
    "        et = np.append(et[2:], [elapsed_time])//1000\n",
    "        ts = (np.append(ts[2:], [time_stamp])-ts[1:])/1000\n",
    "        tasks= np.append(tasks[1:], [task_container])\n",
    "        \n",
    "        for i in range(len(ts)-1):\n",
    "            if tasks[i+1]==tasks[i+2]:\n",
    "                ts[i+1]=ts[i]\n",
    "                #xa[i+1]=xa[i]\n",
    "        #print(tasks[1:])\n",
    "        #print(ts)\n",
    "        et = np.clip(et,0,300)\n",
    "        #et = np.clip(et,0,300)\n",
    "        #print(f\"###last elapsed time: {et[-1]}###\")\n",
    "        mask=(questions==13523)\n",
    "        mask[0]=False\n",
    "        cluster=self.question_cluster[questions]\n",
    "        tags=self.tag_encoding[questions]\n",
    "        \n",
    "        #attention_mask=task_mask(tasks[1:])\n",
    "        attention_mask=0\n",
    "        #attention_mask[:,0]=False\n",
    "        \n",
    "        return questions, xa, et, pq, ts, attention_mask, mask, cluster, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T22:26:55.210621Z",
     "iopub.status.busy": "2021-01-06T22:26:55.209930Z",
     "iopub.status.idle": "2021-01-06T22:26:55.237553Z",
     "shell.execute_reply": "2021-01-06T22:26:55.236969Z"
    },
    "papermill": {
     "duration": 0.041476,
     "end_time": "2021-01-06T22:26:55.237667",
     "exception": false,
     "start_time": "2021-01-06T22:26:55.196191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "\n",
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T22:26:55.276317Z",
     "iopub.status.busy": "2021-01-06T22:26:55.265986Z",
     "iopub.status.idle": "2021-01-06T22:26:57.123849Z",
     "shell.execute_reply": "2021-01-06T22:26:57.124569Z"
    },
    "papermill": {
     "duration": 1.877178,
     "end_time": "2021-01-06T22:26:57.124781",
     "exception": false,
     "start_time": "2021-01-06T22:26:55.247603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "1it [00:01,  1.05s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.94it/s]\n",
      "2it [00:01,  1.28it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.0\n",
      "46.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.22it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.03it/s]\n",
      "4it [00:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "\n",
    "\n",
    "prev_test_df = None\n",
    "\n",
    "for (test_df, sample_prediction_df) in tqdm(iter_test):\n",
    "    #HDKIM\n",
    "    if (prev_test_df is not None) & (psutil.virtual_memory().percent<90):\n",
    "        print(psutil.virtual_memory().percent)\n",
    "        prev_test_df['answered_correctly'] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prev_test_df['prior_question_elapsed_time']=prev_test_df['prior_question_elapsed_time'].fillna(0)\n",
    "        prev_test_df['prior_question_elapsed_time']=prev_test_df['prior_question_elapsed_time'].values        \n",
    "        #prev_test_df['prior_question_had_explanation']=prev_test_df['prior_question_had_explanation'].fillna(False).astype('int')\n",
    "        prev_test_df = prev_test_df[prev_test_df.content_type_id == False]\n",
    "        prev_group = prev_test_df[['user_id', 'content_id', 'answered_correctly','prior_question_elapsed_time','prior_question_had_explanation','timestamp','task_container_id']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values,\n",
    "            r['prior_question_elapsed_time'].values,\n",
    "            r['prior_question_had_explanation'].values,\n",
    "            r['timestamp'].values,\n",
    "            r['task_container_id'].values))\n",
    "        for prev_user_id in prev_group.index:\n",
    "            prev_group_content = prev_group[prev_user_id][0]\n",
    "            prev_group_ac = prev_group[prev_user_id][1]\n",
    "            prev_group_et = prev_group[prev_user_id][2]\n",
    "            prev_group_pq = prev_group[prev_user_id][3]\n",
    "            prev_group_ts = prev_group[prev_user_id][4]\n",
    "            prev_group_tc = prev_group[prev_user_id][5]\n",
    "            if prev_user_id in group.index:\n",
    "                group[prev_user_id] = (np.append(group[prev_user_id][0],prev_group_content), \n",
    "                                       np.append(group[prev_user_id][1],prev_group_ac),\n",
    "                                       np.append(group[prev_user_id][2],prev_group_et),\n",
    "                                       np.append(group[prev_user_id][3],prev_group_pq),\n",
    "                                       np.append(group[prev_user_id][4],prev_group_ts),\n",
    "                                       np.append(group[prev_user_id][5],prev_group_tc))\n",
    " \n",
    "            else:\n",
    "                group[prev_user_id] = (prev_group_content,prev_group_ac,prev_group_et,prev_group_pq,prev_group_ts,prev_group_tc)\n",
    "            if len(group[prev_user_id][0])>MAX_SEQ:\n",
    "                new_group_content = group[prev_user_id][0][-MAX_SEQ:]\n",
    "                new_group_ac = group[prev_user_id][1][-MAX_SEQ:]\n",
    "                new_group_et = group[prev_user_id][2][-MAX_SEQ:]\n",
    "                new_group_pq = group[prev_user_id][3][-MAX_SEQ:]\n",
    "                new_group_ts = group[prev_user_id][4][-MAX_SEQ:]\n",
    "                new_group_tc = group[prev_user_id][5][-MAX_SEQ:]\n",
    "                group[prev_user_id] = (new_group_content,new_group_ac,new_group_et,new_group_pq,new_group_ts,new_group_tc)\n",
    "\n",
    "    vec=test_df['prior_question_had_explanation'].to_numpy()\n",
    "    for i, entry in enumerate(vec):\n",
    "        try:\n",
    "            if entry != 0:\n",
    "                pass\n",
    "        except:\n",
    "            vec[i]=2\n",
    "\n",
    "    vec=vec.astype(int)\n",
    "    test_df['prior_question_had_explanation']=test_df['prior_question_had_explanation'].fillna(True).astype(int)\n",
    "    test_df['prior_question_had_explanation']=vec                \n",
    "                \n",
    "                \n",
    "    prev_test_df = test_df.copy()\n",
    "    \n",
    "    test_df = test_df[test_df.content_type_id == False]\n",
    "\n",
    "    test_dataset = TestDataset(group, test_df)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=51200, shuffle=False)\n",
    "    \n",
    "    outs = []\n",
    "\n",
    "    for item in tqdm(test_dataloader):\n",
    "        target_id = item[0].to(device).long()\n",
    "        xa = item[1].to(device).long()\n",
    "        et = item[2].to(device).float()\n",
    "        et = torch.clamp(et,0,300)\n",
    "        et[et!=et] = 0\n",
    "\n",
    "        #et = item[3].to(device).float()\n",
    "        #x=torch.nan_to_num(x,nan=0)\n",
    "        #print(et)\n",
    "        #print(et)\n",
    "        pq = item[3].to(device).long()\n",
    "        ts = item[4].to(device).float()\n",
    "        ts = torch.clamp(ts,0,1440)\n",
    "        ts[ts!=ts] = 0\n",
    "        attn_mask = item[5].to(device).bool()\n",
    "        mask=item[6].to(device).bool()\n",
    "        cluster=item[7].to(device).long()\n",
    "        tags=item[8].to(device).float()\n",
    "        \n",
    "        outputs=[]\n",
    "        with torch.no_grad():\n",
    "            for model in models:\n",
    "                #print(target_id.shape)\n",
    "                output = model(target_id, xa, et, ts, pq, None, mask, cluster, tags)\n",
    "                outputs.append(output)\n",
    "        \n",
    "        output=torch.sigmoid(torch.stack(outputs,0)).mean(0)\n",
    "        \n",
    "        output = output[:, -1]\n",
    "        #print(output.shape)\n",
    "        # pred = (output >= 0.5).long()\n",
    "        # loss = criterion(output, label)\n",
    "\n",
    "        # val_loss.append(loss.item())\n",
    "        # num_corrects += (pred == label).sum().item()\n",
    "        # num_total += len(label)\n",
    "\n",
    "        # labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "        \n",
    "    test_df['answered_correctly'] =  outs\n",
    "    \n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 63.933429,
   "end_time": "2021-01-06T22:26:58.777631",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-06T22:25:54.844202",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
